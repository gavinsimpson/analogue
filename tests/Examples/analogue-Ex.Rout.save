
R version 4.4.1 (2024-06-14) -- "Race for Your Life"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "analogue"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('analogue')
Loading required package: vegan
Loading required package: permute
Loading required package: lattice
This is vegan 2.6-8
analogue version 0.17-7
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("ImbrieKipp")
> ### * ImbrieKipp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ImbrieKipp
> ### Title: Imbrie and Kipp foraminifera training set
> ### Aliases: ImbrieKipp SumSST WinSST Salinity V12.122
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> head(ImbrieKipp)
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0    0.00       0    0.00    0.00  98.97   0.90    0.00
V17.196      0       0    0.00       0    0.00    0.00  98.13   0.94    0.47
V18.110      0       0    0.00       0    0.00    0.00  96.29   1.71    1.00
V16.227      0       0    0.00       0    0.00    0.00  94.33   4.82    0.85
V14.47       0       0    0.11       0    0.11    0.11  68.50   2.71   10.95
V23.22       0       0    0.00       0    0.00    0.00  55.69  16.62   19.90
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0    0.00       0    0.00   0.00      0    0.00
V17.196       0       0       0    0.47       0    0.00   0.00      0    0.00
V18.110       0       0       0    0.00       0    0.57   0.00      0    0.00
V16.227       0       0       0    0.00       0    0.00   0.00      0    0.00
V14.47        0       0       0    1.95       0   14.20   0.11      0    0.43
V23.22        0       0       0    2.29       0    1.57   0.00      0    0.00
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V14.61     0.00    0.00    0.00       0       0       0  0.13   0.00    0.00
V17.196    0.00    0.00    0.00       0       0       0  0.00   0.00    0.00
V18.110    0.00    0.00    0.00       0       0       0  0.43   0.00    0.00
V16.227    0.00    0.00    0.00       0       0       0  0.00   0.00    0.00
V14.47     0.11    0.11    0.11       0       0       0  0.18   0.32    0.00
V23.22     0.00    0.00    0.00       0       0       0  0.65   3.14    0.13
> 
> data(SumSST)
> data(WinSST)
> data(Salinity)
> 
> plot(cbind(SumSST, WinSST, Salinity))
> 
> data(V12.122)
> head(V12.122)
   O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo G.falco
0   1.792   0.489  43.485   0.814  25.570   0.651      0  0.163   0.000   0.163
10  3.203   0.712  37.722   0.356  30.961   0.712      0  0.356   0.000   0.000
20  2.564   1.709  47.009   0.855  20.513   1.709      0  1.282   0.427   0.000
30  1.124   0.562  47.190   1.124  12.360   2.247      0  3.933   0.562   0.562
40  0.671   1.007  43.623   3.020  15.436   1.007      0  0.336   0.671   0.336
50  1.149   0.766  52.873   0.766  12.261   0.000      0  0.383   2.299   0.000
   G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf G.scitu
0    0.326   3.257   8.958   4.560   0.163  0.163  0.000   0.000   0.163
10   0.000   2.491   8.185   5.694   0.000  0.712  0.356   0.000   0.000
20   0.855   0.855   9.402   5.556   0.000  0.427  0.855   0.000   0.855
30   2.247   5.056   7.865   6.742   1.124  0.000  1.685   0.562   0.562
40   1.678   8.054   9.396   3.691   4.698  0.336  2.349   1.342   0.336
50   1.916   6.897   7.663   4.981   4.215  0.000  2.682   0.766   0.000
   G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu G.hexag G.cglom
0    7.492   0.977   0.651   0.163       0 0.000      0       0       0       0
10   5.694   1.423   0.000   0.356       0 1.068      0       0       0       0
20   2.991   0.855   0.855   0.000       0 0.427      0       0       0       0
30   1.124   2.247   0.000   0.000       0 1.124      0       0       0       0
40   1.007   0.671   0.000   0.000       0 0.336      0       0       0       0
50   0.000   0.000   0.000   0.000       0 0.383      0       0       0       0
   cfH.pel
0        0
10       0
20       0
30       0
40       0
50       0
> 
> 
> 
> cleanEx()
> nameEx("Pollen")
> ### * Pollen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Pollen
> ### Title: North American Modern Pollen Database
> ### Aliases: Pollen Biome Climate Location
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(Pollen)
> 
> data(Climate)
> 
> data(Biome)
> 
> data(Location)
> 
> 
> 
> cleanEx()
> nameEx("RMSEP")
> ### * RMSEP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: RMSEP
> ### Title: Root mean square error of prediction
> ### Aliases: RMSEP RMSEP.default RMSEP.mat RMSEP.bootstrap.mat
> ###   RMSEP.bootstrap.wa
> ### Keywords: methods utilities
> 
> ### ** Examples
> 
> ## Don't show: 
> op <- options(digits = 3)
> ## End(Don't show)
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## Leave-one-out RMSEP for the MAT model
> RMSEP(ik.mat)
[1] 1.73
> 
> ## bootstrap training set
> (ik.boot <- bootstrap(ik.mat, n.boot = 100))

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP    S1   S2 r.squared avg.bias max.bias
LOO       3  1.71     -    -     0.941    0.133     5.17
Bootstrap 5  1.95 0.942 1.71     0.972    0.286     5.73

> 
> ## extract the Birks et al (1990) RMSEP
> RMSEP(ik.boot)
[1] 1.95
> 
> ## Calculate the alternative formulation
> RMSEP(ik.boot, type = "standard")
[1] 1.71
> ## Don't show: 
> options(op)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("Stratiplot")
> ### * Stratiplot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Stratiplot
> ### Title: Palaeoecological stratigraphic diagrams
> ### Aliases: Stratiplot Stratiplot.default Stratiplot.formula
> ###   Stratiplot.matrix
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data(V12.122)
> Depths <- as.numeric(rownames(V12.122))
> 
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122,  type = c("h","l","g","smooth")))
> 
> ## Order taxa by WA in depth --- ephasises change over time
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("h"), sort = "wa"))
> 
> ## Using the default interface
> spp.want <- c("O.univ","G.ruber","G.tenel","G.pacR")
> (plt <- Stratiplot(V12.122[, spp.want], y = Depths,
+                    type = c("poly", "g")))
> 
> ## Adding zones to a Stratigraphic plot
> ## Default labelling and draw zone legend
> ## Here we choose 4 arbitrary Depths as the zone boundaries
> set.seed(123)
> Zones <-sample(Depths, 4)
> Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+            data = V12.122, type = c("poly","g"),
+            zones = Zones)
> 
> ## As before, but supplying your own zone labels
> zone.labs <- c("A","B","C","D","E")
> Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+            data = V12.122, type = c("poly","g"),
+            zones = Zones, zoneNames = zone.labs)
> 
> ## Suppress the drawing of the zone legend
> Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+            data = V12.122, type = c("poly","g"),
+            zones = Zones, drawLegend = FALSE)
> 
> ## Add zones and draw a legend, but do not label the zones
> Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+            data = V12.122, type = c("poly","g"),
+            zones = Zones, zoneNames = "")
> 
> ## Show illustration of NA handling
> set.seed(42)
> dat <- data.frame(Depth = 1:20, LOI = runif(20), TC = NA)
> dat <- within(dat, TC[sample(20, 10)] <- runif(10))
> ## default is 'na.action = "na.pass"'
> Stratiplot(Depth ~ LOI + TC, data = dat, type = c("l","p"))
> ## to remove rows with NA, use 'na.action = "na.omit"'
> Stratiplot(Depth ~ LOI + TC, data = dat, type = c("l","p"),
+            na.action = "na.omit")
> 
> ## Example of two proxies measured on different levels of core
> ## (Here measurements on alternate levels)
> set.seed(5)
> dat2a <- data.frame(Depth = seq(1, by = 2, length = 20), LOI = runif(20))
> dat2b <- data.frame(Depth = seq(0, by = 2, length = 20), TC = runif(20))
> dat2 <- join(dat2a, dat2b, na.replace = FALSE, split = FALSE)
> dat2 <- dat2[order(dat2$Depth), ]
> head(dat2)
    Depth       LOI        TC
110     0        NA 0.8902071
1       1 0.2002145        NA
21      2        NA 0.7207010
2       3 0.6852186        NA
31      4        NA 0.2113403
3       5 0.9168758        NA
> 
> ## Default is to allow NA through formula, but drop them when plotting
> Stratiplot(Depth ~ LOI + TC, data = dat2, type = c("l","p"))
> 
> ## compare with this if we didn't suppress NA in default Stratiplot
> ## method (can't use formula interface for this yet
> Stratiplot(dat2[,-1], dat2[,1], type = c("l","p"),
+            na.action = "na.pass")
> ## Notice no lines are draw as there a no "sections" ithout missing
> ## levels. If you want/desire this behaviour then you can't use formula
> ## interface yet as there is no way to specify the na.action separately
> 
> ## Works with matrices
> M <- as.matrix(V12.122)
> Stratiplot(M, Depths, type = c("h"))
> 
> ## Custom variable labels using expressions
> df <- data.frame(Age = 1:10, Var1 = rnorm(10), Var2 = rnorm(10),
+                  Var3 = rnorm(10))
> ## Use a vector of expressions to label variables on plot
> ## See ?plotmath for syntax of expressions
> exprs <- expression(delta^{15}*N,       # label for Var1
+                     delta^{18}*O,       # label for Var2
+                     delta^{13}*C)       # label for Var3
> Stratiplot(Age ~ ., data = df, labelValues = exprs, varTypes = "absolute")
> 
> 
> 
> cleanEx()
> nameEx("abernethy")
> ### * abernethy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: abernethy
> ### Title: Abernethy Forest Pollen Sequence
> ### Aliases: abernethy
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(abernethy)
> head(abernethy)
  Betula Pinus sylvestris Ulmus Quercus Alnus glutinosa Corylus-Myrica Salix
1  15.11            51.82  2.68    3.44            5.54           6.88  0.00
2  21.00            59.48  0.93    1.86            0.93           7.81  0.93
3   9.26            76.23  0.54    1.09            0.73           7.08  0.00
4  20.70            74.84  0.80    0.48            0.00           0.96  0.16
5   6.07            88.06  0.39    1.37            0.20           1.17  0.20
6  11.32            81.57  1.15    1.34            0.19           2.30  0.58
  Juniperus communis Calluna vulgaris Empetrum Gramineae Cyperaceae
1                  0             7.07     0.76      1.34       4.78
2                  0             3.35     0.74      0.56       2.04
3                  0             2.36     0.36      0.18       2.18
4                  0             0.64     0.00      0.32       0.64
5                  0             0.78     0.59      0.39       0.59
6                  0             0.38     0.00      0.38       0.58
  Solidago-type Compositae Artemisia Caryophyllaceae Sagina Silene
1             0          0         0               0      0      0
2             0          0         0               0      0      0
3             0          0         0               0      0      0
4             0          0         0               0      0      0
5             0          0         0               0      0      0
6             0          0         0               0      0      0
  Chenopodiaceae Epilobium-type Papilionaceae Anthyllis vulneraria
1              0              0             0                    0
2              0              0             0                    0
3              0              0             0                    0
4              0              0             0                    0
5              0              0             0                    0
6              0              0             0                    0
  Astragalus alpinus Ononis-type Rosaceae Rubiaceae Ranunculaceae Thalictrum
1                  0           0     0.00         0             0          0
2                  0           0     0.19         0             0          0
3                  0           0     0.00         0             0          0
4                  0           0     0.00         0             0          0
5                  0           0     0.00         0             0          0
6                  0           0     0.19         0             0          0
  Rumex acetosa-type Oxyria-type Parnassia palustris Saxifraga spp1
1                  0           0                   0              0
2                  0           0                   0              0
3                  0           0                   0              0
4                  0           0                   0              0
5                  0           0                   0              0
6                  0           0                   0              0
  Saxifraga spp2 Sedum Urtica Veronica Depth  Age
1              0     0      0        0   300 5515
2              0     0      0        0   305 5632
3              0     0      0        0   310 5749
4              0     0      0        0   315 5866
5              0     0      0        0   320 5983
6              0     0      0        0   325 6100
> 
> (plt <- Stratiplot(Age ~ . - Depth,
+                    data = chooseTaxa(abernethy, n.occ = 5, max.abun = 10),
+                    type = "poly"))
> 
> 
> 
> cleanEx()
> nameEx("analog")
> ### * analog
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: analog
> ### Title: Analogue matching
> ### Aliases: analog analog.default analog.distance print.analog
> ### Keywords: multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Imbrie and Kipp foraminfera sea-surface temperature
> 
> ## analog matching between SWAP and RLGH core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

      0      10      20      30      40      50      60      70      80      90 
0.00103 0.20580 0.24673 0.27418 0.26386 0.34447 0.36276 0.39255 0.37565 0.38941 
    100     110     120     130     140     150     160     170     180     190 
0.42555 0.38787 0.42905 0.39793 0.44159 0.38670 0.38293 0.33502 0.39193 0.40225 
    200     210     220     230     240     250     260     270     280     290 
0.33727 0.36363 0.34381 0.32030 0.33913 0.33152 0.33710 0.40605 0.41771 0.35843 
    300     310     320     330     340     350     360     370     380     390 
0.36563 0.45973 0.42443 0.43737 0.36395 0.39245 0.38022 0.42119 0.38140 0.41874 
    400     410     420     430     440     450     460     470     480     490 
0.34186 0.45068 0.33572 0.40482 0.29348 0.34371 0.35648 0.33792 0.40345 0.36043 
    500     510     520     530     540     550     560     570     580     590 
0.34283 0.43705 0.36927 0.43211 0.43543 0.43002 0.37040 0.35875 0.34271 0.27971 
    600     610     620     630     640     650     660     670     680     690 
0.33571 0.43484 0.49012 0.33567 0.36832 0.34366 0.42574 0.44031 0.47852 0.35294 
    700     710     720     730     740     750     760     770     780     790 
0.40298 0.41467 0.47288 0.50627 0.38976 0.36831 0.39931 0.44974 0.50466 0.35900 
    800     810     820     830     840     850     860     870     880     890 
0.36004 0.37868 0.39429 0.33538 0.36688 0.42206 0.43431 0.42413 0.40355 0.47735 
    900     910     920     930     940     950     960     970     980     990 
0.46549 0.39262 0.40363 0.39642 0.34586 0.43115 0.41340 0.37004 0.34726 0.44592 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.37685 0.48035 0.43378 0.43677 0.46931 0.33997 0.42792 0.42910 0.37678 0.36444 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    V14.5     V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   A180.76   V12.79    V16.21    V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V22.204   V15.164   V22.219 
   7  V15.164   V20.230   V14.90    A180.72   V20.234   V20.234   V20.167 
   8  V16.21    V20.167   V20.230   V22.204   V14.90    A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V20.230   V20.230   V12.18  
  10  V20.230   V20.7     V9.31     V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V9.31     V14.90    V19.216   V14.90  
  V16.21    V16.21    V22.204   V22.204   V20.230   V22.172   V19.216 
  V14.90    V20.167   V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    V9.31     V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   A153.154  V14.90    V12.79    V20.167   V12.79  
  V20.234   A179.13   V14.90    V16.21    V22.172   A153.154  V22.204 
  V20.167   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V9.31     V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V22.204   V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V22.172 
  V20.230   V20.167   V10.89    V20.230   V14.90    V9.31     V9.31   
  V20.234   V16.21    V9.31     V16.21    V16.21    V14.90    V14.90  
  V14.90    V19.216   V19.216   V22.172   V20.230   V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V10.89    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V16.21  
  V16.21    V15.164   V16.33    V9.31     V15.164   V20.234   V12.79  
  V15.164   V20.230   V22.172   V22.219   V20.234   V16.21    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V3.128    V20.230   V14.5     V12.122   V22.172   V22.172   A180.72 
  V20.167   V18.21    V14.90    V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   V20.234   V18.21    V12.79    V12.122   V12.79  
  V20.230   V14.5     A180.76   V22.172   V12.122   A180.72   V22.204 
  V20.234   V20.234   V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   V14.5     V10.89    V20.234   V18.21  
  A180.76   A180.76   V15.164   A180.72   V9.31     A180.76   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V22.172 
  V12.122   V14.5     V19.216   V14.90    V22.172   V14.90    V10.89  
  V22.204   A180.72   V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V16.190   V14.90    A180.39   V19.308 
  V14.5     V22.172   V20.230   V20.230   V16.21    V16.190   V16.21  
  V20.234   V3.128    V9.31     V16.21    V12.122   V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V9.31     V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V20.167   V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   V22.172   V20.230 
  V14.90    V14.90    V12.122   V20.230   V9.31     A180.76   V9.31   
  V16.21    V20.234   V22.204   A180.76   V14.90    V20.230   V14.90  
  V22.172   V15.164   V20.234   V3.128    V20.234   A180.72   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V16.33    V22.204   V20.167   V19.216   V20.234 
  V15.164   V9.31     V15.164   V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V22.172   V14.90  
  V20.234   V9.31     V14.90    V20.234   V3.128    V20.167   A180.76 
  V14.90    V20.234   V20.234   V18.21    V14.5     V20.234   V22.204 
  V20.230   V14.90    V20.230   V12.122   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   A180.72   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   A180.76   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   V20.230   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V9.31   
  A180.76   V16.21    V19.216   V14.90    V15.164   V19.216   V3.128  
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  V12.122   V18.21    V20.234   V3.128    V16.21    V19.216   V22.172 
  A180.72   V20.230   V20.230   V19.216   V10.89    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.78   V12.122   V22.172   V12.79  
  V14.5     V14.5     V19.216   A180.72   V15.164   V16.21    V9.31   
  V14.90    V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V9.31     V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V12.79    V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V22.204   V22.172   A180.72   V14.90    V20.167 
  V9.31     A180.78   V14.90    V16.21    A180.76   V12.122   V19.216 
  A180.76   V14.90    A180.72   V15.164   V22.204   V22.204   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V12.79    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V3.128    V16.33  
  V20.234   V20.234   V20.234   V14.90    V20.230   A180.72   V20.230 
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  V12.122   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  A180.72   V14.5     V22.172   V22.172   V22.172   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     A180.72   V9.31     V22.172 
  V20.230   V3.128    V20.167   V3.128    V20.230   V22.204   V22.219 
  V20.234   A180.72   V14.5     V16.33    V12.122   V16.190   V22.204 
  V22.172   V18.21    V15.164   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   A180.76   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V22.172   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V12.122   V12.79    V3.128  
  V16.21    V20.234   V3.128    V20.230   V20.234   V22.172   V12.122 
  V19.216   V12.122   V10.89    V20.167   V20.230   V20.230   A180.72 
  V10.89    V22.172   V19.216   V12.122   V12.79    V12.122   V20.167 
  V15.164   V20.230   V20.167   V19.216   V20.167   V9.31     V9.31   
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V20.230 
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V19.216   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V22.204   V16.33  
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V20.167 
  V16.21    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V14.90    V22.172   V3.128    V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   A180.72   A180.72   V12.79    V20.167   V12.122 
  V9.31     A180.72   A180.76   V14.90    V14.5     A180.72   V16.190 
  A180.76   V20.230   V20.234   V16.21    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V12.79    A180.72   V9.31     V20.234 
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V22.172   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V19.216   V9.31     V19.222   V9.31   
  V22.204   V9.31     V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V19.216   V19.216   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V20.167   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V16.190 
  A180.72   A180.76   V15.164   V10.89    V12.79    V22.172   V20.230 
  V9.31     V20.230   V12.18    V16.21    V20.167   V9.31     A180.39 
  V14.90    A180.72   V9.31     V20.230   A180.72   V12.79    V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V16.21    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V14.90    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V9.31     V12.79    V22.172 
  V19.222   V22.172   V22.172   V14.90    V20.230   V16.21    V19.216 
  V12.79    V22.204   V14.90    V22.172   V12.122   V22.172   A180.76 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V12.79    V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V20.167   V20.234   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   A180.72   A179.13   V20.167   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  V22.172   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  A180.76   V12.79    V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V22.204   V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.172   V19.216   V19.216   V12.122   V22.204 
  V22.204   V14.90    V22.172   V22.172   V19.216 
  V14.90    V12.122   V22.204   V14.90    V14.90  
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V9.31   
  V16.33    V20.234   V22.219   V20.234   V20.234 
  V16.190   A180.78   V9.31     V20.230   V16.190 

Dissimilarities for k-closest analogues

   k        0       10       20       30       40       50       60       70
   1  0.00103  0.20580  0.24673  0.27418  0.26386  0.34447  0.36276  0.39255
   2  0.21926  0.25739  0.25996  0.27563  0.30406  0.37446  0.39390  0.40656
   3  0.22764  0.27592  0.31710  0.27790  0.31780  0.39293  0.40903  0.41654
   4  0.25235  0.32554  0.32341  0.28835  0.34085  0.40633  0.42194  0.42589
   5  0.30061  0.32868  0.32481  0.30522  0.36582  0.40641  0.42377  0.43659
   6  0.30975  0.35421  0.34224  0.31439  0.37089  0.41120  0.42844  0.44453
   7  0.35531  0.35967  0.35109  0.33136  0.37495  0.44233  0.42926  0.44877
   8  0.35836  0.38994  0.35184  0.33558  0.37806  0.45328  0.44222  0.44919
   9  0.36781  0.40574  0.35983  0.33957  0.37916  0.45638  0.44358  0.45148
  10  0.37869  0.41747  0.36224  0.34318  0.38376  0.47018  0.44470  0.45326
       80       90      100      110      120      130      140      150
  0.37565  0.38941  0.42555  0.38787  0.42905  0.39793  0.44159  0.38670
  0.38328  0.41811  0.44003  0.43782  0.43414  0.41478  0.44773  0.39272
  0.39373  0.48881  0.44158  0.47585  0.43742  0.41982  0.46543  0.39931
  0.39823  0.49538  0.46032  0.49080  0.45839  0.44633  0.46607  0.41529
  0.40922  0.49652  0.47914  0.50140  0.46151  0.45518  0.49664  0.41958
  0.42514  0.49977  0.48790  0.50324  0.49773  0.47669  0.50303  0.43204
  0.43004  0.50025  0.48857  0.50760  0.51037  0.47858  0.51860  0.44963
  0.43658  0.51154  0.49498  0.52084  0.51151  0.50167  0.52045  0.45103
  0.44513  0.52225  0.50037  0.52443  0.51720  0.50295  0.52303  0.45311
  0.45252  0.52647  0.50246  0.52830  0.51885  0.50685  0.52703  0.46088
      160      170      180      190      200      210      220      230
  0.38293  0.33502  0.39193  0.40225  0.33727  0.36363  0.34381  0.32030
  0.42073  0.35365  0.41730  0.42194  0.37912  0.37707  0.39682  0.38325
  0.42142  0.35801  0.42523  0.42892  0.37923  0.38217  0.40051  0.38838
  0.42358  0.35938  0.44208  0.42991  0.37958  0.38290  0.40217  0.38888
  0.42704  0.36539  0.44270  0.45998  0.39387  0.39557  0.40404  0.40040
  0.43300  0.37745  0.44504  0.47036  0.40623  0.41859  0.40794  0.40209
  0.43541  0.37954  0.44894  0.47164  0.40837  0.42067  0.40832  0.41708
  0.43601  0.38858  0.46754  0.49113  0.41674  0.42769  0.41381  0.42265
  0.43714  0.40494  0.48654  0.50343  0.41835  0.42988  0.42134  0.43017
  0.43951  0.41634  0.51293  0.50538  0.42756  0.43470  0.43477  0.44040
      240      250      260      270      280      290      300      310
  0.33913  0.33152  0.33710  0.40605  0.41771  0.35843  0.36563  0.45973
  0.43491  0.38350  0.37142  0.42917  0.44705  0.37742  0.37086  0.47899
  0.43793  0.40723  0.37189  0.44690  0.44740  0.41176  0.37251  0.48393
  0.44636  0.42500  0.38672  0.45761  0.44923  0.41600  0.39375  0.50345
  0.45073  0.43560  0.39042  0.45814  0.46229  0.41923  0.40068  0.51087
  0.46334  0.43976  0.39826  0.47164  0.46240  0.42384  0.40753  0.53673
  0.47192  0.44086  0.40691  0.47951  0.46816  0.42613  0.40881  0.54013
  0.47705  0.45178  0.42084  0.48167  0.47171  0.45453  0.42049  0.54410
  0.48299  0.45330  0.42890  0.48300  0.48737  0.46290  0.42621  0.54547
  0.48493  0.45447  0.42990  0.49926  0.49628  0.46477  0.42883  0.54979
      320      330      340      350      360      370      380      390
  0.42443  0.43737  0.36395  0.39245  0.38022  0.42119  0.38140  0.41874
  0.43637  0.44053  0.39057  0.39936  0.39218  0.43332  0.39492  0.43403
  0.44000  0.44600  0.39337  0.40290  0.39593  0.43806  0.39738  0.46329
  0.46298  0.44996  0.40433  0.41662  0.40214  0.45921  0.40898  0.47115
  0.46331  0.46518  0.41291  0.42198  0.40240  0.46164  0.42888  0.47265
  0.46597  0.46629  0.43428  0.43209  0.40373  0.46197  0.44031  0.47610
  0.48042  0.47581  0.43880  0.43662  0.41511  0.48247  0.44213  0.47867
  0.48123  0.48338  0.44066  0.44473  0.41555  0.48825  0.45137  0.48915
  0.48617  0.48487  0.44221  0.45851  0.43056  0.49824  0.45198  0.49337
  0.49358  0.48922  0.44471  0.46839  0.43321  0.49865  0.45360  0.49529
      400      410      420      430      440      450      460      470
  0.34186  0.45068  0.33572  0.40482  0.29348  0.34371  0.35648  0.33792
  0.34991  0.45175  0.36469  0.44423  0.38508  0.35718  0.36784  0.34111
  0.41192  0.46582  0.36937  0.45030  0.39283  0.35826  0.41164  0.35165
  0.43330  0.46696  0.37115  0.45228  0.39672  0.37215  0.43668  0.35420
  0.43337  0.46808  0.37852  0.45328  0.43506  0.37371  0.45585  0.35844
  0.43511  0.47270  0.38145  0.45970  0.44118  0.37755  0.45732  0.35976
  0.43513  0.47773  0.39823  0.47916  0.44271  0.38953  0.45870  0.36097
  0.44033  0.48489  0.40172  0.48579  0.44310  0.40641  0.47307  0.36831
  0.44870  0.48657  0.40807  0.49068  0.44708  0.40658  0.47475  0.37386
  0.45318  0.50251  0.41416  0.50332  0.45294  0.41187  0.47622  0.37955
      480      490      500      510      520      530      540      550
  0.40345  0.36043  0.34283  0.43705  0.36927  0.43211  0.43543  0.43002
  0.40441  0.36855  0.35345  0.46671  0.41872  0.44491  0.43957  0.43063
  0.41353  0.37734  0.38501  0.47403  0.43053  0.44512  0.44428  0.43896
  0.41798  0.37964  0.38632  0.47959  0.45074  0.44660  0.45577  0.44389
  0.42943  0.37977  0.38665  0.49918  0.45563  0.44827  0.46556  0.45327
  0.43747  0.38713  0.40339  0.50420  0.46353  0.45752  0.47245  0.47124
  0.44122  0.39121  0.40627  0.51011  0.46961  0.46611  0.47683  0.49380
  0.44847  0.39921  0.41472  0.51385  0.47100  0.46798  0.48757  0.49383
  0.46854  0.40065  0.43965  0.52002  0.47818  0.48314  0.49310  0.50217
  0.47023  0.40443  0.43974  0.52114  0.48214  0.49092  0.49870  0.50396
      560      570      580      590      600      610      620      630
  0.37040  0.35875  0.34271  0.27971  0.33571  0.43484  0.49012  0.33567
  0.38072  0.35951  0.34339  0.34208  0.38491  0.43992  0.49519  0.42507
  0.42074  0.39751  0.35652  0.34407  0.38894  0.44648  0.50221  0.43324
  0.42443  0.40370  0.37124  0.34924  0.39580  0.44674  0.50842  0.43508
  0.42906  0.41337  0.37156  0.35570  0.41571  0.45201  0.51252  0.43625
  0.44200  0.41589  0.38380  0.36003  0.42445  0.46094  0.51440  0.43725
  0.45587  0.42660  0.41861  0.36856  0.42763  0.48917  0.51938  0.44659
  0.45875  0.42973  0.43173  0.37838  0.43509  0.49194  0.53311  0.44729
  0.47266  0.43325  0.43779  0.39153  0.43953  0.49258  0.54249  0.45796
  0.47929  0.43998  0.45290  0.39361  0.44359  0.49889  0.54275  0.47429
      640      650      660      670      680      690      700      710
  0.36832  0.34366  0.42574  0.44031  0.47852  0.35294  0.40298  0.41467
  0.38040  0.36740  0.42849  0.44563  0.49456  0.38960  0.40559  0.44073
  0.39369  0.39622  0.43216  0.46273  0.50097  0.39700  0.43168  0.44906
  0.39814  0.40695  0.43746  0.46699  0.53400  0.40936  0.44151  0.46036
  0.39920  0.42655  0.44064  0.47664  0.53555  0.42450  0.46275  0.47714
  0.41661  0.43192  0.44692  0.47983  0.54447  0.49552  0.48112  0.48072
  0.42091  0.43694  0.45318  0.48334  0.56143  0.50583  0.48306  0.48187
  0.42264  0.44326  0.45852  0.48343  0.57179  0.50801  0.48710  0.49356
  0.42736  0.44996  0.47026  0.49696  0.57843  0.51166  0.48900  0.49472
  0.43567  0.45079  0.48020  0.49727  0.58595  0.51894  0.49570  0.50009
      720      730      740      750      760      770      780      790
  0.47288  0.50627  0.38976  0.36831  0.39931  0.44974  0.50466  0.35900
  0.48088  0.51314  0.40104  0.40076  0.42345  0.45358  0.51282  0.37602
  0.49369  0.52138  0.41910  0.40345  0.43136  0.47755  0.54873  0.41955
  0.50520  0.52530  0.43006  0.42038  0.43481  0.48763  0.55591  0.43657
  0.50607  0.52923  0.43055  0.42832  0.43677  0.48881  0.56285  0.44149
  0.51746  0.53209  0.43311  0.42876  0.43792  0.49011  0.56390  0.44788
  0.53014  0.53550  0.43939  0.43684  0.43856  0.50267  0.57193  0.44868
  0.53168  0.54400  0.43949  0.43941  0.43861  0.50507  0.58244  0.45431
  0.54051  0.56067  0.44196  0.44065  0.45539  0.50910  0.58758  0.45550
  0.54257  0.56119  0.45051  0.45033  0.46033  0.51034  0.58862  0.46583
      800      810      820      830      840      850      860      870
  0.36004  0.37868  0.39429  0.33538  0.36688  0.42206  0.43431  0.42413
  0.38321  0.38887  0.42610  0.42583  0.40565  0.44871  0.45531  0.42431
  0.40486  0.39989  0.42629  0.43253  0.44404  0.45044  0.46005  0.43743
  0.42331  0.40523  0.45518  0.43383  0.45330  0.45122  0.46880  0.44596
  0.43776  0.40622  0.45746  0.45336  0.47275  0.46041  0.46907  0.46783
  0.44750  0.41167  0.46768  0.46708  0.47505  0.46049  0.47745  0.47982
  0.45170  0.41424  0.48039  0.47255  0.48153  0.48548  0.49358  0.48918
  0.45279  0.42337  0.48113  0.47697  0.49428  0.48802  0.49752  0.49125
  0.46725  0.42632  0.50986  0.48376  0.49672  0.48810  0.50827  0.51282
  0.46736  0.43076  0.51092  0.49359  0.50170  0.49491  0.51377  0.51781
      880      890      900      910      920      930      940      950
  0.40355  0.47735  0.46549  0.39262  0.40363  0.39642  0.34586  0.43115
  0.45557  0.50117  0.51492  0.46424  0.48709  0.42105  0.38375  0.43440
  0.47207  0.51009  0.54278  0.46997  0.52705  0.47301  0.39410  0.43534
  0.48705  0.51495  0.54909  0.47603  0.54523  0.48907  0.40882  0.44430
  0.49363  0.51757  0.55462  0.47839  0.54877  0.49890  0.41606  0.44454
  0.49624  0.52245  0.56395  0.49422  0.55045  0.51677  0.42172  0.44704
  0.50072  0.56077  0.57732  0.50829  0.55931  0.51826  0.45078  0.45516
  0.50353  0.56545  0.57862  0.51014  0.56003  0.52177  0.45173  0.46725
  0.51047  0.57039  0.59138  0.51932  0.56395  0.52257  0.46965  0.47445
  0.52602  0.57043  0.59688  0.52392  0.57118  0.53575  0.47191  0.48273
      960      970      980      990     1000     1010     1020     1030
  0.41340  0.37004  0.34726  0.44592  0.37685  0.48035  0.43378  0.43677
  0.41617  0.39179  0.40365  0.46708  0.37994  0.48239  0.50875  0.45307
  0.42197  0.39649  0.41422  0.46999  0.39647  0.51079  0.51194  0.45368
  0.43702  0.40046  0.44031  0.47625  0.39863  0.52011  0.52269  0.45856
  0.43837  0.40837  0.45618  0.48750  0.41329  0.52876  0.52569  0.47290
  0.44038  0.40845  0.45716  0.49802  0.42198  0.54004  0.53390  0.50031
  0.45028  0.40923  0.46432  0.49867  0.45919  0.54191  0.54819  0.52081
  0.45281  0.42071  0.46493  0.51410  0.46491  0.56273  0.54977  0.53488
  0.45948  0.42644  0.47039  0.51686  0.47031  0.56672  0.56705  0.54430
  0.46422  0.42747  0.47740  0.52783  0.47558  0.57032  0.57449  0.54835
     1040     1050     1060     1070     1080     1090
  0.46931  0.33997  0.42792  0.42910  0.37678  0.36444
  0.50089  0.40625  0.43916  0.43215  0.39138  0.37379
  0.53353  0.40803  0.50134  0.45058  0.39631  0.37446
  0.55156  0.40892  0.51540  0.45621  0.40649  0.37467
  0.55601  0.43962  0.51967  0.46166  0.42668  0.42026
  0.56071  0.46096  0.52125  0.47752  0.44332  0.43487
  0.56228  0.46564  0.53512  0.48548  0.44590  0.43999
  0.56837  0.46820  0.53823  0.50018  0.45501  0.44285
  0.57103  0.47784  0.54993  0.51040  0.45627  0.44430
  0.57641  0.48217  0.56053  0.51838  0.45860  0.45217

> 
> ## Can take pre-computed dissimilarity objects
> d1 <- distance(ImbrieKipp, V12.122)
> d2 <- distance(ImbrieKipp)
> ik <- analog(d1, d2, keep.train = TRUE)
> ik

	Analogue matching for fossil samples

Call: analog(x = d1, train = d2, keep.train = TRUE) 
Dissimilarity: euclidean 

Percentiles of the dissimilarities for the training set:

    1%     2%     5%    10%    20% 
0.0669 0.0956 0.1304 0.1739 0.2341 

	Minimum dissimilarity per sample

Dissimilarity: euclidean 

      0      10      20      30      40      50      60      70      80      90 
0.00012 0.08529 0.07638 0.08464 0.09664 0.07392 0.09275 0.10572 0.08734 0.11819 
    100     110     120     130     140     150     160     170     180     190 
0.13058 0.12955 0.13540 0.13663 0.12585 0.10448 0.12037 0.07876 0.12011 0.13041 
    200     210     220     230     240     250     260     270     280     290 
0.11417 0.11681 0.12529 0.11987 0.14560 0.08968 0.09731 0.15471 0.11494 0.11061 
    300     310     320     330     340     350     360     370     380     390 
0.10989 0.16210 0.10429 0.12834 0.09510 0.10760 0.09792 0.12989 0.11053 0.11640 
    400     410     420     430     440     450     460     470     480     490 
0.11534 0.16118 0.12001 0.13875 0.09290 0.12652 0.11703 0.09200 0.13288 0.13311 
    500     510     520     530     540     550     560     570     580     590 
0.11339 0.16103 0.12411 0.10760 0.10538 0.15002 0.12090 0.11901 0.08905 0.07164 
    600     610     620     630     640     650     660     670     680     690 
0.09920 0.12626 0.15805 0.09084 0.10447 0.07581 0.13105 0.11909 0.18304 0.14075 
    700     710     720     730     740     750     760     770     780     790 
0.09041 0.13892 0.17267 0.18076 0.11172 0.08318 0.12815 0.12077 0.17215 0.13593 
    800     810     820     830     840     850     860     870     880     890 
0.12459 0.08233 0.14046 0.11394 0.14823 0.14410 0.13920 0.12177 0.12567 0.17765 
    900     910     920     930     940     950     960     970     980     990 
0.17639 0.13165 0.15500 0.12373 0.09444 0.11822 0.09979 0.08756 0.10402 0.15001 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.11129 0.20911 0.20009 0.15203 0.20616 0.12068 0.20582 0.12403 0.12840 0.10295 

> 
> 
> 
> 
> cleanEx()
> nameEx("bayesF")
> ### * bayesF
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bayesF
> ### Title: Bayes factors
> ### Aliases: bayesF print.bayesF plot.bayesF
> ### Keywords: univar methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 12)
> 
> ## fit the ROC curve
> swap.roc <- roc(swap.ana, groups = grps)
> swap.roc

	ROC curve of dissimilarities

Discrimination for all groups:

Optimal Dissimilarity = 0.575 

AUC = 0.974, p-value: < 2.22e-16
No. within: 167   No. outside: 1837 

> 
> ## calculate the Bayes factors of analogue and no-analogue
> ## (uses observed probabilities of analogue/no-analogue
> swap.bayes <- bayesF(swap.roc)
> swap.bayes

	Bayes factors (likelihood ratios)

Object: swap.roc 

Groups (N = 12):
  1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12


Prior probabilities:
Positive: 0.5   Negative: 0.5 

> 
> ## plot the probability of analogue
> plot(swap.bayes)
> 
> ## Not run: 
> ##D ## calculate the Bayes factors of analogue and no-analogue
> ##D ## with prior probabilities c(0.5, 0.05)
> ##D swap.bayes2 <- bayesF(swap.roc, prior = c(0.5, 0.05))
> ##D swap.bayes
> ##D 
> ##D ## plot the probability of analogue
> ##D plot(swap.bayes2)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("bootstrap")
> ### * bootstrap
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootstrap
> ### Title: Bootstrap estimation and errors
> ### Aliases: bootstrap bootstrap.default bootstrap.mat print.bootstrap.mat
> ###   residuals.bootstrap.mat resid.bootstrap.mat
> ###   print.residuals.bootstrap.mat fitted.bootstrap.mat
> ###   print.fitted.bootstrap.mat
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## Don't show: 
> op <- options(digits = 3)
> ## End(Don't show)
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Imbrie and Kipp foraminfera sea-surface temperature 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> 
> ## bootstrap training set
> ## IGNORE_RDIFF_BEGIN
> ik.boot <- bootstrap(ik.mat, n.boot = 100)
> ik.boot

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP    S1   S2 r.squared avg.bias max.bias
LOO       3  1.71     -    -     0.941    0.133     5.17
Bootstrap 5  1.95 0.942 1.71     0.972    0.286     5.73

> summary(ik.boot)

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP    S1   S2 r.squared avg.bias max.bias
LOO       3  1.71     -    -     0.941    0.133     5.17
Bootstrap 5  1.95 0.942 1.71     0.972    0.286     5.73


Bootstrap estimated values for training set:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
    7.73     7.21     7.16     7.04     7.80     9.63     6.26    12.79 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   13.54    13.65    15.68    15.03    14.70    17.13    14.37    20.49 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   21.35    18.90    16.44    23.45    23.84    21.66    21.93    23.63 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   23.21    24.83    24.32    22.87    23.92    25.61    25.59    24.66 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   24.96    25.01    25.38    25.73    25.91    26.69    24.20    25.42 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   26.33    26.41    26.61    26.72    26.68    25.68    26.64    26.88 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   26.84    27.10    26.65    27.12    27.26    26.45    26.37    27.12 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   27.04    27.22    27.29    27.16    27.03 

Training set assessment:

          Obs   Est   Resid Boot.Est Boot.Resid    s1    s2 RMSEP
V14.61    2.0  7.17  5.1667     7.73     5.7325 1.456 5.910  2.41
V17.196   5.0  4.83 -0.1667     7.21     2.2143 1.730 2.797  2.48
V18.110   5.5  4.67 -0.8333     7.16     1.6636 1.763 2.410  2.46
V16.227   7.0  7.17  0.1667     7.04     0.0379 1.861 1.829  2.52
V14.47    7.0  7.67  0.6667     7.80     0.7974 1.540 1.717  2.30
V23.22   10.5 10.00 -0.5000     9.63    -0.8657 1.236 1.494  2.13
V2.12    11.0  4.83 -6.1667     6.26    -4.7361 1.531 4.971  2.36
V23.29   10.0 11.83  1.8333    12.79     2.7900 1.262 3.056  2.26
V12.43   13.0 13.50  0.5000    13.54     0.5364 1.273 1.363  2.34
R9.7     12.0 13.67  1.6667    13.65     1.6500 1.480 2.203  2.54
A157.3   14.0 14.50  0.5000    15.68     1.6850 1.148 2.031  2.46
V23.81   14.5 14.33 -0.1667    15.03     0.5275 1.233 1.327  2.60
V23.82   15.0 14.17 -0.8333    14.70    -0.3000 1.222 1.241  2.71
V12.53   14.5 17.00  2.5000    17.13     2.6312 1.135 2.859  2.78
V23.83   16.0 14.50 -1.5000    14.37    -1.6341 1.039 1.930  2.85
V12.56   18.0 20.67  2.6667    20.49     2.4950 1.294 2.803  3.06
A152.84  20.0 22.00  2.0000    21.35     1.3550 1.454 1.974  3.23
V16.50   18.0 17.17 -0.8333    18.90     0.9029 1.342 1.601  3.28
V22.122  19.0 15.50 -3.5000    16.44    -2.5618 1.283 2.857  3.36
V16.41   18.5 23.33  4.8333    23.45     4.9485 1.045 5.054  3.38
V4.32    21.5 24.00  2.5000    23.84     2.3364 0.857 2.484  3.44
V12.66   21.0 21.83  0.8333    21.66     0.6556 0.722 0.969  3.51
V19.245  21.0 20.83 -0.1667    21.93     0.9346 1.533 1.770  3.86
V4.8     24.0 23.83 -0.1667    23.63    -0.3655 1.155 1.193  3.82
A180.15  24.0 23.33 -0.6667    23.21    -0.7868 1.377 1.570  3.98
V18.34   23.0 25.33  2.3333    24.83     1.8313 0.920 2.043  3.95
V20.213  24.0 24.50  0.5000    24.32     0.3159 0.742 0.798  4.01
V19.222  23.0 23.83  0.8333    22.87    -0.1345 0.684 0.685  4.09
A180.39  23.0 24.00  1.0000    23.92     0.9171 0.613 1.098  4.17
V16.189  24.0 25.73  1.7333    25.61     1.6117 0.250 1.630  4.23
V12.18   25.0 26.07  1.0667    25.59     0.5887 0.369 0.692  4.33
V7.67    26.0 25.33 -0.6667    24.66    -1.3361 0.811 1.557  4.48
V17.165  26.0 25.33 -0.6667    24.96    -1.0370 0.506 1.151  4.52
V19.310  26.0 25.33 -0.6667    25.01    -0.9853 0.669 1.185  4.63
V16.190  25.0 25.00  0.0000    25.38     0.3751 0.622 0.719  4.71
A153.154 26.0 25.73 -0.2667    25.73    -0.2695 0.321 0.416  4.76
V19.308  26.0 25.73 -0.2667    25.91    -0.0886 0.521 0.521  4.86
V22.172  24.5 26.40  1.9000    26.69     2.1903 0.293 2.209  4.93
V10.98   27.0 24.67 -2.3333    24.20    -2.7979 0.645 2.869  5.05
V22.219  26.2 25.67 -0.5333    25.42    -0.7769 0.417 0.878  5.10
V16.33   25.0 25.73  0.7333    26.33     1.3290 0.714 1.503  5.21
V22.204  26.5 26.00 -0.5000    26.41    -0.0884 0.507 0.508  5.27
V20.167  26.2 26.17 -0.0333    26.61     0.4088 0.512 0.650  5.35
V10.89   26.0 27.23  1.2333    26.72     0.7211 0.572 0.915  5.44
V12.79   26.0 27.00  1.0000    26.68     0.6757 0.526 0.852  5.51
V19.216  27.0 25.67 -1.3333    25.68    -1.3187 0.666 1.472  5.60
V14.90   27.0 26.83 -0.1667    26.64    -0.3600 0.421 0.550  5.66
A180.72  27.5 26.67 -0.8333    26.88    -0.6238 0.310 0.695  5.74
V16.21   27.0 26.40 -0.6000    26.84    -0.1561 0.321 0.354  5.83
A180.76  27.0 27.17  0.1667    27.10     0.1000 0.200 0.222  5.91
V15.164  27.0 26.73 -0.2667    26.65    -0.3487 0.392 0.521  6.02
A180.78  27.0 26.83 -0.1667    27.12     0.1161 0.458 0.466  6.12
V14.5    27.0 27.33  0.3333    27.26     0.2594 0.205 0.329  6.21
V3.128   29.0 26.07 -2.9333    26.45    -2.5500 0.508 2.599  6.34
A179.13  28.5 26.67 -1.8333    26.37    -2.1317 0.330 2.156  6.43
V9.31    27.5 27.17 -0.3333    27.12    -0.3805 0.335 0.504  6.55
V20.230  27.5 27.33 -0.1667    27.04    -0.4553 0.285 0.535  6.66
V20.7    27.5 27.33 -0.1667    27.22    -0.2806 0.264 0.383  6.77
V20.234  27.0 27.33  0.3333    27.29     0.2886 0.204 0.352  6.88
V18.21   27.0 27.33  0.3333    27.16     0.1611 0.328 0.361  7.00
V12.122  28.0 27.00 -1.0000    27.03    -0.9692 0.104 0.975  7.13
> ## IGNORE_RDIFF_END
> 
> ## Bootstrap fitted values for training set
> ## IGNORE_RDIFF_BEGIN
> fitted(ik.boot)

	Modern Analogue Technique: Bootstrap fitted values for the training set

No. of analogues (k) : 5 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
    7.73     7.21     7.16     7.04     7.80     9.63     6.26    12.79 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   13.54    13.65    15.68    15.03    14.70    17.13    14.37    20.49 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   21.35    18.90    16.44    23.45    23.84    21.66    21.93    23.63 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   23.21    24.83    24.32    22.87    23.92    25.61    25.59    24.66 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   24.96    25.01    25.38    25.73    25.91    26.69    24.20    25.42 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   26.33    26.41    26.61    26.72    26.68    25.68    26.64    26.88 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   26.84    27.10    26.65    27.12    27.26    26.45    26.37    27.12 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   27.04    27.22    27.29    27.16    27.03 
> ## IGNORE_RDIFF_END
> 
> ## residuals
> resid(ik.boot) # uses abbreviated form

	Bootstrap residuals
Model type: MAT 
Weighted: FALSE 

(k chosen from model with lowest RMSEP)

Model residuals:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.1667  -0.1667  -0.8333   0.1667   0.6667  -0.5000  -6.1667   1.8333 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.5000   1.6667   0.5000  -0.1667  -0.8333   2.5000  -1.5000   2.6667 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  2.0000  -0.8333  -3.5000   4.8333   2.5000   0.8333  -0.1667  -0.1667 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.6667   2.3333   0.5000   0.8333   1.0000   1.7333   1.0667  -0.6667 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.6667  -0.6667   0.0000  -0.2667  -0.2667   1.9000  -2.3333  -0.5333 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  0.7333  -0.5000  -0.0333   1.2333   1.0000  -1.3333  -0.1667  -0.8333 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.6000   0.1667  -0.2667  -0.1667   0.3333  -2.9333  -1.8333  -0.3333 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.1667  -0.1667   0.3333   0.3333  -1.0000 

Bootstrap residuals:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.7208   0.6825   0.4280   0.0517   1.1282  -1.1762  -5.7917   2.1667 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.7273   1.2982   0.9417   0.5417  -0.5143   2.9688  -1.6250   2.2333 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  1.7083   0.3873  -3.1618   4.8434   2.5404   0.5370  -0.1667  -0.4023 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.7456   2.2604   0.7311   0.5172   1.1857   1.5813   0.7915  -0.8056 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.6992  -0.5784   0.4378  -0.1000   0.0135   2.0189  -2.5692  -0.5846 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  1.2258  -0.2412   0.3539   0.7581   0.6667  -1.3398  -0.2917  -0.7937 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.1984   0.1589  -0.3291   0.0699   0.2731  -2.6708  -1.9782  -0.2802 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.3439  -0.2020   0.3198   0.2907  -0.9872 

> ## Don't show: 
> options(op)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("bootstrap.wa")
> ### * bootstrap.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootstrap.wa
> ### Title: Bootstrap estimation and errors for WA models
> ### Aliases: bootstrap.wa print.bootstrap.wa
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp
> data(ImbrieKipp)
> data(SumSST)
> ik.wa <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+             min.tol = 2, small.tol = "min")
> ik.wa

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## compare actual tolerances to working values
> with(ik.wa, rbind(tolerances, model.tol))
             O.univ  G.cglob  G.ruber  G.tenel  G.saccu  G.rubes   G.pacL
tolerances 3.746359 1.895600 1.909561 2.124799 1.979651 1.968294 3.941352
model.tol  3.746359 2.124799 2.124799 2.124799 2.124799 2.124799 3.941352
             G.pacR G.bullo  G.falco  G.calid  G.aequi  G.gluti  G.duter
tolerances 5.181162 5.82798 3.109193 2.973112 2.561697 5.898256 1.998304
model.tol  5.181162 5.82798 3.109193 2.973112 2.561697 5.898256 2.124799
            G.infla   G.trnL  G.trnR  G.crasf  G.scitu  G.mentu  P.obliq
tolerances 4.723884 4.161704 3.43492 3.354021 3.990673 2.386584 1.554762
model.tol  4.723884 4.161704 3.43492 3.354021 3.990673 2.386584 2.124799
            C.nitid S.dehis  G.digit    Other   G.quin  G.hirsu
tolerances 1.461725 3.84473 3.108881 5.112464 4.268777 3.942135
model.tol  2.124799 3.84473 3.108881 5.112464 4.268777 3.942135
> 
> ## bootstrap the WA model
> ik.boot <- bootstrap(ik.wa, n.boot = 100)
Bootstrap sample 100 
> 
> ## performance statistics
> performance(ik.boot)
   RMSEP       R2 Avg.Bias Max.Bias 
   2.320    0.900   -0.111   -3.331 
> 
> 
> 
> cleanEx()
> nameEx("caterpillarPlot")
> ### * caterpillarPlot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: caterpillarPlot
> ### Title: Caterpillar plot of species' WA optima and tolerance range.
> ### Aliases: caterpillarPlot caterpillarPlot.default
> ###   caterpillarPlot.data.frame caterpillarPlot.wa caterpillar
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> data(SumSST)
> 
> ## default plot
> caterpillar(ImbrieKipp, SumSST)
> 
> ## customisation
> opttol <-
+     caterpillar(ImbrieKipp, SumSST, col = "red2",
+                 bg = "yellow", lcol = "blue",
+                 xlab = expression(Summer ~ Sea ~ Surface ~
+                                  Temperature~(degree*C)))
> 
> ## invisibly returns the optima and tolerances
> head(opttol)
          Optima Tolerance
P.obliq 26.94320  1.554762
G.duter 26.49014  1.998304
C.nitid 26.41005  1.461725
G.rubes 26.27479  1.968294
G.saccu 26.18001  1.979651
G.mentu 26.13778  2.386584
> 
> 
> 
> cleanEx()
> nameEx("chooseTaxa")
> ### * chooseTaxa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: chooseTaxa
> ### Title: Select taxa (variables) on basis of maximum abundance attained
> ###   and number of occurrences.
> ### Aliases: chooseTaxa chooseTaxa.default
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> IK2 <- chooseTaxa(ImbrieKipp, n.occ = 5)
> dim(ImbrieKipp)
[1] 61 27
> dim(IK2)
[1] 61 27
> 
> ## return a logical vector to select species/columns
> chooseTaxa(ImbrieKipp, n.occ = 5, value = FALSE)
 O.univ G.cglob G.ruber G.tenel G.saccu G.rubes  G.pacL  G.pacR G.bullo G.falco 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf G.scitu G.mentu 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
P.obliq C.nitid S.dehis G.digit   Other  G.quin G.hirsu 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
> 
> 
> 
> cleanEx()
> nameEx("cma")
> ### * cma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cma
> ### Title: Close modern analogues
> ### Aliases: cma cma.default cma.analog cma.mat cma.predict.mat print.cma
> ###   plot.cma
> ### Keywords: methods manip hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAP and RLGH reference samples
> (ik.ana <- analog(ImbrieKipp, V12.122, method = "chord"))

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

      0      10      20      30      40      50      60      70      80      90 
0.00103 0.20580 0.24673 0.27418 0.26386 0.34447 0.36276 0.39255 0.37565 0.38941 
    100     110     120     130     140     150     160     170     180     190 
0.42555 0.38787 0.42905 0.39793 0.44159 0.38670 0.38293 0.33502 0.39193 0.40225 
    200     210     220     230     240     250     260     270     280     290 
0.33727 0.36363 0.34381 0.32030 0.33913 0.33152 0.33710 0.40605 0.41771 0.35843 
    300     310     320     330     340     350     360     370     380     390 
0.36563 0.45973 0.42443 0.43737 0.36395 0.39245 0.38022 0.42119 0.38140 0.41874 
    400     410     420     430     440     450     460     470     480     490 
0.34186 0.45068 0.33572 0.40482 0.29348 0.34371 0.35648 0.33792 0.40345 0.36043 
    500     510     520     530     540     550     560     570     580     590 
0.34283 0.43705 0.36927 0.43211 0.43543 0.43002 0.37040 0.35875 0.34271 0.27971 
    600     610     620     630     640     650     660     670     680     690 
0.33571 0.43484 0.49012 0.33567 0.36832 0.34366 0.42574 0.44031 0.47852 0.35294 
    700     710     720     730     740     750     760     770     780     790 
0.40298 0.41467 0.47288 0.50627 0.38976 0.36831 0.39931 0.44974 0.50466 0.35900 
    800     810     820     830     840     850     860     870     880     890 
0.36004 0.37868 0.39429 0.33538 0.36688 0.42206 0.43431 0.42413 0.40355 0.47735 
    900     910     920     930     940     950     960     970     980     990 
0.46549 0.39262 0.40363 0.39642 0.34586 0.43115 0.41340 0.37004 0.34726 0.44592 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.37685 0.48035 0.43378 0.43677 0.46931 0.33997 0.42792 0.42910 0.37678 0.36444 

> 
> ## close modern analogues
> (ik.cma <- cma(ik.ana, cutoff = 0.4))

	Close modern analogues of fossil samples

Call: cma(object = ik.ana, cutoff = 0.4) 

Dissimilarity: chord 

     k: Not supplied

Cutoff: 0.4 

	Number of analogues per fossil sample:

   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
  11    8   12   14   13    3    2    1    4    1    0    1    0    1    0    3 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
   1    8    1    0    5    5    2    4    1    2    6    0    0    2    4    0 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
   0    0    3    2    3    0    3    0    2    0    7    0    4    7    2   14 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
   0    8    5    0    1    0    0    0    2    3    6   11    4    0    0    1 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
   5    3    0    0    0    3    0    0    0    0    1    1    1    0    0    2 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
   2    3    1    1    1    0    0    0    0    0    0    1    0    1    3    0 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
   0    3    1    0    4    0    0    0    0    1    0    0    3    4 

> summary(ik.cma)

	Close modern analogues of fossil samples

Call: cma(object = ik.ana, cutoff = 0.4) 

Dissimilarity: chord 

     k: Not supplied

Cutoff: 0.4 

	Number of analogues per fossil sample:

   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
  11    8   12   14   13    3    2    1    4    1    0    1    0    1    0    3 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
   1    8    1    0    5    5    2    4    1    2    6    0    0    2    4    0 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
   0    0    3    2    3    0    3    0    2    0    7    0    4    7    2   14 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
   0    8    5    0    1    0    0    0    2    3    6   11    4    0    0    1 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
   5    3    0    0    0    3    0    0    0    0    1    1    1    0    0    2 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
   2    3    1    1    1    0    0    0    0    0    0    1    0    1    3    0 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
   0    3    1    0    4    0    0    0    0    1    0    0    3    4 


Distances:

         0    10    20    30    40    50    60    70    80    90 100   110 120
1  0.00103 0.206 0.247 0.274 0.264 0.344 0.363 0.393 0.376 0.389     0.388    
2  0.21926 0.257 0.260 0.276 0.304 0.374 0.394       0.383                    
3  0.22764 0.276 0.317 0.278 0.318 0.393             0.394                    
4  0.25235 0.326 0.323 0.288 0.341                   0.398                    
5  0.30061 0.329 0.325 0.305 0.366                                            
6  0.30975 0.354 0.342 0.314 0.371                                            
7  0.35531 0.360 0.351 0.331 0.375                                            
8  0.35836 0.390 0.352 0.336 0.378                                            
9  0.36781       0.360 0.340 0.379                                            
10 0.37869       0.362 0.343 0.384                                            
11 0.38258       0.362 0.353 0.393                                            
12               0.372 0.376 0.395                                            
13                     0.386 0.398                                            
14                     0.394                                                  
     130 140   150   160   170   180 190   200   210   220   230   240   250
1  0.398     0.387 0.383 0.335 0.392     0.337 0.364 0.344 0.320 0.339 0.332
2            0.393       0.354           0.379 0.377 0.397 0.383       0.384
3            0.399       0.358           0.379 0.382       0.388            
4                        0.359           0.380 0.383       0.389            
5                        0.365           0.394 0.396                        
6                        0.377                                              
7                        0.380                                              
8                        0.389                                              
9                                                                           
10                                                                          
11                                                                          
12                                                                          
13                                                                          
14                                                                          
     260 270 280   290   300 310 320 330   340   350   360 370   380 390   400
1  0.337         0.358 0.366             0.364 0.392 0.380     0.381     0.342
2  0.371         0.377 0.371             0.391 0.399 0.392     0.395     0.350
3  0.372               0.373             0.393       0.396     0.397          
4  0.387               0.394                                                  
5  0.390                                                                      
6  0.398                                                                      
7                                                                             
8                                                                             
9                                                                             
10                                                                            
11                                                                            
12                                                                            
13                                                                            
14                                                                            
   410   420 430   440   450   460   470 480   490   500 510   520 530 540 550
1      0.336     0.293 0.344 0.356 0.338     0.360 0.343     0.369            
2      0.365     0.385 0.357 0.368 0.341     0.369 0.353                      
3      0.369     0.393 0.358       0.352     0.377 0.385                      
4      0.371     0.397 0.372       0.354     0.380 0.386                      
5      0.379           0.374       0.358     0.380 0.387                      
6      0.381           0.378       0.360     0.387                            
7      0.398           0.390       0.361     0.391                            
8                                  0.368     0.399                            
9                                  0.374                                      
10                                 0.380                                      
11                                 0.389                                      
12                                 0.391                                      
13                                 0.394                                      
14                                 0.399                                      
     560   570   580   590   600 610 620   630   640   650 660 670 680   690
1  0.370 0.359 0.343 0.280 0.336         0.336 0.368 0.344             0.353
2  0.381 0.360 0.343 0.342 0.385               0.380 0.367             0.390
3        0.398 0.357 0.344 0.389               0.394 0.396             0.397
4              0.371 0.349 0.396               0.398                        
5              0.372 0.356                     0.399                        
6              0.384 0.360                                                  
7                    0.369                                                  
8                    0.378                                                  
9                    0.392                                                  
10                   0.394                                                  
11                   0.395                                                  
12                                                                          
13                                                                          
14                                                                          
   700 710 720 730  740   750   760 770 780   790   800   810   820   830   840
1                  0.39 0.368 0.399         0.359 0.360 0.379 0.394 0.335 0.367
2                                           0.376 0.383 0.389                  
3                                                       0.400                  
4                                                                              
5                                                                              
6                                                                              
7                                                                              
8                                                                              
9                                                                              
10                                                                             
11                                                                             
12                                                                             
13                                                                             
14                                                                             
   850 860 870 880 890 900   910 920   930   940 950 960   970   980 990  1000
1                          0.393     0.396 0.346         0.370 0.347     0.377
2                                          0.384         0.392           0.380
3                                          0.394         0.396           0.396
4                                                                        0.399
5                                                                             
6                                                                             
7                                                                             
8                                                                             
9                                                                             
10                                                                            
11                                                                            
12                                                                            
13                                                                            
14                                                                            
   1010 1020 1030 1040 1050 1060 1070  1080  1090
1                      0.34           0.377 0.364
2                                     0.391 0.374
3                                     0.396 0.374
4                                           0.375
5                                                
6                                                
7                                                
8                                                
9                                                
10                                               
11                                               
12                                               
13                                               
14                                               

Samples:

         0      10      20      30      40      50       60     70      80
1  V12.122 V12.122 V12.122 V20.230 V22.172 V22.172  V22.172 V10.89 V22.172
2    V14.5 V20.234 V20.234  V14.90 V20.167 V20.167 A153.154        V19.216
3  V20.234   V14.5  V16.21 V22.172 V19.216 V19.216                  V16.21
4   V18.21  V18.21   V14.5   V9.31  V10.89                         V20.167
5  A180.76 A180.76 A180.76  V12.79  V16.21                                
6  A180.72 A180.72 V15.164 V19.216 V22.204                                
7  V15.164 V20.230  V14.90 A180.72 V20.234                                
8   V16.21 V20.167 V20.230 V22.204  V14.90                                
9  V20.167         A180.72 A180.76 V20.230                                
10 V20.230           V9.31 V20.167 V15.164                                
11  V12.79         V20.167 V20.234 A180.72                                
12                  V18.21  V16.21  V12.79                                
13                         V15.164 V12.122                                
14                         V12.122                                        
        90  100   110  120   130  140     150     160      170     180  190
1  V19.216 None V9.31 None V9.31 None  V10.89 V20.167  V20.167 A179.13 None
2                                     V22.172           V10.89             
3                                     V20.167          V20.230             
4                                                       V16.21             
5                                                      V22.172             
6                                                     A153.154             
7                                                       V14.90             
8                                                      A179.13             
9                                                                          
10                                                                         
11                                                                         
12                                                                         
13                                                                         
14                                                                         
       200     210     220     230    240     250     260  270  280     290
1  V20.230  V14.90 V12.122 V12.122 V3.128  V14.90  V14.90 None None V12.122
2  V22.172 V22.172  V14.90  V18.21        V22.204 V20.167            V14.90
3    V9.31  V3.128           V14.5                V22.172                  
4   V14.90 V20.167          V14.90                 V3.128                  
5  V20.167 V12.122                                V12.122                  
6                                                 A180.72                  
7                                                                          
8                                                                          
9                                                                          
10                                                                         
11                                                                         
12                                                                         
13                                                                         
14                                                                         
       300  310  320  330     340     350     360  370     380  390    400  410
1  V22.172 None None None V19.216 V20.230 V20.167 None   V9.31 None  V9.31 None
2  V20.167                V22.172   V9.31 V22.172      V12.122      V14.90     
3  V19.216                 V10.89          V16.21      V20.234                 
4  V15.164                                                                     
5                                                                              
6                                                                              
7                                                                              
8                                                                              
9                                                                              
10                                                                             
11                                                                             
12                                                                             
13                                                                             
14                                                                             
       420  430     440     450     460     470  480     490     500  510
1    V9.31 None   V9.31 A180.76 V20.167 V22.172 None V20.234 V12.122 None
2  V20.234       V14.90 V20.234  V3.128 V20.167       V3.128 V20.234     
3   V14.90      V20.234  V18.21         V20.234      A180.76 A180.76     
4  V20.230      V20.230 V12.122          V3.128      V12.122  V18.21     
5  V22.172              A180.72          V14.90      A180.72 V20.230     
6  V12.122                V14.5         A180.76      V22.204             
7  V20.167              V20.230         V20.230       V18.21             
8                                       A180.72        V14.5             
9                                       V22.204                          
10                                      V19.216                          
11                                       V12.79                          
12                                       V10.89                          
13                                      V15.164                          
14                                        V9.31                          
      520  530  540  550     560     570     580     590     600  610  620
1  V14.90 None None None  V14.90 V20.230  V12.79 V20.167  V14.90 None None
2                        V20.230   V9.31 V22.204 V22.172 A180.72          
3                                A180.78  V14.90  V16.21 A180.76          
4                                        A180.72 V15.164 V22.204          
5                                        V22.172  V10.89                  
6                                        V20.230 V19.216                  
7                                                V20.230                  
8                                                V20.234                  
9                                                 V3.128                  
10                                                V14.90                  
11                                               A180.76                  
12                                                                        
13                                                                        
14                                                                        
      630     640     650  660  670  680     690  700  710  720  730    740
1  V14.90 V12.122 V22.204 None None None A179.13 None None None None V14.90
2          V14.90 V12.122                 V16.21                           
3         V20.234 V20.234                 V10.89                           
4         V20.167                                                          
5           V14.5                                                          
6                                                                          
7                                                                          
8                                                                          
9                                                                          
10                                                                         
11                                                                         
12                                                                         
13                                                                         
14                                                                         
       750     760  770  780     790     800     810    820     830     840
1  V22.204 V20.234 None None  V18.21 V12.122 V12.122 V14.90 V19.216 V19.216
2                            V12.122  V18.21  V14.90                       
3                                            V22.172                       
4                                                                          
5                                                                          
6                                                                          
7                                                                          
8                                                                          
9                                                                          
10                                                                         
11                                                                         
12                                                                         
13                                                                         
14                                                                         
    850  860  870  880  890  900     910  920   930     940  950  960     970
1  None None None None None None V19.216 None V9.31 V19.216 None None   V9.31
2                                                   V20.230           V20.234
3                                                     V9.31           V20.230
4                                                                            
5                                                                            
6                                                                            
7                                                                            
8                                                                            
9                                                                            
10                                                                           
11                                                                           
12                                                                           
13                                                                           
14                                                                           
     980  990    1000 1010 1020 1030 1040    1050 1060 1070    1080    1090
1  V9.31 None V19.216 None None None None V19.216 None None V19.216 V22.172
2              V14.90                                       V12.122 V22.204
3             V22.172                                       V22.172 V19.216
4               V9.31                                                V14.90
5                                                                          
6                                                                          
7                                                                          
8                                                                          
9                                                                          
10                                                                         
11                                                                         
12                                                                         
13                                                                         
14                                                                         
> 
> ## plot the results
> plot(ik.cma)
> 
> 
> 
> 
> cleanEx()
> nameEx("compare")
> ### * compare
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compare
> ### Title: Compare proxies across two data sets
> ### Aliases: compare compare.default
> ### Keywords: methods utility multivariate
> 
> ### ** Examples
> 
> data(ImbrieKipp, V12.122, SumSST)
> compare(ImbrieKipp, V12.122, env = SumSST, ordination = "rda",
+         method = "chord")
     sumMissing sumPoorOpt closestSamp  residLen
0         0.000      0.000    0.012000 100.45045
10        0.000      0.000    8.529093  93.68949
20        0.000      0.000    7.638006 102.65357
30        0.000      0.000    8.463550  94.36188
40        0.000      0.000    9.663726  86.98909
50        0.000      0.000    7.392168 115.05590
60        0.000      0.000    9.275438 116.25167
70        0.000      0.000   10.571795  90.93459
80        0.000      0.000    8.734429 101.79518
90        0.000      0.000   11.819500  66.41931
100       0.000      0.000   13.058024  90.75872
110       0.000      0.000   12.955413  76.22130
120       0.000      0.000   13.539953 101.86032
130       0.000      0.000   13.662558  82.09076
140       0.000      0.000   12.584746  97.65284
150       0.000      0.000   10.447761  91.24652
160       0.000      0.000   12.037393  82.83356
170       0.000      0.000    7.876003 104.24136
180       0.000      0.000   12.011342  73.52761
190       0.000      0.000   13.041428  75.19979
200       0.000      0.000   11.417475  70.78145
210       0.000      0.000   11.680758  78.28107
220       0.505      0.505   12.529115  71.61394
230       0.474      0.474   11.987421  76.91145
240       0.000      0.000   14.560106  71.50722
250       0.524      0.524    8.968296  67.95728
260       0.000      0.000    9.730622  65.99839
270       1.852      1.852   15.471196  52.40059
280       1.724      1.724   11.494284  64.21726
290       0.518      0.518   11.060659  65.95014
300       0.000      0.000   10.989149  73.56314
310       0.495      0.495   16.209571  53.40485
320       0.000      0.000   10.429376  85.12023
330       0.000      0.000   12.834085  58.76064
340       0.000      0.000    9.509660  80.00532
350       0.000      0.000   10.759804  68.15216
360       0.000      0.000    9.792438 100.14946
370       0.000      0.000   12.988550  82.11932
380       0.422      0.422   11.053320  75.59834
390       0.000      0.000   11.639942  82.89610
400       0.467      0.467   11.534389  68.33031
410       0.000      0.000   16.117800  86.12868
420       0.000      0.000   12.000538  92.17843
430       0.966      0.966   13.874994  90.12956
440       0.649      0.649    9.290071  77.43962
450       0.741      0.741   12.651539  69.56042
460       0.000      0.000   11.703433  70.93111
470       0.000      0.000    9.199769  81.02904
480       0.000      0.000   13.288319  84.19877
490       0.000      0.000   13.310766  70.24003
500       0.000      0.000   11.338801  88.21876
510       0.000      0.000   16.103042  62.50156
520       0.000      0.000   12.410907  72.00782
530       0.800      0.800   10.760163 104.10193
540       0.543      0.543   10.537798 118.81702
550       0.000      0.000   15.001980  57.82661
560       0.000      0.000   12.089809  60.42813
570       0.000      0.000   11.901251  63.00525
580       0.000      0.000    8.905415  65.91836
590       0.000      0.000    7.163614 100.44331
600       0.000      0.000    9.920261  57.34470
610       0.000      0.000   12.626147  62.68886
620       1.478      1.478   15.804703  50.49240
630       0.671      0.671    9.083937  61.50670
640       0.000      0.000   10.447087  62.52280
650       0.719      0.719    7.580717  63.97291
660       0.000      0.000   13.105475  72.15673
670       0.617      0.617   11.908596  81.05597
680       3.015      3.015   18.303993  68.18530
690       0.000      0.000   14.075107  94.19586
700       0.000      0.000    9.040768  70.64488
710       0.000      0.000   13.891600  82.54069
720       0.000      0.000   17.267242  67.79611
730       2.174      2.174   18.075823  59.24978
740       0.535      0.535   11.172356  64.33105
750       2.532      2.532    8.318149  58.54683
760       2.050      2.050   12.814697  71.81245
770       1.190      1.190   12.076516 102.97321
780       5.362      5.362   17.215142  65.93209
790       2.602      2.602   13.592633  75.79725
800       2.090      2.090   12.458966  73.72931
810       2.756      2.756    8.233465  64.36360
820       2.106      2.106   14.045793  44.76871
830       3.572      3.572   11.393857  57.17945
840       0.957      0.957   14.823477  73.22605
850       0.858      0.858   14.410403  62.71034
860       0.308      0.308   13.919643  79.81774
870       0.658      0.658   12.176918 110.46588
880       0.000      0.000   12.566806  68.01227
890       0.338      0.338   17.764617  48.44356
900       0.000      0.000   17.639150  68.66176
910       0.000      0.000   13.165412  78.15575
920       0.348      0.348   15.500074  71.20557
930       0.508      0.508   12.372809  65.49108
940       0.985      0.985    9.443816  75.49261
950       0.735      0.735   11.822458  67.80785
960       1.210      1.210    9.979221  85.23819
970       1.493      1.493    8.756228  92.71209
980       0.000      0.000   10.402372  76.72773
990       0.000      0.000   15.001311  62.77688
1000      0.000      0.000   11.129095  63.09277
1010      0.000      0.000   20.910995  51.32021
1020      0.000      0.000   20.008831  48.58420
1030      0.000      0.000   15.203309  58.36180
1040      0.000      0.000   20.616261  64.44215
1050      0.000      0.000   12.067523  60.69368
1060      0.000      0.000   20.582122  49.91944
1070      0.000      0.000   12.403417  63.83094
1080      0.559      0.559   12.839545  60.47983
1090      0.000      0.000   10.295019  62.46006
> 
> 
> 
> cleanEx()
> nameEx("crossval")
> ### * crossval
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: crossval
> ### Title: Cross-validation of palaeoecological transfer function models
> ### Aliases: crossval crossval.wa crossval.pcr print.crossval
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
>      
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## Leave one out CV
> cv.loo <- crossval(mod)
> cv.loo
	Model Cross-validation:

crossval(obj = mod)

Method: LOO

       R2   avgBias maxBias  RMSEP RMSEP2 s1 s2
1 0.90028 -0.013652 -4.5985 2.2179     NA NA NA
> 
> ## k-fold CV (k == 10)
> cv.kfold <- crossval(mod, method = "kfold", kfold = 10, folds = 1)
> cv.kfold
	Model Cross-validation:

crossval(obj = mod, method = "kfold", folds = 1, kfold = 10)

Method: kfold
k: 10
No. of folds: 1

       R2   avgBias maxBias  RMSEP RMSEP2 s1 s2
1 0.90072 0.0079721  -4.546 2.2129     NA NA NA
> 
> ## n k-fold CV (k == 10, n = 10)
> cv.nkfold <- crossval(mod, method = "kfold", kfold = 10, folds = 10)
> cv.nkfold
	Model Cross-validation:

crossval(obj = mod, method = "kfold", folds = 10, kfold = 10)

Method: kfold
k: 10
No. of folds: 10

       R2    avgBias maxBias  RMSEP RMSEP2      s1     s2
1 0.89889 -0.0073197 -4.6658 2.2348 2.2469 0.23308 2.2348
> 
> ## bootstrap with 100 bootstrap samples
> cv.boot <- crossval(mod, method = "bootstrap", nboot = 100)
> cv.boot
	Model Cross-validation:

crossval(obj = mod, method = "bootstrap", nboot = 100)

Method: bootstrap
No. Bootstraps: 100

       R2   avgBias maxBias  RMSEP RMSEP2      s1     s2
1 0.90291 -0.010444 -4.7374 2.1874  2.233 0.44891 2.1874
> 
> ## extract fitted values and residuals
> fitted(cv.boot)
 [1]  4.263551  3.923723  4.224972  4.098484  8.395109  9.345501  3.202920
 [8] 14.737441 14.604240 16.950078 16.008837 18.943018 18.481213 18.693750
[15] 17.377963 20.460129 19.930614 19.795458 18.690883 22.951026 22.424343
[22] 20.689344 22.401353 22.037299 21.421949 23.370649 23.283449 22.836206
[29] 24.246318 25.669263 25.528396 23.194497 23.622950 23.041782 24.493620
[36] 25.353820 25.799074 26.316436 23.981589 25.468649 26.238889 25.817993
[43] 26.686398 26.377013 26.082067 25.658091 25.812896 26.288900 26.788040
[50] 26.687526 26.831227 25.929266 26.785054 26.753988 26.396926 26.033673
[57] 26.531838 27.216142 26.694501 26.924512 26.742249
> resid(cv.boot)
 [1] -2.26355061  1.07627680  1.27502776  2.90151595 -1.39510924  1.15449898
 [7]  7.79708037 -4.73744119 -1.60424031 -4.95007757 -2.00883651 -4.44301791
[13] -3.48121340 -4.19374987 -1.37796269 -2.46012916  0.06938614 -1.79545771
[19]  0.30911658 -4.45102630 -0.92434329  0.31065618 -1.40135267  1.96270116
[25]  2.57805135 -0.37064854  0.71655097  0.16379363 -1.24631811 -1.66926313
[31] -0.52839649  2.80550341  2.37705047  2.95821781  0.50637958  0.64618036
[37]  0.20092618 -1.81643606  3.01841101  0.73135077 -1.23888856  0.68200663
[43] -0.48639767 -0.37701346 -0.08206703  1.34190894  1.18710439  1.21110044
[49]  0.21195967  0.31247446  0.16877316  1.07073436  0.21494608  2.24601152
[55]  2.10307401  1.46632658  0.96816168  0.28385812  0.30549852  0.07548777
[61]  1.25775064
> 
> ## Principal Components Regression
> mpcr <- pcr(SumSST ~., data = ImbrieKipp, ncomp = 10)
> crossval(mpcr, method = "kfold", kfold = 10, folds = 2, ncomp = 10)
	Model Cross-validation:

crossval(obj = mpcr, method = "kfold", ncomp = 10, folds = 2, 
    kfold = 10)

Method: kfold
k: 10
No. of folds: 2

   comp      R2    avgBias maxBias  RMSEP RMSEP2      s1     s2
1     1 0.93163 -0.0398841 -6.4320 2.5535 2.5845 0.39943 2.5535
2     2 0.95163 -0.0352162 -5.3484 2.1571 2.1600 0.11173 2.1571
3     3 0.95510 -0.0368004 -4.3163 2.0802 2.0848 0.13920 2.0802
4     4 0.95529 -0.0378308 -4.3117 2.0759 2.0818 0.15605 2.0759
5     5 0.95744 -0.0126121 -4.7682 2.0264 2.0414 0.24681 2.0264
6     6 0.95525 -0.0018024 -4.5383 2.0781 2.0982 0.29020 2.0781
7     7 0.95551  0.0218264 -4.4729 2.0734 2.0931 0.28659 2.0734
8     8 0.95862  0.0379215 -4.5940 2.0026 2.0256 0.30481 2.0026
9     9 0.95963  0.0258497 -4.6629 1.9776 2.0009 0.30446 1.9776
10   10 0.95916  0.0249025 -4.7799 1.9879 2.0178 0.34623 1.9879
> 
> crossval(mpcr, method = "bootstrap", nboot = 100, ncomp = 10)
	Model Cross-validation:

crossval(obj = mpcr, method = "bootstrap", ncomp = 10, nboot = 100)

Method: bootstrap
No. Bootstraps: 100

   comp      R2    avgBias maxBias  RMSEP RMSEP2      s1     s2
1     1 0.94418 -0.0460352 -6.8379 2.4010 2.7753 1.39187 2.4010
2     2 0.95040 -0.0036791 -5.4513 2.1839 2.2454 0.52212 2.1839
3     3 0.95298 -0.0141687 -4.7205 2.1275 2.2180 0.62703 2.1275
4     4 0.95389 -0.0216536 -4.4754 2.1073 2.2180 0.69198 2.1073
5     5 0.95494 -0.0100841 -5.5123 2.0838 2.2333 0.80331 2.0838
6     6 0.95561 -0.0224437 -5.2969 2.0691 2.2269 0.82340 2.0691
7     7 0.95714  0.0062714 -5.2670 2.0341 2.1970 0.83010 2.0341
8     8 0.95852  0.0139625 -5.1927 2.0027 2.1697 0.83477 2.0027
9     9 0.95918  0.0138066 -5.2351 1.9861 2.1652 0.86243 1.9861
10   10 0.95985  0.0139420 -5.1188 1.9694 2.1620 0.89203 1.9694
> 
> 
> 
> cleanEx()
> nameEx("densityplot.residLen")
> ### * densityplot.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: densityplot.residLen
> ### Title: Lattice density plot for residual lengths
> ### Aliases: densityplot.residLen densityplot
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                 50%   75%   90%   95%   99%
Training Set: 0.8542 1.556 2.454 2.611 3.719
Passive:      1.0039 1.505 1.870 2.171 2.549
> 
> ## plot the density functions of the residual distances
> densityplot(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("dissimilarities")
> ### * dissimilarities
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dissimilarities
> ### Title: Extract dissimilarity coefficients from models
> ### Aliases: dissimilarities dissimilarities.analog dissimilarities.mat
> ###   dissim
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAPImbrie & Kipp and V12.122 core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

      0      10      20      30      40      50      60      70      80      90 
0.00103 0.20580 0.24673 0.27418 0.26386 0.34447 0.36276 0.39255 0.37565 0.38941 
    100     110     120     130     140     150     160     170     180     190 
0.42555 0.38787 0.42905 0.39793 0.44159 0.38670 0.38293 0.33502 0.39193 0.40225 
    200     210     220     230     240     250     260     270     280     290 
0.33727 0.36363 0.34381 0.32030 0.33913 0.33152 0.33710 0.40605 0.41771 0.35843 
    300     310     320     330     340     350     360     370     380     390 
0.36563 0.45973 0.42443 0.43737 0.36395 0.39245 0.38022 0.42119 0.38140 0.41874 
    400     410     420     430     440     450     460     470     480     490 
0.34186 0.45068 0.33572 0.40482 0.29348 0.34371 0.35648 0.33792 0.40345 0.36043 
    500     510     520     530     540     550     560     570     580     590 
0.34283 0.43705 0.36927 0.43211 0.43543 0.43002 0.37040 0.35875 0.34271 0.27971 
    600     610     620     630     640     650     660     670     680     690 
0.33571 0.43484 0.49012 0.33567 0.36832 0.34366 0.42574 0.44031 0.47852 0.35294 
    700     710     720     730     740     750     760     770     780     790 
0.40298 0.41467 0.47288 0.50627 0.38976 0.36831 0.39931 0.44974 0.50466 0.35900 
    800     810     820     830     840     850     860     870     880     890 
0.36004 0.37868 0.39429 0.33538 0.36688 0.42206 0.43431 0.42413 0.40355 0.47735 
    900     910     920     930     940     950     960     970     980     990 
0.46549 0.39262 0.40363 0.39642 0.34586 0.43115 0.41340 0.37004 0.34726 0.44592 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.37685 0.48035 0.43378 0.43677 0.46931 0.33997 0.42792 0.42910 0.37678 0.36444 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    V14.5     V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   A180.76   V12.79    V16.21    V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V22.204   V15.164   V22.219 
   7  V15.164   V20.230   V14.90    A180.72   V20.234   V20.234   V20.167 
   8  V16.21    V20.167   V20.230   V22.204   V14.90    A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V20.230   V20.230   V12.18  
  10  V20.230   V20.7     V9.31     V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V9.31     V14.90    V19.216   V14.90  
  V16.21    V16.21    V22.204   V22.204   V20.230   V22.172   V19.216 
  V14.90    V20.167   V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    V9.31     V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   A153.154  V14.90    V12.79    V20.167   V12.79  
  V20.234   A179.13   V14.90    V16.21    V22.172   A153.154  V22.204 
  V20.167   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V9.31     V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V22.204   V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V22.172 
  V20.230   V20.167   V10.89    V20.230   V14.90    V9.31     V9.31   
  V20.234   V16.21    V9.31     V16.21    V16.21    V14.90    V14.90  
  V14.90    V19.216   V19.216   V22.172   V20.230   V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V10.89    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V16.21  
  V16.21    V15.164   V16.33    V9.31     V15.164   V20.234   V12.79  
  V15.164   V20.230   V22.172   V22.219   V20.234   V16.21    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V3.128    V20.230   V14.5     V12.122   V22.172   V22.172   A180.72 
  V20.167   V18.21    V14.90    V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   V20.234   V18.21    V12.79    V12.122   V12.79  
  V20.230   V14.5     A180.76   V22.172   V12.122   A180.72   V22.204 
  V20.234   V20.234   V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   V14.5     V10.89    V20.234   V18.21  
  A180.76   A180.76   V15.164   A180.72   V9.31     A180.76   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V22.172 
  V12.122   V14.5     V19.216   V14.90    V22.172   V14.90    V10.89  
  V22.204   A180.72   V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V16.190   V14.90    A180.39   V19.308 
  V14.5     V22.172   V20.230   V20.230   V16.21    V16.190   V16.21  
  V20.234   V3.128    V9.31     V16.21    V12.122   V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V9.31     V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V20.167   V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   V22.172   V20.230 
  V14.90    V14.90    V12.122   V20.230   V9.31     A180.76   V9.31   
  V16.21    V20.234   V22.204   A180.76   V14.90    V20.230   V14.90  
  V22.172   V15.164   V20.234   V3.128    V20.234   A180.72   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V16.33    V22.204   V20.167   V19.216   V20.234 
  V15.164   V9.31     V15.164   V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V22.172   V14.90  
  V20.234   V9.31     V14.90    V20.234   V3.128    V20.167   A180.76 
  V14.90    V20.234   V20.234   V18.21    V14.5     V20.234   V22.204 
  V20.230   V14.90    V20.230   V12.122   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   A180.72   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   A180.76   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   V20.230   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V9.31   
  A180.76   V16.21    V19.216   V14.90    V15.164   V19.216   V3.128  
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  V12.122   V18.21    V20.234   V3.128    V16.21    V19.216   V22.172 
  A180.72   V20.230   V20.230   V19.216   V10.89    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.78   V12.122   V22.172   V12.79  
  V14.5     V14.5     V19.216   A180.72   V15.164   V16.21    V9.31   
  V14.90    V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V9.31     V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V12.79    V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V22.204   V22.172   A180.72   V14.90    V20.167 
  V9.31     A180.78   V14.90    V16.21    A180.76   V12.122   V19.216 
  A180.76   V14.90    A180.72   V15.164   V22.204   V22.204   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V12.79    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V3.128    V16.33  
  V20.234   V20.234   V20.234   V14.90    V20.230   A180.72   V20.230 
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  V12.122   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  A180.72   V14.5     V22.172   V22.172   V22.172   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     A180.72   V9.31     V22.172 
  V20.230   V3.128    V20.167   V3.128    V20.230   V22.204   V22.219 
  V20.234   A180.72   V14.5     V16.33    V12.122   V16.190   V22.204 
  V22.172   V18.21    V15.164   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   A180.76   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V22.172   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V12.122   V12.79    V3.128  
  V16.21    V20.234   V3.128    V20.230   V20.234   V22.172   V12.122 
  V19.216   V12.122   V10.89    V20.167   V20.230   V20.230   A180.72 
  V10.89    V22.172   V19.216   V12.122   V12.79    V12.122   V20.167 
  V15.164   V20.230   V20.167   V19.216   V20.167   V9.31     V9.31   
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V20.230 
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V19.216   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V22.204   V16.33  
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V20.167 
  V16.21    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V14.90    V22.172   V3.128    V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   A180.72   A180.72   V12.79    V20.167   V12.122 
  V9.31     A180.72   A180.76   V14.90    V14.5     A180.72   V16.190 
  A180.76   V20.230   V20.234   V16.21    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V12.79    A180.72   V9.31     V20.234 
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V22.172   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V19.216   V9.31     V19.222   V9.31   
  V22.204   V9.31     V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V19.216   V19.216   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V20.167   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V16.190 
  A180.72   A180.76   V15.164   V10.89    V12.79    V22.172   V20.230 
  V9.31     V20.230   V12.18    V16.21    V20.167   V9.31     A180.39 
  V14.90    A180.72   V9.31     V20.230   A180.72   V12.79    V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V16.21    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V14.90    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V9.31     V12.79    V22.172 
  V19.222   V22.172   V22.172   V14.90    V20.230   V16.21    V19.216 
  V12.79    V22.204   V14.90    V22.172   V12.122   V22.172   A180.76 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V12.79    V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V20.167   V20.234   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   A180.72   A179.13   V20.167   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  V22.172   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  A180.76   V12.79    V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V22.204   V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.172   V19.216   V19.216   V12.122   V22.204 
  V22.204   V14.90    V22.172   V22.172   V19.216 
  V14.90    V12.122   V22.204   V14.90    V14.90  
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V9.31   
  V16.33    V20.234   V22.219   V20.234   V20.234 
  V16.190   A180.78   V9.31     V20.230   V16.190 

Dissimilarities for k-closest analogues

   k        0       10       20       30       40       50       60       70
   1  0.00103  0.20580  0.24673  0.27418  0.26386  0.34447  0.36276  0.39255
   2  0.21926  0.25739  0.25996  0.27563  0.30406  0.37446  0.39390  0.40656
   3  0.22764  0.27592  0.31710  0.27790  0.31780  0.39293  0.40903  0.41654
   4  0.25235  0.32554  0.32341  0.28835  0.34085  0.40633  0.42194  0.42589
   5  0.30061  0.32868  0.32481  0.30522  0.36582  0.40641  0.42377  0.43659
   6  0.30975  0.35421  0.34224  0.31439  0.37089  0.41120  0.42844  0.44453
   7  0.35531  0.35967  0.35109  0.33136  0.37495  0.44233  0.42926  0.44877
   8  0.35836  0.38994  0.35184  0.33558  0.37806  0.45328  0.44222  0.44919
   9  0.36781  0.40574  0.35983  0.33957  0.37916  0.45638  0.44358  0.45148
  10  0.37869  0.41747  0.36224  0.34318  0.38376  0.47018  0.44470  0.45326
       80       90      100      110      120      130      140      150
  0.37565  0.38941  0.42555  0.38787  0.42905  0.39793  0.44159  0.38670
  0.38328  0.41811  0.44003  0.43782  0.43414  0.41478  0.44773  0.39272
  0.39373  0.48881  0.44158  0.47585  0.43742  0.41982  0.46543  0.39931
  0.39823  0.49538  0.46032  0.49080  0.45839  0.44633  0.46607  0.41529
  0.40922  0.49652  0.47914  0.50140  0.46151  0.45518  0.49664  0.41958
  0.42514  0.49977  0.48790  0.50324  0.49773  0.47669  0.50303  0.43204
  0.43004  0.50025  0.48857  0.50760  0.51037  0.47858  0.51860  0.44963
  0.43658  0.51154  0.49498  0.52084  0.51151  0.50167  0.52045  0.45103
  0.44513  0.52225  0.50037  0.52443  0.51720  0.50295  0.52303  0.45311
  0.45252  0.52647  0.50246  0.52830  0.51885  0.50685  0.52703  0.46088
      160      170      180      190      200      210      220      230
  0.38293  0.33502  0.39193  0.40225  0.33727  0.36363  0.34381  0.32030
  0.42073  0.35365  0.41730  0.42194  0.37912  0.37707  0.39682  0.38325
  0.42142  0.35801  0.42523  0.42892  0.37923  0.38217  0.40051  0.38838
  0.42358  0.35938  0.44208  0.42991  0.37958  0.38290  0.40217  0.38888
  0.42704  0.36539  0.44270  0.45998  0.39387  0.39557  0.40404  0.40040
  0.43300  0.37745  0.44504  0.47036  0.40623  0.41859  0.40794  0.40209
  0.43541  0.37954  0.44894  0.47164  0.40837  0.42067  0.40832  0.41708
  0.43601  0.38858  0.46754  0.49113  0.41674  0.42769  0.41381  0.42265
  0.43714  0.40494  0.48654  0.50343  0.41835  0.42988  0.42134  0.43017
  0.43951  0.41634  0.51293  0.50538  0.42756  0.43470  0.43477  0.44040
      240      250      260      270      280      290      300      310
  0.33913  0.33152  0.33710  0.40605  0.41771  0.35843  0.36563  0.45973
  0.43491  0.38350  0.37142  0.42917  0.44705  0.37742  0.37086  0.47899
  0.43793  0.40723  0.37189  0.44690  0.44740  0.41176  0.37251  0.48393
  0.44636  0.42500  0.38672  0.45761  0.44923  0.41600  0.39375  0.50345
  0.45073  0.43560  0.39042  0.45814  0.46229  0.41923  0.40068  0.51087
  0.46334  0.43976  0.39826  0.47164  0.46240  0.42384  0.40753  0.53673
  0.47192  0.44086  0.40691  0.47951  0.46816  0.42613  0.40881  0.54013
  0.47705  0.45178  0.42084  0.48167  0.47171  0.45453  0.42049  0.54410
  0.48299  0.45330  0.42890  0.48300  0.48737  0.46290  0.42621  0.54547
  0.48493  0.45447  0.42990  0.49926  0.49628  0.46477  0.42883  0.54979
      320      330      340      350      360      370      380      390
  0.42443  0.43737  0.36395  0.39245  0.38022  0.42119  0.38140  0.41874
  0.43637  0.44053  0.39057  0.39936  0.39218  0.43332  0.39492  0.43403
  0.44000  0.44600  0.39337  0.40290  0.39593  0.43806  0.39738  0.46329
  0.46298  0.44996  0.40433  0.41662  0.40214  0.45921  0.40898  0.47115
  0.46331  0.46518  0.41291  0.42198  0.40240  0.46164  0.42888  0.47265
  0.46597  0.46629  0.43428  0.43209  0.40373  0.46197  0.44031  0.47610
  0.48042  0.47581  0.43880  0.43662  0.41511  0.48247  0.44213  0.47867
  0.48123  0.48338  0.44066  0.44473  0.41555  0.48825  0.45137  0.48915
  0.48617  0.48487  0.44221  0.45851  0.43056  0.49824  0.45198  0.49337
  0.49358  0.48922  0.44471  0.46839  0.43321  0.49865  0.45360  0.49529
      400      410      420      430      440      450      460      470
  0.34186  0.45068  0.33572  0.40482  0.29348  0.34371  0.35648  0.33792
  0.34991  0.45175  0.36469  0.44423  0.38508  0.35718  0.36784  0.34111
  0.41192  0.46582  0.36937  0.45030  0.39283  0.35826  0.41164  0.35165
  0.43330  0.46696  0.37115  0.45228  0.39672  0.37215  0.43668  0.35420
  0.43337  0.46808  0.37852  0.45328  0.43506  0.37371  0.45585  0.35844
  0.43511  0.47270  0.38145  0.45970  0.44118  0.37755  0.45732  0.35976
  0.43513  0.47773  0.39823  0.47916  0.44271  0.38953  0.45870  0.36097
  0.44033  0.48489  0.40172  0.48579  0.44310  0.40641  0.47307  0.36831
  0.44870  0.48657  0.40807  0.49068  0.44708  0.40658  0.47475  0.37386
  0.45318  0.50251  0.41416  0.50332  0.45294  0.41187  0.47622  0.37955
      480      490      500      510      520      530      540      550
  0.40345  0.36043  0.34283  0.43705  0.36927  0.43211  0.43543  0.43002
  0.40441  0.36855  0.35345  0.46671  0.41872  0.44491  0.43957  0.43063
  0.41353  0.37734  0.38501  0.47403  0.43053  0.44512  0.44428  0.43896
  0.41798  0.37964  0.38632  0.47959  0.45074  0.44660  0.45577  0.44389
  0.42943  0.37977  0.38665  0.49918  0.45563  0.44827  0.46556  0.45327
  0.43747  0.38713  0.40339  0.50420  0.46353  0.45752  0.47245  0.47124
  0.44122  0.39121  0.40627  0.51011  0.46961  0.46611  0.47683  0.49380
  0.44847  0.39921  0.41472  0.51385  0.47100  0.46798  0.48757  0.49383
  0.46854  0.40065  0.43965  0.52002  0.47818  0.48314  0.49310  0.50217
  0.47023  0.40443  0.43974  0.52114  0.48214  0.49092  0.49870  0.50396
      560      570      580      590      600      610      620      630
  0.37040  0.35875  0.34271  0.27971  0.33571  0.43484  0.49012  0.33567
  0.38072  0.35951  0.34339  0.34208  0.38491  0.43992  0.49519  0.42507
  0.42074  0.39751  0.35652  0.34407  0.38894  0.44648  0.50221  0.43324
  0.42443  0.40370  0.37124  0.34924  0.39580  0.44674  0.50842  0.43508
  0.42906  0.41337  0.37156  0.35570  0.41571  0.45201  0.51252  0.43625
  0.44200  0.41589  0.38380  0.36003  0.42445  0.46094  0.51440  0.43725
  0.45587  0.42660  0.41861  0.36856  0.42763  0.48917  0.51938  0.44659
  0.45875  0.42973  0.43173  0.37838  0.43509  0.49194  0.53311  0.44729
  0.47266  0.43325  0.43779  0.39153  0.43953  0.49258  0.54249  0.45796
  0.47929  0.43998  0.45290  0.39361  0.44359  0.49889  0.54275  0.47429
      640      650      660      670      680      690      700      710
  0.36832  0.34366  0.42574  0.44031  0.47852  0.35294  0.40298  0.41467
  0.38040  0.36740  0.42849  0.44563  0.49456  0.38960  0.40559  0.44073
  0.39369  0.39622  0.43216  0.46273  0.50097  0.39700  0.43168  0.44906
  0.39814  0.40695  0.43746  0.46699  0.53400  0.40936  0.44151  0.46036
  0.39920  0.42655  0.44064  0.47664  0.53555  0.42450  0.46275  0.47714
  0.41661  0.43192  0.44692  0.47983  0.54447  0.49552  0.48112  0.48072
  0.42091  0.43694  0.45318  0.48334  0.56143  0.50583  0.48306  0.48187
  0.42264  0.44326  0.45852  0.48343  0.57179  0.50801  0.48710  0.49356
  0.42736  0.44996  0.47026  0.49696  0.57843  0.51166  0.48900  0.49472
  0.43567  0.45079  0.48020  0.49727  0.58595  0.51894  0.49570  0.50009
      720      730      740      750      760      770      780      790
  0.47288  0.50627  0.38976  0.36831  0.39931  0.44974  0.50466  0.35900
  0.48088  0.51314  0.40104  0.40076  0.42345  0.45358  0.51282  0.37602
  0.49369  0.52138  0.41910  0.40345  0.43136  0.47755  0.54873  0.41955
  0.50520  0.52530  0.43006  0.42038  0.43481  0.48763  0.55591  0.43657
  0.50607  0.52923  0.43055  0.42832  0.43677  0.48881  0.56285  0.44149
  0.51746  0.53209  0.43311  0.42876  0.43792  0.49011  0.56390  0.44788
  0.53014  0.53550  0.43939  0.43684  0.43856  0.50267  0.57193  0.44868
  0.53168  0.54400  0.43949  0.43941  0.43861  0.50507  0.58244  0.45431
  0.54051  0.56067  0.44196  0.44065  0.45539  0.50910  0.58758  0.45550
  0.54257  0.56119  0.45051  0.45033  0.46033  0.51034  0.58862  0.46583
      800      810      820      830      840      850      860      870
  0.36004  0.37868  0.39429  0.33538  0.36688  0.42206  0.43431  0.42413
  0.38321  0.38887  0.42610  0.42583  0.40565  0.44871  0.45531  0.42431
  0.40486  0.39989  0.42629  0.43253  0.44404  0.45044  0.46005  0.43743
  0.42331  0.40523  0.45518  0.43383  0.45330  0.45122  0.46880  0.44596
  0.43776  0.40622  0.45746  0.45336  0.47275  0.46041  0.46907  0.46783
  0.44750  0.41167  0.46768  0.46708  0.47505  0.46049  0.47745  0.47982
  0.45170  0.41424  0.48039  0.47255  0.48153  0.48548  0.49358  0.48918
  0.45279  0.42337  0.48113  0.47697  0.49428  0.48802  0.49752  0.49125
  0.46725  0.42632  0.50986  0.48376  0.49672  0.48810  0.50827  0.51282
  0.46736  0.43076  0.51092  0.49359  0.50170  0.49491  0.51377  0.51781
      880      890      900      910      920      930      940      950
  0.40355  0.47735  0.46549  0.39262  0.40363  0.39642  0.34586  0.43115
  0.45557  0.50117  0.51492  0.46424  0.48709  0.42105  0.38375  0.43440
  0.47207  0.51009  0.54278  0.46997  0.52705  0.47301  0.39410  0.43534
  0.48705  0.51495  0.54909  0.47603  0.54523  0.48907  0.40882  0.44430
  0.49363  0.51757  0.55462  0.47839  0.54877  0.49890  0.41606  0.44454
  0.49624  0.52245  0.56395  0.49422  0.55045  0.51677  0.42172  0.44704
  0.50072  0.56077  0.57732  0.50829  0.55931  0.51826  0.45078  0.45516
  0.50353  0.56545  0.57862  0.51014  0.56003  0.52177  0.45173  0.46725
  0.51047  0.57039  0.59138  0.51932  0.56395  0.52257  0.46965  0.47445
  0.52602  0.57043  0.59688  0.52392  0.57118  0.53575  0.47191  0.48273
      960      970      980      990     1000     1010     1020     1030
  0.41340  0.37004  0.34726  0.44592  0.37685  0.48035  0.43378  0.43677
  0.41617  0.39179  0.40365  0.46708  0.37994  0.48239  0.50875  0.45307
  0.42197  0.39649  0.41422  0.46999  0.39647  0.51079  0.51194  0.45368
  0.43702  0.40046  0.44031  0.47625  0.39863  0.52011  0.52269  0.45856
  0.43837  0.40837  0.45618  0.48750  0.41329  0.52876  0.52569  0.47290
  0.44038  0.40845  0.45716  0.49802  0.42198  0.54004  0.53390  0.50031
  0.45028  0.40923  0.46432  0.49867  0.45919  0.54191  0.54819  0.52081
  0.45281  0.42071  0.46493  0.51410  0.46491  0.56273  0.54977  0.53488
  0.45948  0.42644  0.47039  0.51686  0.47031  0.56672  0.56705  0.54430
  0.46422  0.42747  0.47740  0.52783  0.47558  0.57032  0.57449  0.54835
     1040     1050     1060     1070     1080     1090
  0.46931  0.33997  0.42792  0.42910  0.37678  0.36444
  0.50089  0.40625  0.43916  0.43215  0.39138  0.37379
  0.53353  0.40803  0.50134  0.45058  0.39631  0.37446
  0.55156  0.40892  0.51540  0.45621  0.40649  0.37467
  0.55601  0.43962  0.51967  0.46166  0.42668  0.42026
  0.56071  0.46096  0.52125  0.47752  0.44332  0.43487
  0.56228  0.46564  0.53512  0.48548  0.44590  0.43999
  0.56837  0.46820  0.53823  0.50018  0.45501  0.44285
  0.57103  0.47784  0.54993  0.51040  0.45627  0.44430
  0.57641  0.48217  0.56053  0.51838  0.45860  0.45217

> 
> ## compare training set dissimilarities with normals
> ## and derive cut-offs
> ik.dij <- dissim(ik.analog)
> plot(ik.dij)
> 
> 
> 
> 
> cleanEx()
> nameEx("distance")
> ### * distance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: distance
> ### Title: Flexibly calculate dissimilarity or distance measures
> ### Aliases: distance distance.default distance.join oldDistance
> ###   oldDistance.default oldDistance.join
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## simple example using dummy data
> train <- data.frame(matrix(abs(runif(200)), ncol = 10))
> rownames(train) <- LETTERS[1:20]
> colnames(train) <- as.character(1:10)
> fossil <- data.frame(matrix(abs(runif(100)), ncol = 10))
> colnames(fossil) <- as.character(1:10)
> rownames(fossil) <- letters[1:10]
> 
> ## calculate distances/dissimilarities between train and fossil
> ## samples
> test <- distance(train, fossil)
> 
> ## using a different coefficient, chi-square distance
> test <- distance(train, fossil, method = "chi.distance")
> 
> ## calculate pairwise distances/dissimilarities for training
> ## set samples
> test2 <- distance(train)
> 
> ## Using distance on an object of class join
> dists <- distance(join(train, fossil))
> str(dists)
 'distance' num [1:20, 1:10] 1.16 1.45 1.17 1.43 1.59 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:20] "A" "B" "C" "D" ...
  ..$ : chr [1:10] "a" "b" "c" "d" ...
 - attr(*, "method")= chr "euclidean"
 - attr(*, "type")= chr "asymmetric"
> 
> ## calculate Gower's general coefficient for mixed data
> ## first, make a couple of variables factors
> 
> ## fossil[,4] <- factor(sample(rep(1:4, length = 10), 10))
> ## train[,4] <- factor(sample(rep(1:4, length = 20), 20))
> ## ## now fit the mixed coefficient
> ## test3 <- distance(train, fossil, "mixed")
> 
> ## ## Example from page 260 of Legendre & Legendre (1998)
> x1 <- t(c(2,2,NA,2,2,4,2,6))
> x2 <- t(c(1,3,3,1,2,2,2,5))
> Rj <- c(1,4,2,4,1,3,2,5) # supplied ranges
> 
> ## 1 - distance(x1, x2, method = "mixed", R = Rj)
> 
> ## note this gives ~0.66 as Legendre & Legendre describe the
> ## coefficient as a similarity coefficient. Hence here we do
> ## 1 - Dij here to get the same answer.
> 
> ## Tortula example from Podani (1999)
> data(tortula)
> Dij <- distance(tortula[, -1], method = "mixed") # col 1 includes Taxon ID
> 
> ## Only one ordered factor
> data(mite.env, package = "vegan")
> Dij <- distance(mite.env, method = "mixed")
> 
> ## Some variables are constant
> data(BCI.env, package = "vegan")
> Dij <- distance(BCI.env, method = "mixed")
> 
> 
> 
> cleanEx()
> nameEx("evenlySampled")
> ### * evenlySampled
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: evenSample
> ### Title: Number of samples per gradient segments
> ### Aliases: evenSample
> ### Keywords: utilities
> 
> ### ** Examples
> 
> data(SumSST)
> ev <- evenSample(SumSST) ## not an even sample...
> plot(ev)
> 
> 
> 
> cleanEx()
> nameEx("fuse")
> ### * fuse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fuse
> ### Title: Fused dissimilarities
> ### Aliases: fuse fuse.matrix fuse.dist
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> train1 <- data.frame(matrix(abs(runif(100)), ncol = 10))
> train2 <- data.frame(matrix(sample(c(0,1), 100, replace = TRUE),
+                      ncol = 10))
> rownames(train1) <- rownames(train2) <- LETTERS[1:10]
> colnames(train1) <- colnames(train2) <- as.character(1:10)
> 
> d1 <- vegdist(train1, method = "bray")
> d2 <- vegdist(train2, method = "jaccard")
> 
> dd <- fuse(d1, d2, weights = c(0.6, 0.4))
> dd
          A         B         C         D         E         F         G
B 0.6741366                                                            
C 0.6821428 0.7638106                                                  
D 0.8685390 0.8634414 0.8075357                                        
E 0.8224894 0.6538099 0.6458443 0.6796898                              
F 0.7965598 0.7630124 0.7031496 0.4841402 0.6346842                    
G 0.8000000 0.8807779 0.6907921 0.6786377 0.6906887 0.5272781          
H 0.6132811 0.7871696 0.5351353 0.7228206 0.6607027 0.6399487 0.6718826
I 0.6210972 0.7686238 0.5374326 0.7366627 0.6290217 0.5180525 0.6037263
J 0.7111374 0.8568535 0.7959756 0.6859347 0.6546886 0.5986896 0.6380316
          H         I
B                    
C                    
D                    
E                    
F                    
G                    
H                    
I 0.6728394          
J 0.7368634 0.6771997
> str(dd)
 'dist' num [1:45] 0.674 0.682 0.869 0.822 0.797 ...
 - attr(*, "Labels")= chr [1:10] "A" "B" "C" "D" ...
 - attr(*, "Size")= int 10
 - attr(*, "Diag")= logi FALSE
 - attr(*, "Upper")= logi FALSE
 - attr(*, "method")= chr "fuse"
 - attr(*, "weights")= num [1:2] 0.6 0.4
 - attr(*, "call")= language fuse.dist(d1, d2, weights = c(0.6, 0.4))
> 
> 
> 
> cleanEx()
> nameEx("getK")
> ### * getK
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getK
> ### Title: Extract and set the number of analogues
> ### Aliases: getK getK.default getK.mat getK.bootstrap.mat getK.predict.mat
> ###   setK<- setK<-.default setK<-.mat
> ### Keywords: utilities manip
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit a MAT model
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> 
> ## How many analogues gives lowest RMSE?
> getK(ik.mat)
[1] 3
attr(,"auto")
[1] TRUE
attr(,"weighted")
[1] FALSE
> ## note that this value was chosen automatically
> 
> ## Now set k to be 10
> setK(ik.mat) <- 10
> 
> ## check
> getK(ik.mat)
[1] 10
attr(,"auto")
[1] FALSE
attr(,"weighted")
[1] FALSE
> 
> 
> 
> 
> cleanEx()
> nameEx("gradientDist")
> ### * gradientDist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gradientDist
> ### Title: Positions of samples along a unit-length ordination gradient.
> ### Aliases: gradientDist gradientDist.default gradientDist.cca
> ###   gradientDist.prcurve
> ### Keywords: multivariate utility
> 
> ### ** Examples
> 
> 
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit PCA
> aber.pca <- rda(abernethy2)
> 
> ## Distance along the first PCA axis
> gradientDist(aber.pca)
 [1] 0.34172583 0.30240442 0.11451277 0.16889765 0.00000000 0.07556094
 [7] 0.15850388 0.15179676 0.34544036 0.33863684 0.37796456 0.35447305
[13] 0.37725714 0.43590145 0.52614525 0.83212029 0.91442163 0.94000421
[19] 0.94470578 0.95980762 0.96907601 0.96296241 0.99047280 0.98153216
[25] 0.96405261 1.00000000 0.97592084 0.95435245 0.97401520 0.91746396
[31] 0.94109965 0.88969437 0.80369973 0.75290552 0.71033293 0.72969928
[37] 0.71642084 0.75419351 0.74347844 0.77265593 0.75973303 0.81801884
[43] 0.86196277 0.82424335 0.81704433 0.74625922 0.73571176 0.69173333
[49] 0.71982710
attr(,"class")
[1] "gradientDist"
> 
> 
> 
> cleanEx()
> nameEx("hist.residLen")
> ### * hist.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: hist.residLen
> ### Title: Histogram plot for residual lengths
> ### Aliases: hist.residLen
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                 50%   75%   90%   95%   99%
Training Set: 0.8542 1.556 2.454 2.611 3.719
Passive:      1.0039 1.505 1.870 2.171 2.549
> 
> ## plot a histogram of the residual distances
> hist(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("histogram.residLen")
> ### * histogram.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: histogram.residLen
> ### Title: Lattice histogram plot for residual lengths
> ### Aliases: histogram.residLen histogram
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                 50%   75%   90%   95%   99%
Training Set: 0.8542 1.556 2.454 2.611 3.719
Passive:      1.0039 1.505 1.870 2.171 2.549
> 
> ## plot a histogram of the residual distances
> histogram(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("join")
> ### * join
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: join
> ### Title: Merge species data sets on common columns (species)
> ### Aliases: join head.join tail.join
> ### Keywords: multivariate manip
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## merge training and test set using left join
> head(join(swapdiat, rlgh, verbose = TRUE, type = "left"))

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  277
Merged:      268  277

$swapdiat
       AC001A AC002A AC004A AC013A AC014A AC014B AC014C AC017A AC018A AC019A
1.21        0      0      0 0.0019      0      0 0.0057 0.0096      0 0.0000
10.21       0      0      0 0.0406      0      0 0.0101 0.0000      0 0.0118
11          0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0000
113.21      0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0000
115.11      0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0031
12.11       0      0      0 0.0000      0      0 0.0403 0.0000      0 0.0000
       AC022A AC025A AC028A AC029A AC030A AC034A AC035A AC039A AC042A AC044A
1.21   0.0631 0.0000      0 0.0000      0      0      0      0      0 0.0076
10.21  0.0000 0.0000      0 0.0017      0      0      0      0      0 0.0000
11     0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
113.21 0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
115.11 0.0000 0.0016      0 0.0000      0      0      0      0      0 0.0000
12.11  0.1194 0.0000      0 0.0000      0      0      0      0      0 0.0045
       AC046A AC048A AC9964 AC9965 AC9968 AC9969 AC9975 AC9996 AM001A AM001B
1.21        0      0      0      0      0      0      0      0 0.0000      0
10.21       0      0      0      0      0      0      0      0 0.0000      0
11          0      0      0      0      0      0      0      0 0.0000      0
113.21      0      0      0      0      0      0      0      0 0.0142      0
115.11      0      0      0      0      0      0      0      0 0.0000      0
12.11       0      0      0      0      0      0      0      0 0.0000      0
       AM001D AS001A AS003A AT001A AU001C AU002A AU003B AU003D AU004A AU004B
1.21        0      0 0.0019 0.0000      0      0      0      0 0.0000      0
10.21       0      0 0.0000 0.0000      0      0      0      0 0.0000      0
11          0      0 0.0000 0.0040      0      0      0      0 0.0000      0
113.21      0      0 0.0000 0.0000      0      0      0      0 0.0000      0
115.11      0      0 0.0000 0.0016      0      0      0      0 0.0313      0
12.11       0      0 0.0000 0.0000      0      0      0      0 0.0000      0
       AU004C AU004D AU005A AU005B AU005D AU005E AU005J AU005L AU009A AU009B
1.21        0      0 0.0000      0      0 0.0000      0      0      0      0
10.21       0      0 0.0000      0      0 0.0000      0      0      0      0
11          0      0 0.0000      0      0 0.0000      0      0      0      0
113.21      0      0 0.0000      0      0 0.0000      0      0      0      0
115.11      0      0 0.0016      0      0 0.0110      0      0      0      0
12.11       0      0 0.0298      0      0 0.0776      0      0      0      0
       AU010A AU010B AU014A AU022A AU023A AU9983 AU9984 AU9987 AU9988 BR001A
1.21        0      0      0      0      0      0      0      0      0 0.0115
10.21       0      0      0      0      0      0      0      0      0 0.2149
11          0      0      0      0      0      0      0      0      0 0.0020
113.21      0      0      0      0      0      0      0      0      0 0.2131
115.11      0      0      0      0      0      0      0      0      0 0.0579
12.11       0      0      0      0      0      0      0      0      0 0.0060
       BR003A BR004A BR005A BR006A BR9997 CA018A CC001A CM004A CM010A CM013A
1.21   0.0000 0.0019      0 0.0287  0.000      0      0 0.0000 0.0096      0
10.21  0.0000 0.0034      0 0.0846  0.000      0      0 0.0000 0.0085      0
11     0.0299 0.0140      0 0.0798  0.022      0      0 0.0000 0.0140      0
113.21 0.0000 0.0057      0 0.0000  0.000      0      0 0.0000 0.0426      0
115.11 0.0141 0.0078      0 0.0438  0.000      0      0 0.0047 0.0078      0
12.11  0.0015 0.0000      0 0.0254  0.000      0      0 0.0060 0.0000      0
       CM014A CM015A CM015B CM017A CM020A CM031A CM031C CM038A CM048A CM050A
1.21        0 0.0000      0 0.0019      0 0.0000 0.0000 0.0000 0.0000      0
10.21       0 0.0051      0 0.0051      0 0.0000 0.0101 0.0000 0.0000      0
11          0 0.0000      0 0.0120      0 0.0000 0.0000 0.0000 0.0000      0
113.21      0 0.0455      0 0.0028      0 0.0142 0.0000 0.0057 0.0057      0
115.11      0 0.0000      0 0.0016      0 0.0000 0.0000 0.0000 0.0329      0
12.11       0 0.0000      0 0.0119      0 0.0000 0.0239 0.0000 0.0060      0
       CM051A CM052A CM101B CM9989 CM9995 CO001A CO001B CY001A CY002A CY003A
1.21        0      0      0      0      0      0      0      0      0      0
10.21       0      0      0      0      0      0      0      0      0      0
11          0      0      0      0      0      0      0      0      0      0
113.21      0      0      0      0      0      0      0      0      0      0
115.11      0      0      0      0      0      0      0      0      0      0
12.11       0      0      0      0      0      0      0      0      0      0
       CY004A CY007A CY010A CY013A CY9991 DE001A DT002A DT003A DT004B EU002A
1.21        0      0      0      0 0.0000      0      0      0      0 0.0000
10.21       0      0      0      0 0.0778      0      0      0      0 0.0051
11          0      0      0      0 0.0000      0      0      0      0 0.0000
113.21      0      0      0      0 0.0000      0      0      0      0 0.0000
115.11      0      0      0      0 0.0391      0      0      0      0 0.0000
12.11       0      0      0      0 0.0493      0      0      0      0 0.0000
       EU002B EU002D EU002E EU002K EU003A EU004A EU009A EU009C EU011A EU013A
1.21   0.0153      0      0 0.0076 0.0019 0.0229 0.0325      0  0.000  0.000
10.21  0.0051      0      0 0.0000 0.0017 0.0220 0.0169      0  0.000  0.000
11     0.0000      0      0 0.0000 0.0000 0.0000 0.0080      0  0.018  0.000
113.21 0.0085      0      0 0.0000 0.0000 0.0142 0.0142      0  0.000  0.000
115.11 0.0047      0      0 0.0000 0.0000 0.0282 0.0078      0  0.000  0.000
12.11  0.0000      0      0 0.0000 0.0000 0.0000 0.0463      0  0.000  0.003
       EU014A EU015A EU016A EU017A EU019A EU020A EU021A EU022A EU025A EU027A
1.21    0.000 0.0019      0 0.0019  0.000 0.0057      0      0      0 0.0019
10.21   0.000 0.0000      0 0.0000  0.000 0.0085      0      0      0 0.0000
11      0.002 0.0000      0 0.0000  0.004 0.0020      0      0      0 0.0000
113.21  0.000 0.0000      0 0.0085  0.000 0.0142      0      0      0 0.0000
115.11  0.000 0.0047      0 0.0000  0.000 0.0219      0      0      0 0.0000
12.11   0.000 0.0000      0 0.0000  0.000 0.0104      0      0      0 0.0000
       EU028A EU028B EU031A EU034A EU039A EU040A EU046C EU047A EU048A EU049A
1.21   0.0306      0  0.000      0 0.0019      0      0 0.0880 0.0401 0.0000
10.21  0.0000      0  0.000      0 0.0000      0      0 0.0288 0.0068 0.0000
11     0.0000      0  0.002      0 0.0000      0      0 0.0120 0.0140 0.0000
113.21 0.0000      0  0.000      0 0.0000      0      0 0.0085 0.0000 0.0057
115.11 0.0000      0  0.000      0 0.0047      0      0 0.0250 0.0125 0.0000
12.11  0.0000      0  0.000      0 0.0179      0      0 0.0284 0.0627 0.0000
       EU049B EU051A EU051B EU056A EU057A EU058A EU9961 EU9962 EU9965 EU9969
1.21        0 0.0019      0      0  0.000      0      0      0      0      0
10.21       0 0.0017      0      0  0.000      0      0      0      0      0
11          0 0.0020      0      0  0.002      0      0      0      0      0
113.21      0 0.0085      0      0  0.000      0      0      0      0      0
115.11      0 0.0000      0      0  0.000      0      0      0      0      0
12.11       0 0.0000      0      0  0.000      0      0      0      0      0
       FR001A FR001B FR002A FR002C FR005A FR005D FR006A FR007A FR008A FR009F
1.21        0      0      0      0      0 0.0057      0      0      0      0
10.21       0      0      0      0      0 0.0457      0      0      0      0
11          0      0      0      0      0 0.0000      0      0      0      0
113.21      0      0      0      0      0 0.0114      0      0      0      0
115.11      0      0      0      0      0 0.0031      0      0      0      0
12.11       0      0      0      0      0 0.0000      0      0      0      0
       FR010A FR011A FR015A FR018A FR9991 FU002A FU002B FU002F GO003A GO004A
1.21        0      0 0.0076      0 0.0038 0.0076 0.0535      0 0.0000 0.0000
10.21       0      0 0.0000      0 0.0000 0.0271 0.1049      0 0.0000 0.0051
11          0      0 0.0000      0 0.0000 0.0938 0.3253      0 0.0000 0.0000
113.21      0      0 0.0000      0 0.0000 0.0085 0.0625      0 0.0057 0.0000
115.11      0      0 0.0000      0 0.0000 0.0689 0.1878      0 0.0000 0.0000
12.11       0      0 0.0000      0 0.0000 0.0060 0.0597      0 0.0000 0.0000
       GO006C GO013A GO023A GO025B GO025F GY005A HN001A ME019A NA002A NA003A
1.21        0 0.0019      0      0      0      0      0      0      0  0.000
10.21       0 0.0000      0      0      0      0      0      0      0  0.044
11          0 0.0000      0      0      0      0      0      0      0  0.000
113.21      0 0.0000      0      0      0      0      0      0      0  0.000
115.11      0 0.0000      0      0      0      0      0      0      0  0.000
12.11       0 0.0000      0      0      0      0      0      0      0  0.000
       NA003B NA005A NA005B NA006A NA006B NA007A NA008A NA013A NA014A NA015A
1.21        0      0      0 0.0096      0      0      0      0 0.0000      0
10.21       0      0      0 0.0000      0      0      0      0 0.0000      0
11          0      0      0 0.0160      0      0      0      0 0.0000      0
113.21      0      0      0 0.0085      0      0      0      0 0.0000      0
115.11      0      0      0 0.0031      0      0      0      0 0.0016      0
12.11       0      0      0 0.0060      0      0      0      0 0.0000      0
       NA016A NA032A NA033A NA037A NA038A NA042A NA043A NA044A NA045A NA046A
1.21        0 0.0000 0.0019      0 0.0076 0.0000      0 0.0000      0      0
10.21       0 0.0000 0.0000      0 0.0000 0.0000      0 0.0034      0      0
11          0 0.0000 0.0220      0 0.0000 0.0000      0 0.0000      0      0
113.21      0 0.0171 0.0000      0 0.0000 0.0341      0 0.0000      0      0
115.11      0 0.0063 0.0000      0 0.0000 0.0000      0 0.0016      0      0
12.11       0 0.0000 0.0000      0 0.0000 0.0000      0 0.0701      0      0
       NA048A NA063A NA068A NA084A NA086A NA099A NA101A NA102A NA112D NA113A
1.21   0.0019      0      0      0      0  0.000      0      0      0      0
10.21  0.0000      0      0      0      0  0.000      0      0      0      0
11     0.0000      0      0      0      0  0.004      0      0      0      0
113.21 0.0000      0      0      0      0  0.000      0      0      0      0
115.11 0.0000      0      0      0      0  0.000      0      0      0      0
12.11  0.0000      0      0      0      0  0.000      0      0      0      0
       NA114A NA115A NA129A NA133A NA135A NA140A NA149A NA151A NA156A NA158A
1.21        0      0      0      0 0.0000 0.0153      0      0 0.0994      0
10.21       0      0      0      0 0.0051 0.0000      0      0 0.0000      0
11          0      0      0      0 0.0000 0.0120      0      0 0.0439      0
113.21      0      0      0      0 0.0000 0.0000      0      0 0.0142      0
115.11      0      0      0      0 0.0000 0.0000      0      0 0.0203      0
12.11       0      0      0      0 0.0000 0.0000      0      0 0.0015      0
       NA160A NA167A NA170A NA9904 NA9919 NA9955 NA9963 NA9964 NE003A NE003B
1.21   0.0000 0.0153      0      0      0      0      0      0 0.0000 0.0038
10.21  0.0017 0.0338      0      0      0      0      0      0 0.0051 0.0000
11     0.0000 0.0479      0      0      0      0      0      0 0.0080 0.0000
113.21 0.0000 0.0341      0      0      0      0      0      0 0.0028 0.0000
115.11 0.0000 0.0297      0      0      0      0      0      0 0.0016 0.0000
12.11  0.0000 0.0000      0      0      0      0      0      0 0.0000 0.0000
       NE003C NE004A NE012A NE020A NE023A NI002A NI005A NI008A NI009A NI009B
1.21        0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0000 0.0000
10.21       0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0068 0.0000
11          0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0000 0.0000
113.21      0 0.0028      0 0.0028      0 0.0114      0 0.0028 0.0227 0.0171
115.11      0 0.0000      0 0.0000      0 0.0000      0 0.0031 0.0000 0.0125
12.11       0 0.0000      0 0.0090      0 0.0000      0 0.0000 0.0030 0.0000
       NI017A NI021A NI026A NI027A NI152A NI9984 OP001A PE002A PI005A PI007A
1.21   0.0000 0.0000      0 0.0000 0.0000      0      0 0.0038 0.0000      0
10.21  0.0017 0.0000      0 0.0000 0.0101      0      0 0.0152 0.0000      0
11     0.0000 0.0000      0 0.0000 0.0000      0      0 0.0040 0.0000      0
113.21 0.0000 0.0171      0 0.0114 0.0000      0      0 0.0000 0.0000      0
115.11 0.0000 0.0047      0 0.0000 0.0000      0      0 0.0000 0.0047      0
12.11  0.0000 0.0000      0 0.0000 0.0000      0      0 0.0119 0.0000      0
       PI011A PI014A PI015A PI016A PI018A PI018B PI022B PI023A PI055A PI056A
1.21   0.0000 0.0000 0.0000      0 0.0019      0 0.0057      0      0  0.000
10.21  0.0000 0.0000 0.0000      0 0.0118      0 0.0000      0      0  0.000
11     0.0020 0.0000 0.0020      0 0.0080      0 0.0000      0      0  0.006
113.21 0.0000 0.0284 0.0000      0 0.0000      0 0.0000      0      0  0.000
115.11 0.0078 0.0000 0.0078      0 0.0000      0 0.0000      0      0  0.000
12.11  0.0000 0.0000 0.0045      0 0.0119      0 0.0239      0      0  0.000
       PI139A PI164A RH006B SA001A SA001B SA006A SA042A SE001A SP002A ST004A
1.21        0 0.0115      0 0.0000      0      0 0.0000 0.0344 0.0000      0
10.21       0 0.0000      0 0.0000      0      0 0.0000 0.0000 0.0000      0
11          0 0.0000      0 0.0000      0      0 0.0000 0.0299 0.0040      0
113.21      0 0.0114      0 0.0028      0      0 0.0000 0.0000 0.0000      0
115.11      0 0.0000      0 0.0016      0      0 0.0047 0.0094 0.0016      0
12.11       0 0.0000      0 0.0000      0      0 0.0015 0.0015 0.0000      0
       ST010A SU002A SU004A SU005A SU006A SY002A SY003A SY004A SY009A SY010A
1.21        0      0      0 0.0019 0.0038      0      0      0 0.0000 0.0000
10.21       0      0      0 0.0068 0.0051      0      0      0 0.0017 0.0000
11          0      0      0 0.0000 0.0040      0      0      0 0.0000 0.0000
113.21      0      0      0 0.0000 0.0000      0      0      0 0.0000 0.0028
115.11      0      0      0 0.0016 0.0047      0      0      0 0.0000 0.0000
12.11       0      0      0 0.0030 0.0075      0      0      0 0.0000 0.0000
       SY013A SY043A TA001A TA002A TA003A TA004A TA9996
1.21        0 0.0000 0.0096      0 0.1128 0.0249      0
10.21       0 0.0068 0.0372      0 0.0000 0.0034      0
11          0 0.0000 0.0140      0 0.0080 0.0419      0
113.21      0 0.0000 0.0739      0 0.0000 0.0000      0
115.11      0 0.0000 0.0266      0 0.0000 0.0000      0
12.11       0 0.0000 0.0239      0 0.0015 0.0000      0

$rlgh
      AC001A AC002A AC004A AC013A AC014A AC014B AC014C AC017A AC018A AC019A
000.3      0      0 0.0000 0.0086 0.0017      0      0      0      0      0
000.8      0      0 0.0038 0.0038 0.0000      0      0      0      0      0
001.3      0      0 0.0000 0.0055 0.0055      0      0      0      0      0
001.8      0      0 0.0000 0.0018 0.0036      0      0      0      0      0
002.3      0      0 0.0037 0.0000 0.0019      0      0      0      0      0
002.8      0      0 0.0000 0.0091 0.0000      0      0      0      0      0
      AC022A AC025A AC028A AC029A AC030A AC034A AC035A AC039A AC042A AC044A
000.3 0.0189 0.0000      0      0      0      0      0      0      0      0
000.8 0.0250 0.0000      0      0      0      0      0      0      0      0
001.3 0.0148 0.0018      0      0      0      0      0      0      0      0
001.8 0.0089 0.0000      0      0      0      0      0      0      0      0
002.3 0.0318 0.0000      0      0      0      0      0      0      0      0
002.8 0.0145 0.0018      0      0      0      0      0      0      0      0
      AC046A AC048A AC9964 AC9965 AC9968 AC9969 AC9975 AC9996 AM001A AM001B
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      AM001D AS001A AS003A AT001A AU001C AU002A AU003B AU003D AU004A AU004B
000.3      0      0      0      0      0      0      0      0 0.0000      0
000.8      0      0      0      0      0      0      0      0 0.0000      0
001.3      0      0      0      0      0      0      0      0 0.0000      0
001.8      0      0      0      0      0      0      0      0 0.0053      0
002.3      0      0      0      0      0      0      0      0 0.0019      0
002.8      0      0      0      0      0      0      0      0 0.0018      0
      AU004C AU004D AU005A AU005B AU005D AU005E AU005J AU005L AU009A AU009B
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      AU010A AU010B AU014A AU022A AU023A AU9983 AU9984 AU9987 AU9988 BR001A
000.3 0.0154      0      0      0      0      0      0      0 0.0069 0.0274
000.8 0.0134      0      0      0      0      0      0      0 0.0000 0.0307
001.3 0.0074      0      0      0      0      0      0      0 0.0037 0.0203
001.8 0.0160      0      0      0      0      0      0      0 0.0018 0.0391
002.3 0.0037      0      0      0      0      0      0      0 0.0169 0.0262
002.8 0.0109      0      0      0      0      0      0      0 0.0000 0.0181
      BR003A BR004A BR005A BR006A BR9997 CA018A CC001A CM004A CM010A CM013A
000.3 0.0000      0      0 0.0515 0.0069      0      0 0.0034 0.0086      0
000.8 0.0038      0      0 0.0768 0.0019      0      0 0.0000 0.0096      0
001.3 0.0037      0      0 0.0425 0.0037      0      0 0.0000 0.0018      0
001.8 0.0018      0      0 0.0196 0.0000      0      0 0.0000 0.0018      0
002.3 0.0037      0      0 0.0356 0.0000      0      0 0.0000 0.0056      0
002.8 0.0036      0      0 0.0381 0.0000      0      0 0.0000 0.0054      0
      CM014A CM015A CM015B CM017A CM020A CM031A CM031C CM038A CM048A CM050A
000.3 0.0034      0      0 0.0034 0.0120      0      0      0 0.0000      0
000.8 0.0038      0      0 0.0058 0.0000      0      0      0 0.0038      0
001.3 0.0074      0      0 0.0185 0.0000      0      0      0 0.0037      0
001.8 0.0089      0      0 0.0036 0.0000      0      0      0 0.0107      0
002.3 0.0112      0      0 0.0000 0.0112      0      0      0 0.0094      0
002.8 0.0073      0      0 0.0000 0.0000      0      0      0 0.0036      0
      CM051A CM052A CM101B CM9989 CM9995 CO001A CO001B CY001A CY002A CY003A
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      CY004A CY007A CY010A CY013A CY9991 DE001A DT002A DT003A DT004B EU002A
000.3      0      0      0      0 0.0069      0      0      0      0 0.0017
000.8      0      0      0      0 0.0000      0      0      0      0 0.0038
001.3      0      0      0      0 0.0000      0      0      0      0 0.0018
001.8      0      0      0      0 0.0018      0      0      0      0 0.0018
002.3      0      0      0      0 0.0000      0      0      0      0 0.0019
002.8      0      0      0      0 0.0018      0      0      0      0 0.0036
      EU002B EU002D EU002E EU002K EU003A EU004A EU009A EU009C EU011A EU013A
000.3 0.0429      0 0.0051 0.0000 0.0000 0.0154 0.0172      0 0.0000      0
000.8 0.0384      0 0.0019 0.0019 0.0019 0.0038 0.0134      0 0.0000      0
001.3 0.0444      0 0.0000 0.0037 0.0000 0.0111 0.0203      0 0.0018      0
001.8 0.0302      0 0.0053 0.0000 0.0018 0.0089 0.0125      0 0.0036      0
002.3 0.0243      0 0.0037 0.0019 0.0000 0.0094 0.0131      0 0.0037      0
002.8 0.0254      0 0.0018 0.0018 0.0000 0.0200 0.0109      0 0.0000      0
      EU014A EU015A EU016A EU017A EU019A EU020A EU021A EU022A EU025A EU027A
000.3 0.0034 0.0000 0.0017 0.0000 0.0000 0.0051 0.0000      0      0      0
000.8 0.0077 0.0096 0.0038 0.0000 0.0000 0.0000 0.0000      0      0      0
001.3 0.0055 0.0055 0.0000 0.0000 0.0000 0.0018 0.0000      0      0      0
001.8 0.0071 0.0018 0.0036 0.0000 0.0018 0.0000 0.0000      0      0      0
002.3 0.0019 0.0037 0.0019 0.0000 0.0000 0.0037 0.0000      0      0      0
002.8 0.0000 0.0127 0.0000 0.0018 0.0000 0.0000 0.0036      0      0      0
      EU028A EU028B EU031A EU034A EU039A EU040A EU046C EU047A EU048A EU049A
000.3      0      0      0      0      0      0      0 0.1235 0.0309 0.0051
000.8      0      0      0      0      0      0      0 0.1228 0.0307 0.0019
001.3      0      0      0      0      0      0      0 0.1128 0.0203 0.0018
001.8      0      0      0      0      0      0      0 0.1281 0.0374 0.0018
002.3      0      0      0      0      0      0      0 0.1236 0.0318 0.0000
002.8      0      0      0      0      0      0      0 0.1180 0.0635 0.0000
      EU049B EU051A EU051B EU056A EU057A EU058A EU9961 EU9962 EU9965 EU9969
000.3 0.0000 0.0000      0      0      0      0      0      0      0      0
000.8 0.0000 0.0000      0      0      0      0      0      0      0      0
001.3 0.0000 0.0018      0      0      0      0      0      0      0      0
001.8 0.0000 0.0018      0      0      0      0      0      0      0      0
002.3 0.0000 0.0019      0      0      0      0      0      0      0      0
002.8 0.0018 0.0073      0      0      0      0      0      0      0      0
      FR001A FR001B FR002A FR002C FR005A FR005D FR006A FR007A FR008A FR009F
000.3      0      0      0      0      0 0.0292      0      0      0      0
000.8      0      0      0      0      0 0.0211      0      0      0      0
001.3      0      0      0      0      0 0.0203      0      0      0      0
001.8      0      0      0      0      0 0.0178      0      0      0      0
002.3      0      0      0      0      0 0.0187      0      0      0      0
002.8      0      0      0      0      0 0.0127      0      0      0      0
      FR010A FR011A FR015A FR018A FR9991 FU002A FU002B FU002F GO003A GO004A
000.3      0      0      0      0      0 0.0172 0.0738      0      0 0.0017
000.8      0      0      0      0      0 0.0326 0.0480      0      0 0.0000
001.3      0      0      0      0      0 0.0370 0.0702      0      0 0.0000
001.8      0      0      0      0      0 0.0445 0.0801      0      0 0.0000
002.3      0      0      0      0      0 0.0300 0.0674      0      0 0.0000
002.8      0      0      0      0      0 0.0363 0.0744      0      0 0.0000
      GO006C GO013A GO023A GO025B GO025F GY005A HN001A ME019A NA002A NA003A
000.3      0 0.0017      0      0      0      0      0      0      0      0
000.8      0 0.0000      0      0      0      0      0      0      0      0
001.3      0 0.0000      0      0      0      0      0      0      0      0
001.8      0 0.0000      0      0      0      0      0      0      0      0
002.3      0 0.0000      0      0      0      0      0      0      0      0
002.8      0 0.0000      0      0      0      0      0      0      0      0
      NA003B NA005A NA005B NA006A NA006B NA007A NA008A NA013A NA014A NA015A
000.3 0.0034 0.0017      0 0.0000      0      0      0      0      0 0.0017
000.8 0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
001.3 0.0000 0.0000      0 0.0055      0      0      0      0      0 0.0000
001.8 0.0000 0.0018      0 0.0107      0      0      0      0      0 0.0000
002.3 0.0037 0.0019      0 0.0112      0      0      0      0      0 0.0000
002.8 0.0000 0.0000      0 0.0018      0      0      0      0      0 0.0000
      NA016A NA032A NA033A NA037A NA038A NA042A NA043A NA044A NA045A NA046A
000.3      0 0.0034      0 0.0240      0      0      0      0 0.0051      0
000.8      0 0.0058      0 0.0000      0      0      0      0 0.0000      0
001.3      0 0.0037      0 0.0037      0      0      0      0 0.0000      0
001.8      0 0.0018      0 0.0071      0      0      0      0 0.0000      0
002.3      0 0.0019      0 0.0000      0      0      0      0 0.0000      0
002.8      0 0.0018      0 0.0109      0      0      0      0 0.0000      0
      NA048A NA063A NA068A NA084A NA086A NA099A NA101A NA102A NA112D NA113A
000.3      0      0 0.0034      0      0 0.0000      0      0 0.0000      0
000.8      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
001.3      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
001.8      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
002.3      0      0 0.0000      0      0 0.0000      0      0 0.0019      0
002.8      0      0 0.0036      0      0 0.0036      0      0 0.0000      0
      NA114A NA115A NA129A NA133A NA135A NA140A NA149A NA151A NA156A NA158A
000.3      0      0      0      0      0 0.0309      0      0 0.0635 0.0069
000.8      0      0      0      0      0 0.0403      0      0 0.0653 0.0115
001.3      0      0      0      0      0 0.0351      0      0 0.0869 0.0185
001.8      0      0      0      0      0 0.0409      0      0 0.0765 0.0142
002.3      0      0      0      0      0 0.0393      0      0 0.0674 0.0169
002.8      0      0      0      0      0 0.0218      0      0 0.0581 0.0163
      NA160A NA167A NA170A NA9904 NA9919 NA9955 NA9963 NA9964 NE003A NE003B
000.3      0 0.0326      0      0      0      0      0      0      0      0
000.8      0 0.0365      0      0      0      0      0      0      0      0
001.3      0 0.0555      0      0      0      0      0      0      0      0
001.8      0 0.0427      0      0      0      0      0      0      0      0
002.3      0 0.0300      0      0      0      0      0      0      0      0
002.8      0 0.0399      0      0      0      0      0      0      0      0
      NE003C NE004A NE012A NE020A NE023A NI002A NI005A NI008A NI009A NI009B
000.3      0 0.0000      0      0      0 0.0000 0.0051      0      0      0
000.8      0 0.0019      0      0      0 0.0000 0.0000      0      0      0
001.3      0 0.0000      0      0      0 0.0000 0.0018      0      0      0
001.8      0 0.0000      0      0      0 0.0036 0.0000      0      0      0
002.3      0 0.0019      0      0      0 0.0000 0.0000      0      0      0
002.8      0 0.0073      0      0      0 0.0000 0.0000      0      0      0
      NI017A NI021A NI026A NI027A NI152A NI9984 OP001A PE002A PI005A PI007A
000.3      0      0      0      0      0      0      0 0.0069 0.0017 0.0000
000.8      0      0      0      0      0      0      0 0.0288 0.0000 0.0000
001.3      0      0      0      0      0      0      0 0.0259 0.0000 0.0018
001.8      0      0      0      0      0      0      0 0.0409 0.0000 0.0000
002.3      0      0      0      0      0      0      0 0.0318 0.0000 0.0000
002.8      0      0      0      0      0      0      0 0.0436 0.0000 0.0018
      PI011A PI014A PI015A PI016A PI018A PI018B PI022B PI023A PI055A PI056A
000.3 0.0000 0.0000      0 0.0017 0.0017      0 0.0000      0      0      0
000.8 0.0019 0.0000      0 0.0000 0.0019      0 0.0019      0      0      0
001.3 0.0000 0.0000      0 0.0000 0.0000      0 0.0000      0      0      0
001.8 0.0053 0.0018      0 0.0018 0.0089      0 0.0000      0      0      0
002.3 0.0019 0.0000      0 0.0019 0.0037      0 0.0000      0      0      0
002.8 0.0036 0.0000      0 0.0018 0.0018      0 0.0000      0      0      0
      PI139A PI164A RH006B SA001A SA001B SA006A SA042A SE001A SP002A ST004A
000.3      0      0      0 0.0017 0.0017      0      0      0 0.0000      0
000.8      0      0      0 0.0000 0.0000      0      0      0 0.0000      0
001.3      0      0      0 0.0000 0.0037      0      0      0 0.0018      0
001.8      0      0      0 0.0000 0.0036      0      0      0 0.0000      0
002.3      0      0      0 0.0000 0.0000      0      0      0 0.0000      0
002.8      0      0      0 0.0000 0.0036      0      0      0 0.0000      0
      ST010A SU002A SU004A SU005A SU006A SY002A SY003A SY004A SY009A SY010A
000.3      0      0      0 0.0000 0.0137      0      0      0      0      0
000.8      0      0      0 0.0000 0.0134      0      0      0      0      0
001.3      0      0      0 0.0000 0.0055      0      0      0      0      0
001.8      0      0      0 0.0036 0.0053      0      0      0      0      0
002.3      0      0      0 0.0019 0.0075      0      0      0      0      0
002.8      0      0      0 0.0000 0.0091      0      0      0      0      0
      SY013A SY043A TA001A TA002A TA003A TA004A TA9996
000.3      0      0 0.0103      0 0.0172 0.0806      0
000.8      0      0 0.0115      0 0.0154 0.1440      0
001.3      0      0 0.0055      0 0.0203 0.1165      0
001.8      0      0 0.0053      0 0.0178 0.1352      0
002.3      0      0 0.0075      0 0.0112 0.1517      0
002.8      0      0 0.0181      0 0.0091 0.1234      0

> 
> ## load the example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## show just the first few lines of each data set
> head(dat, n = 4)
$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0       0       0       0       0  98.97   0.90    0.00
V17.196      0       0       0       0       0       0  98.13   0.94    0.47
V18.110      0       0       0       0       0       0  96.29   1.71    1.00
V16.227      0       0       0       0       0       0  94.33   4.82    0.85
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0    0.00       0    0.00      0      0       0
V17.196       0       0       0    0.47       0    0.00      0      0       0
V18.110       0       0       0    0.00       0    0.57      0      0       0
V16.227       0       0       0    0.00       0    0.00      0      0       0
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V14.61        0       0       0       0       0       0  0.13      0       0
V17.196       0       0       0       0       0       0  0.00      0       0
V18.110       0       0       0       0       0       0  0.43      0       0
V16.227       0       0       0       0       0       0  0.00      0       0
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0

$V12.122
   O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo G.falco
0   1.792   0.489  43.485   0.814  25.570   0.651      0  0.163   0.000   0.163
10  3.203   0.712  37.722   0.356  30.961   0.712      0  0.356   0.000   0.000
20  2.564   1.709  47.009   0.855  20.513   1.709      0  1.282   0.427   0.000
30  1.124   0.562  47.190   1.124  12.360   2.247      0  3.933   0.562   0.562
   G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf G.scitu
0    0.326   3.257   8.958   4.560   0.163  0.163  0.000   0.000   0.163
10   0.000   2.491   8.185   5.694   0.000  0.712  0.356   0.000   0.000
20   0.855   0.855   9.402   5.556   0.000  0.427  0.855   0.000   0.855
30   2.247   5.056   7.865   6.742   1.124  0.000  1.685   0.562   0.562
   G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu G.hexag G.cglom
0    7.492   0.977   0.651   0.163       0 0.000      0       0       0       0
10   5.694   1.423   0.000   0.356       0 1.068      0       0       0       0
20   2.991   0.855   0.855   0.000       0 0.427      0       0       0       0
30   1.124   2.247   0.000   0.000       0 1.124      0       0       0       0
   cfH.pel
0        0
10       0
20       0
30       0

> 
> ## show just the last few lines of each data set
> tail(dat, n = 4)
$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V20.7     3.08    0.00   60.50    0.00   21.03    0.00      0   0.00    0.00
V20.234   1.09    0.00   46.28    1.09   29.04    0.54      0   0.36    0.18
V18.21    0.21    0.42   47.47    0.21   18.99    0.00      0   0.00    0.00
V12.122   1.79    0.49   43.49    0.81   25.57    0.65      0   0.16    0.00
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V20.7      0.00    0.00    3.08    0.00    7.70    0.00   0.00   0.00       0
V20.234    0.00    1.09    3.27    7.99    2.00    0.00   0.00   0.54       0
V18.21     0.00    1.05    4.43    6.54    2.53    0.00   0.00   0.00       0
V12.122    0.16    0.33    3.26    8.96    4.56    0.16   0.16   0.00       0
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V20.7      0.00    3.08    0.00    0.00    0.00       0  1.54      0       0
V20.234    1.27    3.63    0.91    0.00    0.18       0  0.54      0       0
V18.21     0.63   12.45    3.38    0.21    0.42       0  1.05      0       0
V12.122    0.16    7.49    0.98    0.65    0.16       0  0.00      0       0
        G.hexag G.cglom cfH.pel
V20.7         0       0       0
V20.234       0       0       0
V18.21        0       0       0
V12.122       0       0       0

$V12.122
     O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
1060  1.878   0.469  24.883   1.878  14.085   1.408      0  9.390   0.939
1070  2.286   2.286  37.143   1.714   8.000   1.714      0  8.000   4.571
1080  3.911   2.793  32.961   1.117  14.525   1.117      0  2.793   0.559
1090  0.658   0.658  34.869   4.605  15.789   1.316      0  3.947   1.974
     G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
1060       0   1.878   2.347   6.103  15.493   7.512  0.000  1.408   0.000
1070       0   2.857   3.429   8.000   5.714   5.143  0.571  5.714   0.571
1080       0   1.676   5.028  10.056  11.732   3.911  0.000  1.117   1.117
1090       0   3.289   2.632   9.210   5.921   3.289  0.658  3.289   1.974
     G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
1060   0.469   9.390   0.000       0       0       0 0.469      0       0
1070   0.000   2.286   0.000       0       0       0 0.000      0       0
1080   0.000   4.469   0.559       0       0       0 0.000      0       0
1090   0.000   3.289   0.000       0       0       0 2.632      0       0
     G.hexag G.cglom cfH.pel
1060   0.000       0       0
1070   0.000       0       0
1080   0.559       0       0
1090   0.000       0       0

> 
> ## merge training and test set using inner join
> head(join(ImbrieKipp, V12.122, verbose = TRUE, type = "inner"))

Summary:

            Rows Cols
Data set 1:   61   30
Data set 2:  110   30
Merged:      171   30

$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0  0.0000       0  0.0000  0.0000 0.9897 0.0090  0.0000
V17.196      0       0  0.0000       0  0.0000  0.0000 0.9813 0.0094  0.0047
V18.110      0       0  0.0000       0  0.0000  0.0000 0.9629 0.0171  0.0100
V16.227      0       0  0.0000       0  0.0000  0.0000 0.9433 0.0482  0.0085
V14.47       0       0  0.0011       0  0.0011  0.0011 0.6850 0.0271  0.1095
V23.22       0       0  0.0000       0  0.0000  0.0000 0.5569 0.1662  0.1990
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V17.196       0       0       0  0.0047       0  0.0000 0.0000      0  0.0000
V18.110       0       0       0  0.0000       0  0.0057 0.0000      0  0.0000
V16.227       0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V14.47        0       0       0  0.0195       0  0.1420 0.0011      0  0.0043
V23.22        0       0       0  0.0229       0  0.0157 0.0000      0  0.0000
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit  Other G.quin G.hirsu
V14.61   0.0000  0.0000  0.0000       0       0       0 0.0013 0.0000  0.0000
V17.196  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V18.110  0.0000  0.0000  0.0000       0       0       0 0.0043 0.0000  0.0000
V16.227  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V14.47   0.0011  0.0011  0.0011       0       0       0 0.0018 0.0032  0.0000
V23.22   0.0000  0.0000  0.0000       0       0       0 0.0065 0.0314  0.0013
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0
V14.47        0       0       0
V23.22        0       0       0

$V12.122
    O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL  G.pacR G.bullo
0  0.01792 0.00489 0.43485 0.00814 0.25570 0.00651      0 0.00163 0.00000
10 0.03203 0.00712 0.37722 0.00356 0.30961 0.00712      0 0.00356 0.00000
20 0.02564 0.01709 0.47009 0.00855 0.20513 0.01709      0 0.01282 0.00427
30 0.01124 0.00562 0.47190 0.01124 0.12360 0.02247      0 0.03933 0.00562
40 0.00671 0.01007 0.43623 0.03020 0.15436 0.01007      0 0.00336 0.00671
50 0.01149 0.00766 0.52873 0.00766 0.12261 0.00000      0 0.00383 0.02299
   G.falco G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf
0  0.00163 0.00326 0.03257 0.08958 0.04560 0.00163 0.00163 0.00000 0.00000
10 0.00000 0.00000 0.02491 0.08185 0.05694 0.00000 0.00712 0.00356 0.00000
20 0.00000 0.00855 0.00855 0.09402 0.05556 0.00000 0.00427 0.00855 0.00000
30 0.00562 0.02247 0.05056 0.07865 0.06742 0.01124 0.00000 0.01685 0.00562
40 0.00336 0.01678 0.08054 0.09396 0.03691 0.04698 0.00336 0.02349 0.01342
50 0.00000 0.01916 0.06897 0.07663 0.04981 0.04215 0.00000 0.02682 0.00766
   G.scitu G.mentu P.obliq C.nitid S.dehis G.digit   Other G.quin G.hirsu
0  0.00163 0.07492 0.00977 0.00651 0.00163       0 0.00000      0       0
10 0.00000 0.05694 0.01423 0.00000 0.00356       0 0.01068      0       0
20 0.00855 0.02991 0.00855 0.00855 0.00000       0 0.00427      0       0
30 0.00562 0.01124 0.02247 0.00000 0.00000       0 0.01124      0       0
40 0.00336 0.01007 0.00671 0.00000 0.00000       0 0.00336      0       0
50 0.00000 0.00000 0.00000 0.00000 0.00000       0 0.00383      0       0
   G.hexag G.cglom cfH.pel
0        0       0       0
10       0       0       0
20       0       0       0
30       0       0       0
40       0       0       0
50       0       0       0

> 
> ## merge training and test set using outer join and replace
> ## NA with -99.9
> head(join(ImbrieKipp, V12.122, verbose = TRUE, value = -99.9))

Summary:

            Rows Cols
Data set 1:   61   30
Data set 2:  110   30
Merged:      171   30

$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0  0.0000       0  0.0000  0.0000 0.9897 0.0090  0.0000
V17.196      0       0  0.0000       0  0.0000  0.0000 0.9813 0.0094  0.0047
V18.110      0       0  0.0000       0  0.0000  0.0000 0.9629 0.0171  0.0100
V16.227      0       0  0.0000       0  0.0000  0.0000 0.9433 0.0482  0.0085
V14.47       0       0  0.0011       0  0.0011  0.0011 0.6850 0.0271  0.1095
V23.22       0       0  0.0000       0  0.0000  0.0000 0.5569 0.1662  0.1990
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V17.196       0       0       0  0.0047       0  0.0000 0.0000      0  0.0000
V18.110       0       0       0  0.0000       0  0.0057 0.0000      0  0.0000
V16.227       0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V14.47        0       0       0  0.0195       0  0.1420 0.0011      0  0.0043
V23.22        0       0       0  0.0229       0  0.0157 0.0000      0  0.0000
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit  Other G.quin G.hirsu
V14.61   0.0000  0.0000  0.0000       0       0       0 0.0013 0.0000  0.0000
V17.196  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V18.110  0.0000  0.0000  0.0000       0       0       0 0.0043 0.0000  0.0000
V16.227  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V14.47   0.0011  0.0011  0.0011       0       0       0 0.0018 0.0032  0.0000
V23.22   0.0000  0.0000  0.0000       0       0       0 0.0065 0.0314  0.0013
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0
V14.47        0       0       0
V23.22        0       0       0

$V12.122
    O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL  G.pacR G.bullo
0  0.01792 0.00489 0.43485 0.00814 0.25570 0.00651      0 0.00163 0.00000
10 0.03203 0.00712 0.37722 0.00356 0.30961 0.00712      0 0.00356 0.00000
20 0.02564 0.01709 0.47009 0.00855 0.20513 0.01709      0 0.01282 0.00427
30 0.01124 0.00562 0.47190 0.01124 0.12360 0.02247      0 0.03933 0.00562
40 0.00671 0.01007 0.43623 0.03020 0.15436 0.01007      0 0.00336 0.00671
50 0.01149 0.00766 0.52873 0.00766 0.12261 0.00000      0 0.00383 0.02299
   G.falco G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf
0  0.00163 0.00326 0.03257 0.08958 0.04560 0.00163 0.00163 0.00000 0.00000
10 0.00000 0.00000 0.02491 0.08185 0.05694 0.00000 0.00712 0.00356 0.00000
20 0.00000 0.00855 0.00855 0.09402 0.05556 0.00000 0.00427 0.00855 0.00000
30 0.00562 0.02247 0.05056 0.07865 0.06742 0.01124 0.00000 0.01685 0.00562
40 0.00336 0.01678 0.08054 0.09396 0.03691 0.04698 0.00336 0.02349 0.01342
50 0.00000 0.01916 0.06897 0.07663 0.04981 0.04215 0.00000 0.02682 0.00766
   G.scitu G.mentu P.obliq C.nitid S.dehis G.digit   Other G.quin G.hirsu
0  0.00163 0.07492 0.00977 0.00651 0.00163       0 0.00000      0       0
10 0.00000 0.05694 0.01423 0.00000 0.00356       0 0.01068      0       0
20 0.00855 0.02991 0.00855 0.00855 0.00000       0 0.00427      0       0
30 0.00562 0.01124 0.02247 0.00000 0.00000       0 0.01124      0       0
40 0.00336 0.01007 0.00671 0.00000 0.00000       0 0.00336      0       0
50 0.00000 0.00000 0.00000 0.00000 0.00000       0 0.00383      0       0
   G.hexag G.cglom cfH.pel
0        0       0       0
10       0       0       0
20       0       0       0
30       0       0       0
40       0       0       0
50       0       0       0

> 
> 
> 
> cleanEx()
> nameEx("logitreg")
> ### * logitreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: logitreg
> ### Title: Logistic regression models for assessing analogues/non-analogues
> ### Aliases: logitreg logitreg.default logitreg.analog print.logitreg
> ###   summary.logitreg print.summary.logitreg
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 6)
> 
> ## fit the logit models to the analog object
> swap.lrm <- logitreg(swap.ana, grps)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
> swap.lrm

Object of class: "logitreg"
Number of models: 7

For groups:
[1] "1"        "2"        "3"        "4"        "5"        "6"        "Combined"

> 
> ## summary statistics
> summary(swap.lrm)

Logit regression models

          In Out E[Dij]    SE      Z    p-value Dij(p=0.9) SE (Dij)
1         46 121  -15.8  2.80  -5.63 1.8454e-08      0.338   0.0332
2         35 132  -32.2  6.87  -4.68 2.8597e-06      0.409   0.0200
3         22 145  -34.1 10.19  -3.35 0.00081417      0.366   0.0264
4         24 143  -27.2  6.74  -4.03 5.6098e-05      0.495   0.0274
5         25 142  -16.2  3.93  -4.12 3.7464e-05      0.461   0.0494
6         15 152  -11.0  2.71  -4.06 4.8045e-05      0.283   0.0794
Combined 167 835  -16.2  1.41 -11.51 < 2.22e-16      0.359   0.0166

> 
> ## plot the fitted logit curves
> plot(swap.lrm, conf.type = "polygon")
> 
> ## extract fitted posterior probabilities for training samples
> ## for the individual groups
> fit <- fitted(swap.lrm)
> head(fit)
          1           2         3         4         5         6
1 0.7704741 0.992926550 0.9705455 0.9967696 0.9977100 0.8004397
2 0.9480710 0.008663829 0.9961969 0.7215776 0.9573624 0.4823301
3 0.9740472 0.847497770 0.9714598 0.6919208 0.9965144 0.2744509
4 0.7168113 0.847497770 0.9535765 0.3007374 0.9990662 0.2870750
5 0.9661203 0.997014448 0.9970177 0.9946234 0.9178795 0.4975797
6 0.9740472 0.445288611 0.3826365 0.7858915 0.9990662 0.2870750
> 
> ## compute posterior probabilities of analogue-ness for the rlgh
> ## samples. Here we take the dissimilarities between fossil and
> ## training samples from the `swap.ana` object rather than re-
> ## compute them
> pred <- predict(swap.lrm, newdata = swap.ana$analogs)
> head(pred)
              1          2         3           4            5          6
000.3 0.8888987 0.08607136 0.0541194 0.005482089 8.536340e-05 0.03915959
000.8 0.9508126 0.01931803 0.4638425 0.070408351 1.349192e-05 0.02206208
001.3 0.9423900 0.04554104 0.7782695 0.043191558 1.474048e-05 0.01984818
001.8 0.9523237 0.03181413 0.3485667 0.010448649 2.326359e-05 0.02003420
002.3 0.9372000 0.02182155 0.3034852 0.031319684 1.133939e-05 0.01383880
002.8 0.9732644 0.05464832 0.5834611 0.027163318 4.119295e-05 0.03144971
> 
> ## Bias reduction
> ## fit the logit models to the analog object
> swap.brlrm <- logitreg(swap.ana, grps, biasReduced = TRUE)
> summary(swap.brlrm)

Logit regression models

          In Out E[Dij]   SE      Z    p-value Dij(p=0.9) SE (Dij)
1         46 121  -15.1 2.68  -5.63 1.7690e-08      0.331   0.0346
2         35 132  -29.5 6.08  -4.85 1.2174e-06      0.403   0.0212
3         22 145  -28.5 7.82  -3.65 0.00026651      0.353   0.0287
4         24 143  -24.2 5.73  -4.22 2.4163e-05      0.485   0.0298
5         25 142  -14.5 3.34  -4.33 1.4819e-05      0.442   0.0530
6         15 152  -10.1 2.44  -4.15 3.3636e-05      0.260   0.0858
Combined 167 835  -16.0 1.38 -11.55 < 2.22e-16      0.357   0.0167

> 
> 
> 
> cleanEx()
> nameEx("mat")
> ### * mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mat
> ### Title: Modern Analogue Technique transfer function models
> ### Aliases: mat mat.default mat.formula fitted.mat residuals.mat resid.mat
> ###   print.residuals.mat print.mat print.fitted.mat
> ### Keywords: models multivariate methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> ik.mat

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## model summary
> summary(ik.mat)

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

Results for training set

  * (W.)Est and (W.)Resi are based on k=10-closest analogues
  * minDC is the minimum distance to another sample in the training set
  * min(W.)Resi is the minimum residual for a k-closest model,
    where k = 1,...,10. Column k(.W) displays which k has minResi

           Obs    Est   Resi  W.Est   W.Resi  minDC  minResi   k  minW.Resi
V14.61     2.0   9.50   7.50   7.93   5.9273  0.104   5.1000   5   5.37e+00
V17.196    5.0   9.20   4.20   6.86   1.8572  0.130   0.1667   3   4.61e-01
V18.110    5.5   9.15   3.65   7.13   1.6290  0.134   0.5000   1   4.84e-01
V16.227    7.0   9.00   2.00   7.16   0.1554  0.134   0.1667   3   2.62e-02
V14.47     7.0   9.00   2.00   8.66   1.6594  0.452   0.0000   4   3.63e-02
V23.22    10.5   8.65  -1.85   8.68  -1.8229  0.467   0.5000   3   7.43e-01
V2.12     11.0   8.60  -2.40   5.70  -5.2971  0.119   2.4000  10   5.30e+00
V23.29    10.0  13.65   3.65  13.33   3.3347  0.467   1.2500   2   1.41e+00
V12.43    13.0  13.25   0.25  13.31   0.3135  0.490   0.0000   5   1.71e-01
R9.7      12.0  14.85   2.85  14.29   2.2876  0.432   1.0000   2   4.65e-01
A157.3    14.0  16.30   2.30  16.04   2.0418  0.407   0.5000   2   3.14e-01
V23.81    14.5  15.45   0.95  15.40   0.8996  0.299   0.1667   3   8.08e-02
V23.82    15.0  16.20   1.20  15.84   0.8369  0.299   0.1429   7   1.40e-01
V12.53    14.5  17.80   3.30  17.76   3.2607  0.442   2.3571   7   2.55e+00
V23.83    16.0  15.30  -0.70  15.02  -0.9814  0.295   0.7000  10   9.81e-01
V12.56    18.0  20.90   2.90  20.78   2.7832  0.380   1.0000   2   1.03e+00
A152.84   20.0  21.60   1.60  21.64   1.6374  0.361   0.1429   7   5.77e-01
V16.50    18.0  20.50   2.50  20.28   2.2759  0.429   0.0000   1   0.00e+00
V22.122   19.0  17.95  -1.05  17.58  -1.4223  0.429   1.0500  10   1.42e+00
V16.41    18.5  23.90   5.40  23.64   5.1402  0.380   2.5000   1   2.50e+00
V4.32     21.5  23.60   2.10  23.62   2.1185  0.333   1.6250   8   1.73e+00
V12.66    21.0  21.10   0.10  21.12   0.1228  0.421   0.0000   1   0.00e+00
V19.245   21.0  23.20   2.20  22.72   1.7177  0.331   0.1667   3   4.41e-01
V4.8      24.0  23.35  -0.65  23.38  -0.6203  0.280   0.0000   1   0.00e+00
A180.15   24.0  22.95  -1.05  22.99  -1.0083  0.292   0.0000   1   0.00e+00
V18.34    23.0  24.35   1.35  24.49   1.4904  0.411   1.3500  10   1.49e+00
V20.213   24.0  24.57   0.57  24.56   0.5565  0.326   0.0833   6   1.38e-01
V19.222   23.0  23.00   0.00  23.06   0.0580  0.384   0.0000  10   3.83e-02
A180.39   23.0  24.25   1.25  24.24   1.2366  0.347   0.4167   6   5.12e-01
V16.189   24.0  25.89   1.89  25.85   1.8495  0.399   1.0000   1   1.00e+00
V12.18    25.0  25.39   0.39  25.48   0.4751  0.289   0.3000   9   4.19e-01
V7.67     26.0  23.45  -2.55  23.76  -2.2436  0.308   0.0000   1   0.00e+00
V17.165   26.0  24.77  -1.23  24.80  -1.2021  0.308   0.0000   1   0.00e+00
V19.310   26.0  23.75  -2.25  23.97  -2.0257  0.296   0.0000   1   0.00e+00
V16.190   25.0  25.32   0.32  25.34   0.3424  0.324   0.0000   2   3.98e-02
A153.154  26.0  25.67  -0.33  25.73  -0.2694  0.222   0.1000   2   1.11e-01
V19.308   26.0  25.99  -0.01  25.98  -0.0223  0.222   0.0100  10   2.23e-02
V22.172   24.5  26.72   2.22  26.71   2.2110  0.307   1.5000   1   1.50e+00
V10.98    27.0  24.82  -2.18  24.77  -2.2349  0.330   2.0000   1   2.00e+00
V22.219   26.2  25.65  -0.55  25.63  -0.5709  0.189   0.2000   1   2.00e-01
V16.33    25.0  26.37   1.37  26.37   1.3703  0.493   0.7333   3   7.48e-01
V22.204   26.5  26.80   0.30  26.74   0.2362  0.325   0.0000   6   3.12e-02
V20.167   26.2  26.90   0.70  26.87   0.6732  0.257   0.0333   3   1.17e-02
V10.89    26.0  26.04   0.04  26.12   0.1184  0.308   0.0400  10   1.18e-01
V12.79    26.0  26.90   0.90  26.88   0.8813  0.249   0.3750   4   5.16e-01
V19.216   27.0  25.27  -1.73  25.32  -1.6776  0.363   0.9000   7   9.65e-01
V14.90    27.0  26.95  -0.05  26.89  -0.1113  0.249   0.0000   4   2.56e-02
A180.72   27.5  26.75  -0.75  26.74  -0.7623  0.185   0.4286   7   5.18e-01
V16.21    27.0  26.87  -0.13  26.85  -0.1453  0.247   0.0000   1   0.00e+00
A180.76   27.0  27.15   0.15  27.16   0.1582  0.233   0.0000   6   3.86e-02
V15.164   27.0  26.82  -0.18  26.79  -0.2081  0.257   0.0000   1   0.00e+00
A180.78   27.0  27.20   0.20  27.19   0.1940  0.405   0.0000   5   1.03e-04
V14.5     27.0  27.02   0.02  27.07   0.0730  0.219   0.0000   1   3.55e-15
V3.128    29.0  26.72  -2.28  26.69  -2.3050  0.366   2.1500   2   2.17e+00
A179.13   28.5  26.09  -2.41  26.13  -2.3699  0.327   1.8333   3   1.85e+00
V9.31     27.5  26.87  -0.63  26.92  -0.5805  0.309   0.0000   1   0.00e+00
V20.230   27.5  26.87  -0.63  26.90  -0.6015  0.291   0.1667   3   1.77e-01
V20.7     27.5  27.27  -0.23  27.25  -0.2452  0.431   0.0000   2   1.06e-03
V20.234   27.0  27.02   0.02  27.08   0.0788  0.228   0.0000   1   0.00e+00
V18.21    27.0  26.77  -0.23  26.87  -0.1318  0.252   0.0000   1   3.55e-15
V12.122   28.0  26.92  -1.08  26.94  -1.0561  0.228   0.9000   5   9.17e-01
          k.W
V14.61      5
V17.196     3
V18.110     2
V16.227     9
V14.47      6
V23.22      3
V2.12      10
V23.29      2
V12.43      5
R9.7        2
A157.3      2
V23.81      4
V23.82      7
V12.53      7
V23.83     10
V12.56      2
A152.84     7
V16.50      1
V22.122    10
V16.41      1
V4.32       8
V12.66      1
V19.245     4
V4.8        1
A180.15     1
V18.34     10
V20.213     6
V19.222     9
A180.39     6
V16.189     1
V12.18      9
V7.67       1
V17.165     1
V19.310     1
V16.190     3
A153.154    2
V19.308    10
V22.172     1
V10.98      1
V22.219     2
V16.33      3
V22.204     7
V20.167     4
V10.89     10
V12.79      4
V19.216     7
V14.90      4
A180.72     7
V16.21      1
A180.76     7
V15.164     1
A180.78     5
V14.5       1
V3.128      2
A179.13     3
V9.31       1
V20.230     3
V20.7       2
V20.234     1
V18.21      1
V12.122     5

> 
> ## fitted values
> fitted(ik.mat)

	Modern Analogue Technique: Fitted values

No. of analogues (k) : 3 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
    7.17     4.83     4.67     7.17     7.67    10.00     4.83    11.83 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   13.50    13.67    14.50    14.33    14.17    17.00    14.50    20.67 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   22.00    17.17    15.50    23.33    24.00    21.83    20.83    23.83 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   23.33    25.33    24.50    23.83    24.00    25.73    26.07    25.33 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   25.33    25.33    25.00    25.73    25.73    26.40    24.67    25.67 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   25.73    26.00    26.17    27.23    27.00    25.67    26.83    26.67 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   26.40    27.17    26.73    26.83    27.33    26.07    26.67    27.17 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   27.33    27.33    27.33    27.33    27.00 
> 
> ## model residuals
> resid(ik.mat)

	Modern Analogue Technique Residuals

No. of analogues (k) : 3 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.1667  -0.1667  -0.8333   0.1667   0.6667  -0.5000  -6.1667   1.8333 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.5000   1.6667   0.5000  -0.1667  -0.8333   2.5000  -1.5000   2.6667 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  2.0000  -0.8333  -3.5000   4.8333   2.5000   0.8333  -0.1667  -0.1667 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.6667   2.3333   0.5000   0.8333   1.0000   1.7333   1.0667  -0.6667 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.6667  -0.6667   0.0000  -0.2667  -0.2667   1.9000  -2.3333  -0.5333 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  0.7333  -0.5000  -0.0333   1.2333   1.0000  -1.3333  -0.1667  -0.8333 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.6000   0.1667  -0.2667  -0.1667   0.3333  -2.9333  -1.8333  -0.3333 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.1667  -0.1667   0.3333   0.3333  -1.0000 
> 
> ## draw summary plots of the model
> par(mfrow = c(2,2))
> plot(ik.mat)
> par(mfrow = c(1,1))
> 
> ## reconstruct for the V12.122 core data
> coreV12.mat <- predict(ik.mat, V12.122, k = 3)
> coreV12.mat

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? FALSE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
    1.713     0.941     0.133     5.167 

Predicted values:
   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
27.3 27.3 27.3 26.3 25.9 25.9 25.5 25.8 26.2 26.0 27.0 27.3 26.3 27.2 26.5 25.6 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
26.6 26.6 27.2 27.3 26.5 26.8 27.5 27.3 27.7 26.0 25.9 26.3 26.5 27.3 25.9 26.3 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
26.3 26.2 25.8 27.1 25.9 25.9 27.5 26.8 27.0 27.7 27.2 27.5 27.2 27.0 27.4 25.9 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
26.8 27.7 27.3 27.0 27.0 25.9 26.1 26.2 27.3 27.3 26.5 25.9 27.2 27.1 26.6 27.2 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
27.3 27.2 26.8 27.0 26.8 27.2 26.9 27.4 26.2 27.8 27.0 26.8 26.8 27.4 27.7 27.3 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
27.3 26.5 26.8 25.5 26.2 27.0 26.0 25.9 26.3 25.0 26.8 26.2 26.5 27.3 27.3 26.7 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
27.5 27.3 27.3 27.3 26.2 27.3 26.2 26.2 27.0 26.0 26.8 25.5 26.5 26.0 
> summary(coreV12.mat)

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? FALSE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
    1.713     0.941     0.133     5.167 

Predicted values:
   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
27.3 27.3 27.3 26.3 25.9 25.9 25.5 25.8 26.2 26.0 27.0 27.3 26.3 27.2 26.5 25.6 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
26.6 26.6 27.2 27.3 26.5 26.8 27.5 27.3 27.7 26.0 25.9 26.3 26.5 27.3 25.9 26.3 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
26.3 26.2 25.8 27.1 25.9 25.9 27.5 26.8 27.0 27.7 27.2 27.5 27.2 27.0 27.4 25.9 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
26.8 27.7 27.3 27.0 27.0 25.9 26.1 26.2 27.3 27.3 26.5 25.9 27.2 27.1 26.6 27.2 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
27.3 27.2 26.8 27.0 26.8 27.2 26.9 27.4 26.2 27.8 27.0 26.8 26.8 27.4 27.7 27.3 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
27.3 26.5 26.8 25.5 26.2 27.0 26.0 25.9 26.3 25.0 26.8 26.2 26.5 27.3 27.3 26.7 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
27.5 27.3 27.3 27.3 26.2 27.3 26.2 26.2 27.0 26.0 26.8 25.5 26.5 26.0 

Training set assessment:

          Obs   Est   Resid
V14.61    2.0  7.17  5.1667
V17.196   5.0  4.83 -0.1667
V18.110   5.5  4.67 -0.8333
V16.227   7.0  7.17  0.1667
V14.47    7.0  7.67  0.6667
V23.22   10.5 10.00 -0.5000
V2.12    11.0  4.83 -6.1667
V23.29   10.0 11.83  1.8333
V12.43   13.0 13.50  0.5000
R9.7     12.0 13.67  1.6667
A157.3   14.0 14.50  0.5000
V23.81   14.5 14.33 -0.1667
V23.82   15.0 14.17 -0.8333
V12.53   14.5 17.00  2.5000
V23.83   16.0 14.50 -1.5000
V12.56   18.0 20.67  2.6667
A152.84  20.0 22.00  2.0000
V16.50   18.0 17.17 -0.8333
V22.122  19.0 15.50 -3.5000
V16.41   18.5 23.33  4.8333
V4.32    21.5 24.00  2.5000
V12.66   21.0 21.83  0.8333
V19.245  21.0 20.83 -0.1667
V4.8     24.0 23.83 -0.1667
A180.15  24.0 23.33 -0.6667
V18.34   23.0 25.33  2.3333
V20.213  24.0 24.50  0.5000
V19.222  23.0 23.83  0.8333
A180.39  23.0 24.00  1.0000
V16.189  24.0 25.73  1.7333
V12.18   25.0 26.07  1.0667
V7.67    26.0 25.33 -0.6667
V17.165  26.0 25.33 -0.6667
V19.310  26.0 25.33 -0.6667
V16.190  25.0 25.00  0.0000
A153.154 26.0 25.73 -0.2667
V19.308  26.0 25.73 -0.2667
V22.172  24.5 26.40  1.9000
V10.98   27.0 24.67 -2.3333
V22.219  26.2 25.67 -0.5333
V16.33   25.0 25.73  0.7333
V22.204  26.5 26.00 -0.5000
V20.167  26.2 26.17 -0.0333
V10.89   26.0 27.23  1.2333
V12.79   26.0 27.00  1.0000
V19.216  27.0 25.67 -1.3333
V14.90   27.0 26.83 -0.1667
A180.72  27.5 26.67 -0.8333
V16.21   27.0 26.40 -0.6000
A180.76  27.0 27.17  0.1667
V15.164  27.0 26.73 -0.2667
A180.78  27.0 26.83 -0.1667
V14.5    27.0 27.33  0.3333
V3.128   29.0 26.07 -2.9333
A179.13  28.5 26.67 -1.8333
V9.31    27.5 27.17 -0.3333
V20.230  27.5 27.33 -0.1667
V20.7    27.5 27.33 -0.1667
V20.234  27.0 27.33  0.3333
V18.21   27.0 27.33  0.3333
V12.122  28.0 27.00 -1.0000
> 
> ## draw the reconstruction
> reconPlot(coreV12.mat, use.labels = TRUE, display.error = "bars",
+           xlab = "Depth", ylab = "SumSST")
> 
> ## fit the MAT model using the squared chord distance measure
> ## and restrict the number of analogues we fit models for to 1:20
> ik.mat2 <- mat(ImbrieKipp, SumSST, method = "chord", kmax = 20)
> ik.mat2

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord", kmax = 20) 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("mcarlo")
> ### * mcarlo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mcarlo
> ### Title: Monte Carlo simulation of dissimilarities
> ### Aliases: mcarlo mcarlo.default mcarlo.mat mcarlo.analog print.mcarlo
> ### Keywords: multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## perform the modified method of Sawada (2004) - paired sampling,
> ## with replacement
> ik.mcarlo <- mcarlo(ImbrieKipp, method = "chord", nsamp = 1000,
+                     type = "paired", replace = FALSE)
> ik.mcarlo

	Simulated Dissimilarities

Simulation type : paired 
No. simulations : 1000 
Coefficient     : chord 

Summary of simulated distribution:
    Min 1st Qu.  Median    Mean 3rd Qu.     Max 
 0.0917  1.3141  1.3698  1.2303  1.4061  1.4119 

Percentiles of simulated distribution:
    1%   2.5%     5%    10%    90%    95%  97.5%    99% 
0.0917 0.1035 0.1301 0.6572 1.4112 1.4115 1.4116 1.4119 

> 
> ## plot the simulated distribution
> layout(matrix(1:2, ncol = 1))
> plot(ik.mcarlo)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("minDC")
> ### * minDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: minDC
> ### Title: Extract minimum dissimilarities
> ### Aliases: minDC minDC.default minDC.predict.mat minDC.analog minDC.wa
> ###   print.minDC
> ### Keywords: utilities manip methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> ik.mat

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "SQchord") 

Percentiles of the dissimilarities for the training set:

    1%     2%     5%    10%    20% 
0.0483 0.0786 0.1163 0.1710 0.2512 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.926 0.927    0.244    6.364
  3 1.770 0.937    0.139    5.771
  4 1.772 0.937    0.166    5.674
  5 1.758 0.938    0.172    5.667
  6 1.717 0.941    0.186    5.688
  7 1.717 0.941    0.200    5.705
  8 1.753 0.939    0.197    5.712
  9 1.765 0.938    0.205    5.729
 10 1.822 0.934    0.262    5.740

> 
> ## reconstruct for the V12-122 core data
> v12.mat <- predict(ik.mat, V12.122)
> 
> ## extract the minimum DC values
> v12.mdc <- minDC(v12.mat)
> v12.mdc

	Minimum dissimilarity per sample

Dissimilarity: SQchord 

       0       10       20       30       40       50       60       70 
1.06e-06 4.24e-02 6.09e-02 7.52e-02 6.96e-02 1.19e-01 1.32e-01 1.54e-01 
      80       90      100      110      120      130      140      150 
1.41e-01 1.52e-01 1.81e-01 1.50e-01 1.84e-01 1.58e-01 1.95e-01 1.50e-01 
     160      170      180      190      200      210      220      230 
1.47e-01 1.12e-01 1.54e-01 1.62e-01 1.14e-01 1.32e-01 1.18e-01 1.03e-01 
     240      250      260      270      280      290      300      310 
1.15e-01 1.10e-01 1.14e-01 1.65e-01 1.74e-01 1.28e-01 1.34e-01 2.11e-01 
     320      330      340      350      360      370      380      390 
1.80e-01 1.91e-01 1.32e-01 1.54e-01 1.45e-01 1.77e-01 1.45e-01 1.75e-01 
     400      410      420      430      440      450      460      470 
1.17e-01 2.03e-01 1.13e-01 1.64e-01 8.61e-02 1.18e-01 1.27e-01 1.14e-01 
     480      490      500      510      520      530      540      550 
1.63e-01 1.30e-01 1.18e-01 1.91e-01 1.36e-01 1.87e-01 1.90e-01 1.85e-01 
     560      570      580      590      600      610      620      630 
1.37e-01 1.29e-01 1.17e-01 7.82e-02 1.13e-01 1.89e-01 2.40e-01 1.13e-01 
     640      650      660      670      680      690      700      710 
1.36e-01 1.18e-01 1.81e-01 1.94e-01 2.29e-01 1.25e-01 1.62e-01 1.72e-01 
     720      730      740      750      760      770      780      790 
2.24e-01 2.56e-01 1.52e-01 1.36e-01 1.59e-01 2.02e-01 2.55e-01 1.29e-01 
     800      810      820      830      840      850      860      870 
1.30e-01 1.43e-01 1.55e-01 1.12e-01 1.35e-01 1.78e-01 1.89e-01 1.80e-01 
     880      890      900      910      920      930      940      950 
1.63e-01 2.28e-01 2.17e-01 1.54e-01 1.63e-01 1.57e-01 1.20e-01 1.86e-01 
     960      970      980      990     1000     1010     1020     1030 
1.71e-01 1.37e-01 1.21e-01 1.99e-01 1.42e-01 2.31e-01 1.88e-01 1.91e-01 
    1040     1050     1060     1070     1080     1090 
2.20e-01 1.16e-01 1.83e-01 1.84e-01 1.42e-01 1.33e-01 
> 
> ## draw a plot of minimum DC by time
> plot(v12.mdc, use.labels = TRUE, xlab = "Depth (cm.)")
> 
> 
> 
> cleanEx()
> nameEx("n2")
> ### * n2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: n2
> ### Title: Calculate Hill's N2 diversity measure
> ### Aliases: n2 n2.default
> ### Keywords: methods multivariate utilities
> 
> ### ** Examples
> 
> data(swapdiat)
> sppN2 <- n2(swapdiat, "species")
> head(sppN2)
   AC001A    AC002A    AC004A    AC013A    AC014A    AC014B 
 8.248589 12.128209 10.997128 46.072440  3.025195  9.190233 
> sampN2 <- n2(swapdiat, "sites")
> head(sampN2)
     1.21     10.21        11    113.21    115.11     12.11 
15.501849 11.026197  6.702897 10.712509 11.370488 15.094376 
> 
> 
> 
> cleanEx()
> nameEx("optima")
> ### * optima
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: optima
> ### Title: Weighted averaging optima and tolerance ranges
> ### Aliases: optima optima.default print.optima print.tolerance
> ###   tolerance.default as.data.frame.optima as.data.frame.tolerance
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## WA optima
> (opt <- optima(ImbrieKipp, SumSST))

	Weighted Average Optima For: SumSST

   O.univ   G.cglob   G.ruber   G.tenel   G.saccu   G.rubes    G.pacL    G.pacR 
24.337228 25.726081 26.067809 25.574791 26.180014 26.274793  7.333465 16.980489 
  G.bullo   G.falco   G.calid   G.aequi   G.gluti   G.duter   G.infla    G.trnL 
17.514873 23.287148 24.527161 25.541789 22.265921 26.490136 19.873421 22.378081 
   G.trnR   G.crasf   G.scitu   G.mentu   P.obliq   C.nitid   S.dehis   G.digit 
24.552945 24.863128 22.617220 26.137781 26.943196 26.410054 24.077808 25.114701 
    Other    G.quin   G.hirsu 
22.716838 12.878463 22.279986 
> 
> ## WA tolerances
> (tol <- tolerance(ImbrieKipp, SumSST, useN2 = TRUE))

	Weighted Average Tolerances For: SumSST

  O.univ  G.cglob  G.ruber  G.tenel  G.saccu  G.rubes   G.pacL   G.pacR 
3.746359 1.895600 1.909561 2.124799 1.979651 1.968294 3.941352 5.181162 
 G.bullo  G.falco  G.calid  G.aequi  G.gluti  G.duter  G.infla   G.trnL 
5.827980 3.109193 2.973112 2.561697 5.898256 1.998304 4.723884 4.161704 
  G.trnR  G.crasf  G.scitu  G.mentu  P.obliq  C.nitid  S.dehis  G.digit 
3.434920 3.354021 3.990673 2.386584 1.554762 1.461725 3.844730 3.108881 
   Other   G.quin  G.hirsu 
5.112464 4.268777 3.942135 
> 
> ## caterpillar plot
> caterpillarPlot(opt, tol)
> 
> ## convert to data frame
> as.data.frame(opt)
              Opt
O.univ  24.337228
G.cglob 25.726081
G.ruber 26.067809
G.tenel 25.574791
G.saccu 26.180014
G.rubes 26.274793
G.pacL   7.333465
G.pacR  16.980489
G.bullo 17.514873
G.falco 23.287148
G.calid 24.527161
G.aequi 25.541789
G.gluti 22.265921
G.duter 26.490136
G.infla 19.873421
G.trnL  22.378081
G.trnR  24.552945
G.crasf 24.863128
G.scitu 22.617220
G.mentu 26.137781
P.obliq 26.943196
C.nitid 26.410054
S.dehis 24.077808
G.digit 25.114701
Other   22.716838
G.quin  12.878463
G.hirsu 22.279986
> as.data.frame(tol)
             Tol
O.univ  3.746359
G.cglob 1.895600
G.ruber 1.909561
G.tenel 2.124799
G.saccu 1.979651
G.rubes 1.968294
G.pacL  3.941352
G.pacR  5.181162
G.bullo 5.827980
G.falco 3.109193
G.calid 2.973112
G.aequi 2.561697
G.gluti 5.898256
G.duter 1.998304
G.infla 4.723884
G.trnL  4.161704
G.trnR  3.434920
G.crasf 3.354021
G.scitu 3.990673
G.mentu 2.386584
P.obliq 1.554762
C.nitid 1.461725
S.dehis 3.844730
G.digit 3.108881
Other   5.112464
G.quin  4.268777
G.hirsu 3.942135
> 
> ## bootstrap WA optima - 100 resamples too low for SD & pCI
> bopt <- optima(ImbrieKipp, SumSST, boot = TRUE, nboot = 100)
> head(bopt)
          Optima  optBoot     optSD     2.5%    97.5%
O.univ  24.33723 24.30575 0.7519027 22.59502 25.53861
G.cglob 25.72608 25.73315 0.3708404 25.04122 26.44573
G.ruber 26.06781 26.03858 0.2469646 25.59262 26.55639
G.tenel 25.57479 25.51317 0.4903363 24.57123 26.37755
G.saccu 26.18001 26.11238 0.2759070 25.54407 26.64906
G.rubes 26.27479 26.21838 0.3013788 25.53009 26.67768
> 
> 
> 
> 
> cleanEx()
> nameEx("pcr")
> ### * pcr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pcr
> ### Title: Prinicpal component regression transfer function models
> ### Aliases: pcr pcr.default pcr.formula print.pcr Hellinger ChiSquare
> ###   performance.pcr fitted.pcr coef.pcr residuals.pcr screeplot.pcr
> ###   eigenvals.pcr
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## normal interface and apply Hellinger transformation
> mod <- pcr(ImbrieKipp, SumSST, tranFun = Hellinger)
> mod

	Principal Component Regression Model

Call:
pcr(x = ImbrieKipp, y = SumSST, tranFun = Hellinger)

No. of Components: 27

RMSE (Apparent):
     PC1      PC2      PC3      PC4      PC5      PC6      PC7      PC8 
2.381215 1.707588 1.680896 1.679774 1.608903 1.535145 1.507995 1.496939 
     PC9     PC10     PC11     PC12     PC13     PC14     PC15     PC16 
1.496908 1.432142 1.426444 1.405155 1.391348 1.349172 1.349172 1.315284 
    PC17     PC18     PC19     PC20     PC21     PC22     PC23     PC24 
1.313187 1.311801 1.291201 1.206484 1.188438 1.187503 1.171215 1.170947 
    PC25     PC26     PC27 
1.170380 1.162497 1.162355 
> 
> ## formula interface, but as above
> mod2 <- pcr(SumSST ~ ., data = ImbrieKipp, tranFun = Hellinger)
> mod2

	Principal Component Regression Model

Call:
pcr(formula = SumSST ~ ., data = ImbrieKipp, tranFun = Hellinger)

No. of Components: 27

RMSE (Apparent):
     PC1      PC2      PC3      PC4      PC5      PC6      PC7      PC8 
2.381215 1.707588 1.680896 1.679774 1.608903 1.535145 1.507995 1.496939 
     PC9     PC10     PC11     PC12     PC13     PC14     PC15     PC16 
1.496908 1.432142 1.426444 1.405155 1.391348 1.349172 1.349172 1.315284 
    PC17     PC18     PC19     PC20     PC21     PC22     PC23     PC24 
1.313187 1.311801 1.291201 1.206484 1.188438 1.187503 1.171215 1.170947 
    PC25     PC26     PC27 
1.170380 1.162497 1.162355 
> 
> ## Several standard methods are available
> fitted(mod, comps = 1:4)
               PC1       PC2       PC3       PC4
V14.61   10.555808  6.619315  6.231607  6.223489
V17.196  10.426913  6.642886  6.321525  6.331140
V18.110  10.046044  6.588254  6.229915  6.213675
V16.227   9.934414  6.385660  6.125620  6.122140
V14.47   10.344901  8.688447  8.462348  8.415080
V23.22    9.380071  7.894699  8.078653  8.121775
V2.12    10.327887  6.574059  6.254559  6.245294
V23.29   11.220420 11.010411 11.624394 11.747316
V12.43   10.262113 10.898128 11.104700 11.068104
R9.7     12.341125 12.821689 13.524704 13.647164
A157.3   11.858419 12.965630 13.111907 13.066726
V23.81   14.593051 16.556046 17.227016 17.277798
V23.82   13.336231 14.880487 15.434312 15.449878
V12.53   13.710271 16.082667 16.071022 16.031209
V23.83   12.848861 14.545725 15.164077 15.181428
V12.56   16.776159 19.280888 18.991744 18.968327
A152.84  17.077391 19.199983 19.242103 19.297802
V16.50   16.263966 18.370537 18.123056 18.017602
V22.122  14.919350 17.161238 17.120519 16.994304
V16.41   21.781309 23.324942 23.009634 22.922366
V4.32    20.986958 22.505015 22.408206 22.462948
V12.66   19.028806 20.660237 20.722466 20.672507
V19.245  21.247213 22.864519 22.688461 22.571391
V4.8     20.751607 22.455502 22.271175 22.373501
A180.15  19.780414 21.697544 21.557218 21.601158
V18.34   21.872722 23.281368 22.901843 22.877120
V20.213  22.441029 23.899982 23.607650 23.642023
V19.222  22.079376 23.527630 23.455039 23.419094
A180.39  24.324601 25.324928 25.201835 25.156614
V16.189  26.545437 26.689606 26.485185 26.482065
V12.18   25.921284 26.412748 26.169977 26.243723
V7.67    22.963671 24.469206 24.259184 24.257127
V17.165  22.963501 24.371047 23.989180 24.069959
V19.310  22.547546 24.259671 24.000703 24.001026
V16.190  24.465707 25.339617 25.171419 25.161826
A153.154 25.998933 26.517402 26.140467 26.233199
V19.308  26.524374 26.827078 26.364425 26.460970
V22.172  27.461512 27.008179 27.100808 27.101809
V10.98   23.296429 24.340573 24.058102 24.033477
V22.219  25.575392 26.028292 25.614264 25.698634
V16.33   26.871770 26.473815 26.393492 26.301020
V22.204  26.415256 26.199712 26.432944 26.417952
V20.167  28.638137 27.643128 27.607118 27.617569
V10.89   27.604368 27.152325 27.013009 27.101828
V12.79   26.985569 26.512017 26.775884 26.753831
V19.216  26.318526 26.447055 26.447463 26.376106
V14.90   26.549162 25.911084 26.210126 26.227570
A180.72  27.195719 26.297326 26.561474 26.539114
V16.21   28.761788 27.523073 27.513898 27.575058
A180.76  28.066329 26.901275 27.191136 27.188959
V15.164  28.684206 27.361226 27.427899 27.467281
A180.78  25.584535 24.635575 25.160030 25.050603
V14.5    28.541053 27.094016 27.361091 27.330425
V3.128   28.020994 26.998395 27.075575 27.024086
A179.13  27.854058 26.920927 26.758398 26.900515
V9.31    26.315023 25.337387 25.675590 25.682354
V20.230  27.958050 26.757884 27.073016 27.065162
V20.7    28.472945 26.743289 26.778757 26.706427
V20.234  28.285842 26.960325 27.241527 27.229153
V18.21   28.619852 27.033444 27.307550 27.256230
V12.122  28.375604 27.024886 27.273001 27.225971
> resid(mod, comps = 1:4)
                 PC1         PC2         PC3         PC4
V14.61   -8.55580828 -4.61931539 -4.23160689 -4.22348927
V17.196  -5.42691346 -1.64288550 -1.32152484 -1.33114042
V18.110  -4.54604377 -1.08825356 -0.72991536 -0.71367516
V16.227  -2.93441364  0.61433992  0.87437956  0.87785995
V14.47   -3.34490101 -1.68844684 -1.46234814 -1.41507982
V23.22    1.11992858  2.60530095  2.42134659  2.37822477
V2.12     0.67211261  4.42594079  4.74544141  4.75470567
V23.29   -1.22042034 -1.01041144 -1.62439376 -1.74731557
V12.43    2.73788748  2.10187177  1.89529962  1.93189598
R9.7     -0.34112536 -0.82168936 -1.52470351 -1.64716394
A157.3    2.14158093  1.03436954  0.88809328  0.93327443
V23.81   -0.09305088 -2.05604621 -2.72701564 -2.77779830
V23.82    1.66376884  0.11951252 -0.43431226 -0.44987757
V12.53    0.78972926 -1.58266660 -1.57102151 -1.53120873
V23.83    3.15113866  1.45427521  0.83592257  0.81857207
V12.56    1.22384150 -1.28088823 -0.99174384 -0.96832655
A152.84   2.92260950  0.80001714  0.75789671  0.70219785
V16.50    1.73603415 -0.37053699 -0.12305564 -0.01760185
V22.122   4.08064989  1.83876237  1.87948061  2.00569618
V16.41   -3.28130912 -4.82494212 -4.50963378 -4.42236632
V4.32     0.51304180 -1.00501470 -0.90820579 -0.96294823
V12.66    1.97119373  0.33976296  0.27753388  0.32749338
V19.245  -0.24721268 -1.86451920 -1.68846065 -1.57139122
V4.8      3.24839261  1.54449833  1.72882462  1.62649913
A180.15   4.21958575  2.30245555  2.44278198  2.39884202
V18.34    1.12727837 -0.28136770  0.09815736  0.12288040
V20.213   1.55897133  0.10001846  0.39235035  0.35797682
V19.222   0.92062407 -0.52762978 -0.45503949 -0.41909357
A180.39  -1.32460093 -2.32492753 -2.20183543 -2.15661410
V16.189  -2.54543712 -2.68960583 -2.48518493 -2.48206451
V12.18   -0.92128430 -1.41274773 -1.16997716 -1.24372269
V7.67     3.03632898  1.53079362  1.74081620  1.74287253
V17.165   3.03649858  1.62895270  2.01081972  1.93004135
V19.310   3.45245449  1.74032881  1.99929681  1.99897351
V16.190   0.53429312 -0.33961708 -0.17141935 -0.16182624
A153.154  0.00106744 -0.51740153 -0.14046678 -0.23319938
V19.308  -0.52437386 -0.82707755 -0.36442472 -0.46096976
V22.172  -2.96151168 -2.50817888 -2.60080768 -2.60180880
V10.98    3.70357142  2.65942657  2.94189846  2.96652266
V22.219   0.62460843  0.17170781  0.58573582  0.50136556
V16.33   -1.87177023 -1.47381459 -1.39349177 -1.30101973
V22.204   0.08474448  0.30028792  0.06705632  0.08204839
V20.167  -2.43813701 -1.44312826 -1.40711830 -1.41756903
V10.89   -1.60436848 -1.15232531 -1.01300912 -1.10182847
V12.79   -0.98556944 -0.51201684 -0.77588414 -0.75383126
V19.216   0.68147388  0.55294527  0.55253680  0.62389450
V14.90    0.45083830  1.08891559  0.78987351  0.77242971
A180.72   0.30428130  1.20267358  0.93852585  0.96088599
V16.21   -1.76178778 -0.52307300 -0.51389825 -0.57505766
A180.76  -1.06632860  0.09872517 -0.19113579 -0.18895925
V15.164  -1.68420625 -0.36122600 -0.42789930 -0.46728143
A180.78   1.41546459  2.36442498  1.83997023  1.94939711
V14.5    -1.54105274 -0.09401624 -0.36109103 -0.33042474
V3.128    0.97900593  2.00160534  1.92442533  1.97591411
A179.13   0.64594244  1.57907275  1.74160153  1.59948509
V9.31     1.18497719  2.16261291  1.82440952  1.81764617
V20.230  -0.45805035  0.74211555  0.42698439  0.43483780
V20.7    -0.97294453  0.75671106  0.72124311  0.79357341
V20.234  -1.28584195  0.03967503 -0.24152719 -0.22915280
V18.21   -1.61985198 -0.03344370 -0.30754956 -0.25622958
V12.122  -0.37560386  0.97511353  0.72699945  0.77402942
> coef(mod, comps = 1:4)
                PC1        PC2          PC3         PC4
O.univ   0.97960861  1.2016603   1.13015179   1.1128268
G.cglob  1.13276639  1.1471271   1.00706123   1.0353731
G.ruber  8.65297976  8.4754988   8.14705363   8.2402103
G.tenel  1.24482761  1.3677458   1.21179400   1.3121058
G.saccu  4.75959547  4.2246275   4.52885172   4.3579999
G.rubes  1.02476239  0.9544143   0.94733705   0.9961300
G.pacL  -7.17321578 -9.9353151 -10.45254750 -10.4565564
G.pacR  -3.90121839 -2.3776793  -1.67789328  -1.7008174
G.bullo -3.13326388 -1.4979098  -1.17933855  -1.0882139
G.falco  0.73594411  2.1020478   1.54570170   1.6164401
G.calid  1.19625271  1.5937153   1.39718760   1.4306745
G.aequi  2.43986501  2.5052818   2.46842828   2.4770908
G.gluti  1.14851354  1.7835416   2.39612953   2.5787239
G.duter  1.69404223  1.5003410   1.70327333   1.5826949
G.infla -2.20267657  0.5541993   0.08307447  -0.1458796
G.trnL  -0.03914596  1.1190751   0.58123923   0.5835277
G.trnR   1.08435617  1.5664182   1.37083689   1.4156359
G.crasf  0.54353847  0.7381725   0.62418317   0.5621548
G.scitu  0.22989678  0.7283892   0.72644944   0.7652869
G.mentu  2.22457439  1.9158889   2.20559117   2.0235286
P.obliq  1.52543742  1.1961121   1.53168829   1.4341713
C.nitid  0.40742311  0.3362025   0.31750482   0.3386641
S.dehis  0.24717152  0.2328456   0.24478974   0.2258191
G.digit  0.41418305  0.4783198   0.43292016   0.4492291
Other    0.42771518  0.9316359   0.96369184   0.9914426
G.quin  -1.41219311 -1.0681350  -0.74369293  -0.6525037
G.hirsu -0.19363169  0.7346868   0.44297993   0.4546855
> 
> ## Eigenvalues can be extracted
> eigenvals(mod)
        PC1         PC2         PC3         PC4         PC5         PC6 
12.83557461  6.36679233  1.95151000  1.01340354  0.55172707  0.43074829 
        PC7         PC8         PC9        PC10        PC11        PC12 
 0.34535328  0.26040498  0.23688898  0.21194092  0.17845946  0.17727005 
       PC13        PC14        PC15        PC16        PC17        PC18 
 0.15110942  0.13603337  0.09872344  0.08822732  0.08410382  0.06901474 
       PC19        PC20        PC21        PC22        PC23        PC24 
 0.06059469  0.05572210  0.04438095  0.04006814  0.03096008  0.02463006 
       PC25        PC26        PC27 
 0.01848773  0.01713097  0.01028315 
> 
> ## screeplot method
> screeplot(mod)
> 
> 
> 
> cleanEx()
> nameEx("performance")
> ### * performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance
> ### Title: Transfer function model performance statistics
> ### Aliases: performance print.performance performance.wa
> ###   performance.predict.wa performance.bootstrap.wa performance.crossval
> ### Keywords: methods utilities
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> data(SumSST)
> 
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## the model performance statistics
> performance(mod)
    RMSE       R2 Avg.Bias Max.Bias 
   2.019    0.917    0.000   -3.815 
> 
> 
> 
> cleanEx()
> nameEx("plot.dissimilarities")
> ### * plot.dissimilarities
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.dissimilarities
> ### Title: Plots the distribution of extracted dissimilarities
> ### Aliases: plot.dissimilarities
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAPImbrie & Kipp and V12.122 core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

      0      10      20      30      40      50      60      70      80      90 
0.00103 0.20580 0.24673 0.27418 0.26386 0.34447 0.36276 0.39255 0.37565 0.38941 
    100     110     120     130     140     150     160     170     180     190 
0.42555 0.38787 0.42905 0.39793 0.44159 0.38670 0.38293 0.33502 0.39193 0.40225 
    200     210     220     230     240     250     260     270     280     290 
0.33727 0.36363 0.34381 0.32030 0.33913 0.33152 0.33710 0.40605 0.41771 0.35843 
    300     310     320     330     340     350     360     370     380     390 
0.36563 0.45973 0.42443 0.43737 0.36395 0.39245 0.38022 0.42119 0.38140 0.41874 
    400     410     420     430     440     450     460     470     480     490 
0.34186 0.45068 0.33572 0.40482 0.29348 0.34371 0.35648 0.33792 0.40345 0.36043 
    500     510     520     530     540     550     560     570     580     590 
0.34283 0.43705 0.36927 0.43211 0.43543 0.43002 0.37040 0.35875 0.34271 0.27971 
    600     610     620     630     640     650     660     670     680     690 
0.33571 0.43484 0.49012 0.33567 0.36832 0.34366 0.42574 0.44031 0.47852 0.35294 
    700     710     720     730     740     750     760     770     780     790 
0.40298 0.41467 0.47288 0.50627 0.38976 0.36831 0.39931 0.44974 0.50466 0.35900 
    800     810     820     830     840     850     860     870     880     890 
0.36004 0.37868 0.39429 0.33538 0.36688 0.42206 0.43431 0.42413 0.40355 0.47735 
    900     910     920     930     940     950     960     970     980     990 
0.46549 0.39262 0.40363 0.39642 0.34586 0.43115 0.41340 0.37004 0.34726 0.44592 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.37685 0.48035 0.43378 0.43677 0.46931 0.33997 0.42792 0.42910 0.37678 0.36444 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    V14.5     V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   A180.76   V12.79    V16.21    V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V22.204   V15.164   V22.219 
   7  V15.164   V20.230   V14.90    A180.72   V20.234   V20.234   V20.167 
   8  V16.21    V20.167   V20.230   V22.204   V14.90    A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V20.230   V20.230   V12.18  
  10  V20.230   V20.7     V9.31     V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V9.31     V14.90    V19.216   V14.90  
  V16.21    V16.21    V22.204   V22.204   V20.230   V22.172   V19.216 
  V14.90    V20.167   V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    V9.31     V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   A153.154  V14.90    V12.79    V20.167   V12.79  
  V20.234   A179.13   V14.90    V16.21    V22.172   A153.154  V22.204 
  V20.167   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V9.31     V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V22.204   V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V22.172 
  V20.230   V20.167   V10.89    V20.230   V14.90    V9.31     V9.31   
  V20.234   V16.21    V9.31     V16.21    V16.21    V14.90    V14.90  
  V14.90    V19.216   V19.216   V22.172   V20.230   V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V10.89    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V16.21  
  V16.21    V15.164   V16.33    V9.31     V15.164   V20.234   V12.79  
  V15.164   V20.230   V22.172   V22.219   V20.234   V16.21    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V3.128    V20.230   V14.5     V12.122   V22.172   V22.172   A180.72 
  V20.167   V18.21    V14.90    V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   V20.234   V18.21    V12.79    V12.122   V12.79  
  V20.230   V14.5     A180.76   V22.172   V12.122   A180.72   V22.204 
  V20.234   V20.234   V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   V14.5     V10.89    V20.234   V18.21  
  A180.76   A180.76   V15.164   A180.72   V9.31     A180.76   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V22.172 
  V12.122   V14.5     V19.216   V14.90    V22.172   V14.90    V10.89  
  V22.204   A180.72   V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V16.190   V14.90    A180.39   V19.308 
  V14.5     V22.172   V20.230   V20.230   V16.21    V16.190   V16.21  
  V20.234   V3.128    V9.31     V16.21    V12.122   V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V9.31     V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V20.167   V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   V22.172   V20.230 
  V14.90    V14.90    V12.122   V20.230   V9.31     A180.76   V9.31   
  V16.21    V20.234   V22.204   A180.76   V14.90    V20.230   V14.90  
  V22.172   V15.164   V20.234   V3.128    V20.234   A180.72   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V16.33    V22.204   V20.167   V19.216   V20.234 
  V15.164   V9.31     V15.164   V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V22.172   V14.90  
  V20.234   V9.31     V14.90    V20.234   V3.128    V20.167   A180.76 
  V14.90    V20.234   V20.234   V18.21    V14.5     V20.234   V22.204 
  V20.230   V14.90    V20.230   V12.122   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   A180.72   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   A180.76   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   V20.230   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V9.31   
  A180.76   V16.21    V19.216   V14.90    V15.164   V19.216   V3.128  
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  V12.122   V18.21    V20.234   V3.128    V16.21    V19.216   V22.172 
  A180.72   V20.230   V20.230   V19.216   V10.89    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.78   V12.122   V22.172   V12.79  
  V14.5     V14.5     V19.216   A180.72   V15.164   V16.21    V9.31   
  V14.90    V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V9.31     V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V12.79    V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V22.204   V22.172   A180.72   V14.90    V20.167 
  V9.31     A180.78   V14.90    V16.21    A180.76   V12.122   V19.216 
  A180.76   V14.90    A180.72   V15.164   V22.204   V22.204   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V12.79    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V3.128    V16.33  
  V20.234   V20.234   V20.234   V14.90    V20.230   A180.72   V20.230 
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  V12.122   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  A180.72   V14.5     V22.172   V22.172   V22.172   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     A180.72   V9.31     V22.172 
  V20.230   V3.128    V20.167   V3.128    V20.230   V22.204   V22.219 
  V20.234   A180.72   V14.5     V16.33    V12.122   V16.190   V22.204 
  V22.172   V18.21    V15.164   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   A180.76   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V22.172   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V12.122   V12.79    V3.128  
  V16.21    V20.234   V3.128    V20.230   V20.234   V22.172   V12.122 
  V19.216   V12.122   V10.89    V20.167   V20.230   V20.230   A180.72 
  V10.89    V22.172   V19.216   V12.122   V12.79    V12.122   V20.167 
  V15.164   V20.230   V20.167   V19.216   V20.167   V9.31     V9.31   
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V20.230 
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V19.216   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V22.204   V16.33  
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V20.167 
  V16.21    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V14.90    V22.172   V3.128    V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   A180.72   A180.72   V12.79    V20.167   V12.122 
  V9.31     A180.72   A180.76   V14.90    V14.5     A180.72   V16.190 
  A180.76   V20.230   V20.234   V16.21    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V12.79    A180.72   V9.31     V20.234 
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V22.172   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V19.216   V9.31     V19.222   V9.31   
  V22.204   V9.31     V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V19.216   V19.216   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V20.167   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V16.190 
  A180.72   A180.76   V15.164   V10.89    V12.79    V22.172   V20.230 
  V9.31     V20.230   V12.18    V16.21    V20.167   V9.31     A180.39 
  V14.90    A180.72   V9.31     V20.230   A180.72   V12.79    V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V16.21    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V14.90    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V9.31     V12.79    V22.172 
  V19.222   V22.172   V22.172   V14.90    V20.230   V16.21    V19.216 
  V12.79    V22.204   V14.90    V22.172   V12.122   V22.172   A180.76 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V12.79    V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V20.167   V20.234   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   A180.72   A179.13   V20.167   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  V22.172   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  A180.76   V12.79    V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V22.204   V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.172   V19.216   V19.216   V12.122   V22.204 
  V22.204   V14.90    V22.172   V22.172   V19.216 
  V14.90    V12.122   V22.204   V14.90    V14.90  
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V9.31   
  V16.33    V20.234   V22.219   V20.234   V20.234 
  V16.190   A180.78   V9.31     V20.230   V16.190 

Dissimilarities for k-closest analogues

   k        0       10       20       30       40       50       60       70
   1  0.00103  0.20580  0.24673  0.27418  0.26386  0.34447  0.36276  0.39255
   2  0.21926  0.25739  0.25996  0.27563  0.30406  0.37446  0.39390  0.40656
   3  0.22764  0.27592  0.31710  0.27790  0.31780  0.39293  0.40903  0.41654
   4  0.25235  0.32554  0.32341  0.28835  0.34085  0.40633  0.42194  0.42589
   5  0.30061  0.32868  0.32481  0.30522  0.36582  0.40641  0.42377  0.43659
   6  0.30975  0.35421  0.34224  0.31439  0.37089  0.41120  0.42844  0.44453
   7  0.35531  0.35967  0.35109  0.33136  0.37495  0.44233  0.42926  0.44877
   8  0.35836  0.38994  0.35184  0.33558  0.37806  0.45328  0.44222  0.44919
   9  0.36781  0.40574  0.35983  0.33957  0.37916  0.45638  0.44358  0.45148
  10  0.37869  0.41747  0.36224  0.34318  0.38376  0.47018  0.44470  0.45326
       80       90      100      110      120      130      140      150
  0.37565  0.38941  0.42555  0.38787  0.42905  0.39793  0.44159  0.38670
  0.38328  0.41811  0.44003  0.43782  0.43414  0.41478  0.44773  0.39272
  0.39373  0.48881  0.44158  0.47585  0.43742  0.41982  0.46543  0.39931
  0.39823  0.49538  0.46032  0.49080  0.45839  0.44633  0.46607  0.41529
  0.40922  0.49652  0.47914  0.50140  0.46151  0.45518  0.49664  0.41958
  0.42514  0.49977  0.48790  0.50324  0.49773  0.47669  0.50303  0.43204
  0.43004  0.50025  0.48857  0.50760  0.51037  0.47858  0.51860  0.44963
  0.43658  0.51154  0.49498  0.52084  0.51151  0.50167  0.52045  0.45103
  0.44513  0.52225  0.50037  0.52443  0.51720  0.50295  0.52303  0.45311
  0.45252  0.52647  0.50246  0.52830  0.51885  0.50685  0.52703  0.46088
      160      170      180      190      200      210      220      230
  0.38293  0.33502  0.39193  0.40225  0.33727  0.36363  0.34381  0.32030
  0.42073  0.35365  0.41730  0.42194  0.37912  0.37707  0.39682  0.38325
  0.42142  0.35801  0.42523  0.42892  0.37923  0.38217  0.40051  0.38838
  0.42358  0.35938  0.44208  0.42991  0.37958  0.38290  0.40217  0.38888
  0.42704  0.36539  0.44270  0.45998  0.39387  0.39557  0.40404  0.40040
  0.43300  0.37745  0.44504  0.47036  0.40623  0.41859  0.40794  0.40209
  0.43541  0.37954  0.44894  0.47164  0.40837  0.42067  0.40832  0.41708
  0.43601  0.38858  0.46754  0.49113  0.41674  0.42769  0.41381  0.42265
  0.43714  0.40494  0.48654  0.50343  0.41835  0.42988  0.42134  0.43017
  0.43951  0.41634  0.51293  0.50538  0.42756  0.43470  0.43477  0.44040
      240      250      260      270      280      290      300      310
  0.33913  0.33152  0.33710  0.40605  0.41771  0.35843  0.36563  0.45973
  0.43491  0.38350  0.37142  0.42917  0.44705  0.37742  0.37086  0.47899
  0.43793  0.40723  0.37189  0.44690  0.44740  0.41176  0.37251  0.48393
  0.44636  0.42500  0.38672  0.45761  0.44923  0.41600  0.39375  0.50345
  0.45073  0.43560  0.39042  0.45814  0.46229  0.41923  0.40068  0.51087
  0.46334  0.43976  0.39826  0.47164  0.46240  0.42384  0.40753  0.53673
  0.47192  0.44086  0.40691  0.47951  0.46816  0.42613  0.40881  0.54013
  0.47705  0.45178  0.42084  0.48167  0.47171  0.45453  0.42049  0.54410
  0.48299  0.45330  0.42890  0.48300  0.48737  0.46290  0.42621  0.54547
  0.48493  0.45447  0.42990  0.49926  0.49628  0.46477  0.42883  0.54979
      320      330      340      350      360      370      380      390
  0.42443  0.43737  0.36395  0.39245  0.38022  0.42119  0.38140  0.41874
  0.43637  0.44053  0.39057  0.39936  0.39218  0.43332  0.39492  0.43403
  0.44000  0.44600  0.39337  0.40290  0.39593  0.43806  0.39738  0.46329
  0.46298  0.44996  0.40433  0.41662  0.40214  0.45921  0.40898  0.47115
  0.46331  0.46518  0.41291  0.42198  0.40240  0.46164  0.42888  0.47265
  0.46597  0.46629  0.43428  0.43209  0.40373  0.46197  0.44031  0.47610
  0.48042  0.47581  0.43880  0.43662  0.41511  0.48247  0.44213  0.47867
  0.48123  0.48338  0.44066  0.44473  0.41555  0.48825  0.45137  0.48915
  0.48617  0.48487  0.44221  0.45851  0.43056  0.49824  0.45198  0.49337
  0.49358  0.48922  0.44471  0.46839  0.43321  0.49865  0.45360  0.49529
      400      410      420      430      440      450      460      470
  0.34186  0.45068  0.33572  0.40482  0.29348  0.34371  0.35648  0.33792
  0.34991  0.45175  0.36469  0.44423  0.38508  0.35718  0.36784  0.34111
  0.41192  0.46582  0.36937  0.45030  0.39283  0.35826  0.41164  0.35165
  0.43330  0.46696  0.37115  0.45228  0.39672  0.37215  0.43668  0.35420
  0.43337  0.46808  0.37852  0.45328  0.43506  0.37371  0.45585  0.35844
  0.43511  0.47270  0.38145  0.45970  0.44118  0.37755  0.45732  0.35976
  0.43513  0.47773  0.39823  0.47916  0.44271  0.38953  0.45870  0.36097
  0.44033  0.48489  0.40172  0.48579  0.44310  0.40641  0.47307  0.36831
  0.44870  0.48657  0.40807  0.49068  0.44708  0.40658  0.47475  0.37386
  0.45318  0.50251  0.41416  0.50332  0.45294  0.41187  0.47622  0.37955
      480      490      500      510      520      530      540      550
  0.40345  0.36043  0.34283  0.43705  0.36927  0.43211  0.43543  0.43002
  0.40441  0.36855  0.35345  0.46671  0.41872  0.44491  0.43957  0.43063
  0.41353  0.37734  0.38501  0.47403  0.43053  0.44512  0.44428  0.43896
  0.41798  0.37964  0.38632  0.47959  0.45074  0.44660  0.45577  0.44389
  0.42943  0.37977  0.38665  0.49918  0.45563  0.44827  0.46556  0.45327
  0.43747  0.38713  0.40339  0.50420  0.46353  0.45752  0.47245  0.47124
  0.44122  0.39121  0.40627  0.51011  0.46961  0.46611  0.47683  0.49380
  0.44847  0.39921  0.41472  0.51385  0.47100  0.46798  0.48757  0.49383
  0.46854  0.40065  0.43965  0.52002  0.47818  0.48314  0.49310  0.50217
  0.47023  0.40443  0.43974  0.52114  0.48214  0.49092  0.49870  0.50396
      560      570      580      590      600      610      620      630
  0.37040  0.35875  0.34271  0.27971  0.33571  0.43484  0.49012  0.33567
  0.38072  0.35951  0.34339  0.34208  0.38491  0.43992  0.49519  0.42507
  0.42074  0.39751  0.35652  0.34407  0.38894  0.44648  0.50221  0.43324
  0.42443  0.40370  0.37124  0.34924  0.39580  0.44674  0.50842  0.43508
  0.42906  0.41337  0.37156  0.35570  0.41571  0.45201  0.51252  0.43625
  0.44200  0.41589  0.38380  0.36003  0.42445  0.46094  0.51440  0.43725
  0.45587  0.42660  0.41861  0.36856  0.42763  0.48917  0.51938  0.44659
  0.45875  0.42973  0.43173  0.37838  0.43509  0.49194  0.53311  0.44729
  0.47266  0.43325  0.43779  0.39153  0.43953  0.49258  0.54249  0.45796
  0.47929  0.43998  0.45290  0.39361  0.44359  0.49889  0.54275  0.47429
      640      650      660      670      680      690      700      710
  0.36832  0.34366  0.42574  0.44031  0.47852  0.35294  0.40298  0.41467
  0.38040  0.36740  0.42849  0.44563  0.49456  0.38960  0.40559  0.44073
  0.39369  0.39622  0.43216  0.46273  0.50097  0.39700  0.43168  0.44906
  0.39814  0.40695  0.43746  0.46699  0.53400  0.40936  0.44151  0.46036
  0.39920  0.42655  0.44064  0.47664  0.53555  0.42450  0.46275  0.47714
  0.41661  0.43192  0.44692  0.47983  0.54447  0.49552  0.48112  0.48072
  0.42091  0.43694  0.45318  0.48334  0.56143  0.50583  0.48306  0.48187
  0.42264  0.44326  0.45852  0.48343  0.57179  0.50801  0.48710  0.49356
  0.42736  0.44996  0.47026  0.49696  0.57843  0.51166  0.48900  0.49472
  0.43567  0.45079  0.48020  0.49727  0.58595  0.51894  0.49570  0.50009
      720      730      740      750      760      770      780      790
  0.47288  0.50627  0.38976  0.36831  0.39931  0.44974  0.50466  0.35900
  0.48088  0.51314  0.40104  0.40076  0.42345  0.45358  0.51282  0.37602
  0.49369  0.52138  0.41910  0.40345  0.43136  0.47755  0.54873  0.41955
  0.50520  0.52530  0.43006  0.42038  0.43481  0.48763  0.55591  0.43657
  0.50607  0.52923  0.43055  0.42832  0.43677  0.48881  0.56285  0.44149
  0.51746  0.53209  0.43311  0.42876  0.43792  0.49011  0.56390  0.44788
  0.53014  0.53550  0.43939  0.43684  0.43856  0.50267  0.57193  0.44868
  0.53168  0.54400  0.43949  0.43941  0.43861  0.50507  0.58244  0.45431
  0.54051  0.56067  0.44196  0.44065  0.45539  0.50910  0.58758  0.45550
  0.54257  0.56119  0.45051  0.45033  0.46033  0.51034  0.58862  0.46583
      800      810      820      830      840      850      860      870
  0.36004  0.37868  0.39429  0.33538  0.36688  0.42206  0.43431  0.42413
  0.38321  0.38887  0.42610  0.42583  0.40565  0.44871  0.45531  0.42431
  0.40486  0.39989  0.42629  0.43253  0.44404  0.45044  0.46005  0.43743
  0.42331  0.40523  0.45518  0.43383  0.45330  0.45122  0.46880  0.44596
  0.43776  0.40622  0.45746  0.45336  0.47275  0.46041  0.46907  0.46783
  0.44750  0.41167  0.46768  0.46708  0.47505  0.46049  0.47745  0.47982
  0.45170  0.41424  0.48039  0.47255  0.48153  0.48548  0.49358  0.48918
  0.45279  0.42337  0.48113  0.47697  0.49428  0.48802  0.49752  0.49125
  0.46725  0.42632  0.50986  0.48376  0.49672  0.48810  0.50827  0.51282
  0.46736  0.43076  0.51092  0.49359  0.50170  0.49491  0.51377  0.51781
      880      890      900      910      920      930      940      950
  0.40355  0.47735  0.46549  0.39262  0.40363  0.39642  0.34586  0.43115
  0.45557  0.50117  0.51492  0.46424  0.48709  0.42105  0.38375  0.43440
  0.47207  0.51009  0.54278  0.46997  0.52705  0.47301  0.39410  0.43534
  0.48705  0.51495  0.54909  0.47603  0.54523  0.48907  0.40882  0.44430
  0.49363  0.51757  0.55462  0.47839  0.54877  0.49890  0.41606  0.44454
  0.49624  0.52245  0.56395  0.49422  0.55045  0.51677  0.42172  0.44704
  0.50072  0.56077  0.57732  0.50829  0.55931  0.51826  0.45078  0.45516
  0.50353  0.56545  0.57862  0.51014  0.56003  0.52177  0.45173  0.46725
  0.51047  0.57039  0.59138  0.51932  0.56395  0.52257  0.46965  0.47445
  0.52602  0.57043  0.59688  0.52392  0.57118  0.53575  0.47191  0.48273
      960      970      980      990     1000     1010     1020     1030
  0.41340  0.37004  0.34726  0.44592  0.37685  0.48035  0.43378  0.43677
  0.41617  0.39179  0.40365  0.46708  0.37994  0.48239  0.50875  0.45307
  0.42197  0.39649  0.41422  0.46999  0.39647  0.51079  0.51194  0.45368
  0.43702  0.40046  0.44031  0.47625  0.39863  0.52011  0.52269  0.45856
  0.43837  0.40837  0.45618  0.48750  0.41329  0.52876  0.52569  0.47290
  0.44038  0.40845  0.45716  0.49802  0.42198  0.54004  0.53390  0.50031
  0.45028  0.40923  0.46432  0.49867  0.45919  0.54191  0.54819  0.52081
  0.45281  0.42071  0.46493  0.51410  0.46491  0.56273  0.54977  0.53488
  0.45948  0.42644  0.47039  0.51686  0.47031  0.56672  0.56705  0.54430
  0.46422  0.42747  0.47740  0.52783  0.47558  0.57032  0.57449  0.54835
     1040     1050     1060     1070     1080     1090
  0.46931  0.33997  0.42792  0.42910  0.37678  0.36444
  0.50089  0.40625  0.43916  0.43215  0.39138  0.37379
  0.53353  0.40803  0.50134  0.45058  0.39631  0.37446
  0.55156  0.40892  0.51540  0.45621  0.40649  0.37467
  0.55601  0.43962  0.51967  0.46166  0.42668  0.42026
  0.56071  0.46096  0.52125  0.47752  0.44332  0.43487
  0.56228  0.46564  0.53512  0.48548  0.44590  0.43999
  0.56837  0.46820  0.53823  0.50018  0.45501  0.44285
  0.57103  0.47784  0.54993  0.51040  0.45627  0.44430
  0.57641  0.48217  0.56053  0.51838  0.45860  0.45217

> 
> ## compare training set dissimilarities with normals
> ## and derive cut-offs
> ik.dij <- dissim(ik.analog)
> plot(ik.dij)
> 
> 
> 
> cleanEx()
> nameEx("plot.mat")
> ### * plot.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.mat
> ### Title: Plot diagnostics for a mat object
> ### Aliases: plot.mat
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## MAT
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> 
> ## summary plot of MAT model
> layout(matrix(1:4, ncol = 2, byrow = TRUE))
> plot(ik.mat)
> layout(1)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.mcarlo")
> ### * plot.mcarlo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.mcarlo
> ### Title: Plot Monte Carlo simulated dissimilarity distributions
> ### Aliases: plot.mcarlo
> ### Keywords: hplot multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## perform the modified method of Sawada (2004) - paired sampling,
> ## with replacement
> ik.mcarlo <- mcarlo(ImbrieKipp, method = "chord", nsamp = 1000,
+                     type = "paired", replace = FALSE)
> ik.mcarlo

	Simulated Dissimilarities

Simulation type : paired 
No. simulations : 1000 
Coefficient     : chord 

Summary of simulated distribution:
    Min 1st Qu.  Median    Mean 3rd Qu.     Max 
 0.0917  1.3141  1.3698  1.2303  1.4061  1.4119 

Percentiles of simulated distribution:
    1%   2.5%     5%    10%    90%    95%  97.5%    99% 
0.0917 0.1035 0.1301 0.6572 1.4112 1.4115 1.4116 1.4119 

> 
> ## plot the simulated distribution
> layout(matrix(1:2, ncol = 1))
> plot(ik.mcarlo)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("plot.minDC")
> ### * plot.minDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.minDC
> ### Title: Plot of minimum dissimilarity per sample
> ### Aliases: plot.minDC
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## reconstruct for the RLGH core data
> v12.mat <- predict(ik.mat, V12.122)
> 
> ## extract the minimum DC values
> v12.mdc <- minDC(v12.mat)
> v12.mdc

	Minimum dissimilarity per sample

Dissimilarity: chord 

      0      10      20      30      40      50      60      70      80      90 
0.00103 0.20580 0.24673 0.27418 0.26386 0.34447 0.36276 0.39255 0.37565 0.38941 
    100     110     120     130     140     150     160     170     180     190 
0.42555 0.38787 0.42905 0.39793 0.44159 0.38670 0.38293 0.33502 0.39193 0.40225 
    200     210     220     230     240     250     260     270     280     290 
0.33727 0.36363 0.34381 0.32030 0.33913 0.33152 0.33710 0.40605 0.41771 0.35843 
    300     310     320     330     340     350     360     370     380     390 
0.36563 0.45973 0.42443 0.43737 0.36395 0.39245 0.38022 0.42119 0.38140 0.41874 
    400     410     420     430     440     450     460     470     480     490 
0.34186 0.45068 0.33572 0.40482 0.29348 0.34371 0.35648 0.33792 0.40345 0.36043 
    500     510     520     530     540     550     560     570     580     590 
0.34283 0.43705 0.36927 0.43211 0.43543 0.43002 0.37040 0.35875 0.34271 0.27971 
    600     610     620     630     640     650     660     670     680     690 
0.33571 0.43484 0.49012 0.33567 0.36832 0.34366 0.42574 0.44031 0.47852 0.35294 
    700     710     720     730     740     750     760     770     780     790 
0.40298 0.41467 0.47288 0.50627 0.38976 0.36831 0.39931 0.44974 0.50466 0.35900 
    800     810     820     830     840     850     860     870     880     890 
0.36004 0.37868 0.39429 0.33538 0.36688 0.42206 0.43431 0.42413 0.40355 0.47735 
    900     910     920     930     940     950     960     970     980     990 
0.46549 0.39262 0.40363 0.39642 0.34586 0.43115 0.41340 0.37004 0.34726 0.44592 
   1000    1010    1020    1030    1040    1050    1060    1070    1080    1090 
0.37685 0.48035 0.43378 0.43677 0.46931 0.33997 0.42792 0.42910 0.37678 0.36444 
> 
> ## draw a plot of minimum DC by time
> plot(v12.mdc, use.labels = TRUE, xlab = "Depth (cm.)")
> 
> 
> 
> cleanEx()
> nameEx("plot.prcurve")
> ### * plot.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.prcurve
> ### Title: Plot a fitted principal curve in PCA space
> ### Aliases: plot.prcurve lines.prcurve
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.692
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.498
Iteration   6: d.sq: 4369.945

PC Converged in 6 iterations.

> 
> ## Plot the curve
> plot(aber.pc)
> 
> ## The lines() method can be used to add the principal curve to an
> ## existing plot
> ord <- rda(abernethy2)
> plot(ord, scaling = 1)
> lines(aber.pc, scaling = 1)
> 
> 
> 
> cleanEx()
> nameEx("plot.residLen")
> ### * plot.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.residLen
> ### Title: Plot method for residual lengths
> ### Aliases: plot.residLen
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                 50%   75%   90%   95%   99%
Training Set: 0.8542 1.556 2.454 2.611 3.719
Passive:      1.0039 1.505 1.870 2.171 2.549
> 
> ## plot a histogram of the residual distances
> plot(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.wa")
> ### * plot.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.wa
> ### Title: Plot diagnostics for a weighted averaging model
> ### Aliases: plot.wa
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## see full example in ?wa
> 
> 
> 
> 
> cleanEx()
> nameEx("prcurve")
> ### * prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: prcurve
> ### Title: Fits a principal curve to m-dimensional data
> ### Aliases: prcurve initCurve print.prcurve
> ### Keywords: multivariate nonparametric smooth
> 
> ### ** Examples
> 
> ## Load Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using the median complexity over
> ## all species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = FALSE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4853.791
Iteration   2: d.sq: 5013.497
Iteration   3: d.sq: 5109.972
Iteration   4: d.sq: 5135.655
Iteration   5: d.sq: 5137.944

PC Converged in 5 iterations.

> 
> ## Extract fitted values
> fit <- fitted(aber.pc) ## locations on curve
> abun <- fitted(aber.pc, type = "smooths") ## fitted response
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc2 <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                     vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.692
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.498
Iteration   6: d.sq: 4369.945

PC Converged in 6 iterations.

> 
> ## Predict new locations
> take <- abernethy2[1:10, ]
> pred <- predict(aber.pc2, take)
> 
> ## Not run: 
> ##D ## Fit principal curve using a GAM - currently slow ~10secs
> ##D aber.pc3 <- prcurve(abernethy2 / 100, method = "ca", trace = TRUE,
> ##D                     vary = TRUE, smoother = smoothGAM, bs = "cr", family = mgcv::betar())
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("predict.mat")
> ### * predict.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.mat
> ### Title: Predict method for Modern Analogue Technique models
> ### Aliases: predict.mat print.predict.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## predict for V12.122 data
> predict(ik.mat, V12.122)

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? TRUE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
    1.713     0.941     0.133     5.167 

Predicted values:
   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
27.3 27.3 27.3 26.3 25.9 25.9 25.5 25.8 26.2 26.0 27.0 27.3 26.3 27.2 26.5 25.6 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
26.6 26.6 27.2 27.3 26.5 26.8 27.5 27.3 27.7 26.0 25.9 26.3 26.5 27.3 25.9 26.3 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
26.3 26.2 25.8 27.1 25.9 25.9 27.5 26.8 27.0 27.7 27.2 27.5 27.2 27.0 27.4 25.9 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
26.8 27.7 27.3 27.0 27.0 25.9 26.1 26.2 27.3 27.3 26.5 25.9 27.2 27.1 26.6 27.2 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
27.3 27.2 26.8 27.0 26.8 27.2 26.9 27.4 26.2 27.8 27.0 26.8 26.8 27.4 27.7 27.3 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
27.3 26.5 26.8 25.5 26.2 27.0 26.0 25.9 26.3 25.0 26.8 26.2 26.5 27.3 27.3 26.7 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
27.5 27.3 27.3 27.3 26.2 27.3 26.2 26.2 27.0 26.0 26.8 25.5 26.5 26.0 
> 
> 
> 
> 
> cleanEx()
> nameEx("predict.pcr")
> ### * predict.pcr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.pcr
> ### Title: Predicted values from a principal components regression
> ### Aliases: predict.pcr
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## choose 10 samples to act as a test set, for illustration
> take <- c(5,58,31,51,42,28,30,57,8,50)
> 
> ## normal interface and apply Hellinger transformation
> mod <- pcr(ImbrieKipp[-take, ], SumSST[-take], tranFun = Hellinger)
> 
> ## predictions
> predict(mod, ImbrieKipp[take, ], ncomp = 4)
             PC1       PC2       PC3       PC4
V14.47  10.34383  8.964025  8.816845  8.700079
V20.7   28.37448 26.720456 26.781783 26.619102
V12.18  26.20249 26.438019 26.250313 26.405603
V15.164 28.73089 27.389314 27.464025 27.556603
V22.204 26.62995 26.287830 26.489270 26.472449
V19.222 22.51833 23.657659 23.610868 23.537830
V16.189 26.73964 26.671009 26.551076 26.529436
V20.230 28.03053 26.819795 27.094141 27.094730
V23.29  11.45795 11.373413 11.816852 12.136959
A180.76 28.15434 26.970442 27.221069 27.230316
> 
> ## predictions
> set.seed(123)
> predict(mod, ImbrieKipp[take, ], ncomp = 4, CV = "bootstrap",
+         nboot = 100)
             PC1       PC2       PC3       PC4
V14.47  11.55010  9.348342  8.960988  8.817489
V20.7   28.07820 26.738470 26.779099 26.635267
V12.18  25.96975 26.424955 26.238402 26.362456
V15.164 28.36045 27.345663 27.406875 27.473833
V22.204 26.37709 26.167932 26.415661 26.448602
V19.222 22.53749 23.598338 23.592702 23.563523
V16.189 26.46990 26.647118 26.535589 26.459101
V20.230 27.70697 26.712670 27.021555 27.055070
V23.29  12.41973 11.359155 11.705860 12.087577
A180.76 27.82252 26.868605 27.150974 27.213954
> 
> 
> 
> 
> cleanEx()
> nameEx("predict.wa")
> ### * predict.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.wa
> ### Title: Predict from a weighted average model
> ### Aliases: predict.wa print.predict.wa
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp
> data(ImbrieKipp)
> ImbrieKipp <- ImbrieKipp / 100
> data(SumSST)
> ik.wa <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+             min.tol = 2, small.tol = "min")
> ik.wa

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## load V12.122 core data
> data(V12.122)
> V12.122 <- V12.122 / 100
> 
> ## predict summer sea-surface temperature for V12.122 core
> set.seed(2)
> v12.pred <- predict(ik.wa, V12.122, CV = "bootstrap", n.boot = 100)
> 
> ## draw the fitted reconstruction
> reconPlot(v12.pred, use.labels = TRUE, display = "bars")
> 
> ## extract the model performance stats
> performance(v12.pred)
   RMSEP       R2 Avg.Bias Max.Bias 
  2.3306   0.8985  -0.0921  -3.0460 
> 
> 
> 
> 
> cleanEx()
> nameEx("rankDC")
> ### * rankDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rankDC
> ### Title: Rank correlation between environmental and species
> ###   dissimilarities.
> ### Aliases: rankDC print.rankDC plot.rankDC dotplot.rankDC dotplot
> ### Keywords: hplot methods utilities multivariate
> 
> ### ** Examples
> 
> data(swappH)
> data(swapdiat)
> 
> rc <- rankDC(swappH, swapdiat, dc = c("chord","euclidean","gower"))
> 
> ## base plot uses dotchart()
> plot(rc)
> 
> ## lattice version of the base plot
> dotplot(rc)
> 
> 
> 
> 
> cleanEx()
> nameEx("reconPlot")
> ### * reconPlot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: reconPlot
> ### Title: Stratigraphic plots of palaeoenvironmental reconstructions
> ### Aliases: reconPlot reconPlot.default reconPlot.predict.mat
> ###   reconPlot.predict.wa
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Fit a MAT model
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## Reconstruct pH for the RLGH core
> v12.pH <- predict(ik.mat, V12.122)
> 
> ## draw the reconstruction
> reconPlot(v12.pH, use.labels = TRUE, display.error = "bars",
+           xlab = "Depth", ylab = "Summer Seas-surface Temperature")
> 
> 
> 
> cleanEx()
> nameEx("residLen")
> ### * residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residLen
> ### Title: Squared residual length diagnostics
> ### Aliases: residLen print.residLen fittedY sqrlLinear sqrlUnimodal
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                 50%   75%   90%   95%   99%
Training Set: 0.8542 1.556 2.454 2.611 3.719
Passive:      1.0039 1.505 1.870 2.171 2.549
> 
> ## as before but using linear RDA
> residLen(ImbrieKipp, SumSST, V12.122, method = "rda")

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122, method
= "rda")

Ordination Method: rda

Quantiles of residual lengths:

                50%   75%    90%    95%   99%
Training Set: 17.44 40.34  80.61  85.39 103.9
Passive:      71.71 84.89 100.44 103.59 116.1
> 
> 
> 
> cleanEx()
> nameEx("residuals.prcurve")
> ### * residuals.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residuals.prcurve
> ### Title: Residuals of a principal curve fit.
> ### Aliases: residuals.prcurve resid.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
>   ## Don't show: 
> od <- options(digits = 4)
> ## End(Don't show)
>   ## Load Abernethy Forest data set
>   data(abernethy)
> 
>   ## Remove the Depth and Age variables
>   abernethy2 <- abernethy[, -(37:38)]
>   
>   ## Fit the principal curve, preserving the data in the smooth.spline
>   ## smooth functions fitted via keep.data = TRUE
>   aber.pc <- prcurve(abernethy2, method = "ca", keep.data = TRUE)
> 
>   ## default "distance" residuals
>   res <- resid(aber.pc)
>   head(res)
     1      2      3      4      5      6 
14.265  3.340  4.535  7.343  1.396  2.277 
> 
>   ## residuals from the underlying smooth models, also illustrates
>   ## how to select specific types of residual from the individual
>   ## method using argument 'type'
>   res <- resid(aber.pc, which = "smooths", type = "deviance")
>   dim(res)
[1] 49 36
>   head(res[, 1:5])		# just show a few species residuals
      Betula Pinus sylvestris    Ulmus  Quercus Alnus glutinosa
[1,] -2.3568           0.1292 -0.01392  0.07942         -0.0262
[2,] -0.4075          -2.4924 -0.03967  0.03462          0.3272
[3,]  3.1796           0.4291 -0.04390  0.02585         -0.2616
[4,]  1.5921          -0.1065  0.29853 -0.02990          0.1526
[5,]  0.5507           0.5888 -0.06465 -0.05367         -0.1917
[6,] -0.9363           1.5699 -0.06975 -0.12032          0.1378
>   ## Don't show: 
> options(od)
> ## End(Don't show)
> 
> 
> 
> cleanEx()
> nameEx("rlgh")
> ### * rlgh
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rlgh
> ### Title: Round Loch of Glenhead Diatoms
> ### Aliases: rlgh
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(rlgh)
> 
> 
> 
> cleanEx()
> nameEx("roc")
> ### * roc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: roc
> ### Title: ROC curve analysis
> ### Aliases: roc roc.default roc.mat roc.analog print.roc summary.roc
> ###   print.summary.roc
> ### Keywords: models multivariate methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 12)
> 
> ## fit the ROC curve
> swap.roc <- roc(swap.ana, groups = grps)
> swap.roc

	ROC curve of dissimilarities

Discrimination for all groups:

Optimal Dissimilarity = 0.575 

AUC = 0.974, p-value: < 2.22e-16
No. within: 167   No. outside: 1837 

> 
> ## draw the ROC curve
> plot(swap.roc, 1)
> 
> ## draw the four default diagnostic plots
> layout(matrix(1:4, ncol = 2))
> plot(swap.roc)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("scores.prcurve")
> ### * scores.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: scores.prcurve
> ### Title: 'scores' method for principal curve objects of class
> ###   '"prcurve"'.
> ### Aliases: scores.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.692
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.498
Iteration   6: d.sq: 4369.945

PC Converged in 6 iterations.

> 
> ## Extract position on the curve
> pos <- scores(aber.pc, display = "curve")
> head(pos)
       PrC
1 251.3134
2 253.7651
3 273.9467
4 267.3053
5 286.3480
6 277.9563
> 
> ## Extract the coordinates of the curve
> coord <- scores(aber.pc, display = "dimensions")
> dim(coord)
[1] 49 36
> all.equal(dim(coord), dim(abernethy2))
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("screeplot")
> ### * screeplot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: screeplot
> ### Title: Screeplots of model results
> ### Aliases: screeplot.mat screeplot.bootstrap.mat
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> screeplot(ik.mat)
> 
> 
> 
> cleanEx()
> nameEx("splitSample")
> ### * splitSample
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: splitSample
> ### Title: Select samples from along an environmental gradient
> ### Aliases: splitSample
> ### Keywords: manip utilities
> 
> ### ** Examples
> 
> data(swappH)
> 
> ## take a test set of 20 samples along the pH gradient
> test1 <- splitSample(swappH, chunk = 10, take = 20)
> test1
 [1]  48  21  34   3  19 148  87  93  26 141  64  16  58 158  86 120 163 144  18
[20] 133
attr(,"lengths")
 [1] 2 2 2 2 2 2 2 2 2 2
> swappH[test1]
 BER1  4.11 80.11    11 34.11  SKE1  IRD1 LCSU1 59.11   S41  DOI1 21.11 CLYD1 
4.330 4.381 4.730 4.900 5.040 5.125 5.260 5.350 5.517 5.750 5.899 6.046 6.140 
 UIS1 INVA1  S121 WHIN2   S81 3.511  S251 
6.209 6.586 6.510 6.900 6.700 7.000 6.970 
> 
> ## take a larger sample where some chunks don't have many samples
> ## do random filling
> set.seed(3)
> test2 <- splitSample(swappH, chunk = 10, take = 70, fill = "random")
> test2
 [1] 161  27  68  36  35  48  15  42  59  25  91 160  85  34  88 149  76 146 136
[20] 127  56  90  65   6 113 128 108   8 153 157 167   5  71 138  95 155 154 132
[39]  16 140  31 110  73  12  58  30  62  44 158  20 117  54   4  23  86  53  14
[58]  74 162 118  80  57 165  46 129 133 123  18  45 164
attr(,"lengths")
 [1] 7 7 7 7 7 7 7 8 7 6
> swappH[test2]
 VEREV1    6.21    ENO1   82.11   81.21    BER1      21    9.11    CON1    5.11 
  4.490   4.616   4.543   4.619   4.522   4.330   4.500   4.676   4.820   4.640 
   LAR1    VAL1 HOLMEV1   80.11   KIRR1    SKE2   GLYN1 SCOATT1    S281    S191 
  4.875   4.688   4.700   4.730   5.116   5.100   4.920   5.000   4.940   5.030 
   CHN1    LAI1   DOON1   12.11   RIEC1    S201   MUCK1   15.11   TEAN1    UAI1 
  5.144   5.400   5.237   5.244   5.266   5.490   5.417   5.407   5.700   5.767 
  YGAD1  115.11   FINL1    S301    LDE2   TINK1   TECW1    S241   21.11    S311 
  5.740   5.682   5.756   5.520   5.700   5.966   6.060   5.990   6.046   5.890 
  66.11   OCHI1   GARN1   19.21   CLYD1   65.21 DEVOKE1    ARR1    UIS1   37.11 
  5.990   5.953   6.250   6.256   6.140   6.175   6.100   6.179   6.209   6.494 
   S101   BYCH1  113.21   44.21   INVA1 BURNMT1   20.11   GEIR1   WHIN1     S11 
  6.650   6.440   6.431   6.600   6.586   6.400   6.577   6.760   6.899   6.840 
  GWYN1   CLON1   WOOD1   BARE1     S21    S251    S151   3.511   ARTH1   WHIT1 
  6.690   6.942   6.782   6.748   7.160   6.970   7.250   7.000   7.093   7.031 
> 
> 
> 
> cleanEx()
> nameEx("sppResponse.prcurve")
> ### * sppResponse.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sppResponse
> ### Title: Species responses along gradients.
> ### Aliases: sppResponse sppResponse.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.692
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.498
Iteration   6: d.sq: 4369.945

PC Converged in 6 iterations.

> 
> ## Extract the fitted species response curves
> resp <- sppResponse(aber.pc)
> 
> ## Look at only the most abundant/frequently occurring taxa
> take <- chooseTaxa(abernethy2, max.abun = 25, n.occ = 10, value = FALSE)
> layout(matrix(1:12, ncol = 3))  	# split device into panels 
> plot(resp, which = take)
> layout(1)				# reset device
> 
> 
> 
> cleanEx()
> nameEx("stdError")
> ### * stdError
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stdError
> ### Title: Standard error of MAT fitted and predicted values
> ### Aliases: stdError stdError.mat stdError.predict.mat
> ### Keywords: methods univar
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> 
> ## standard errors - unweighted
> stdError(ik.mat)

	Standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : FALSE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   3.329    2.566    2.517    3.329    2.566    3.000    2.566    1.258 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   2.784    3.215    1.500    2.082    2.021    2.646    0.500    3.055 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   3.464    2.363    2.179    2.517    0.000    1.041    2.255    2.255 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   3.055    1.528    2.598    2.255    1.000    0.643    0.115    1.155 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   1.155    1.155    2.000    0.643    0.643    0.529    1.528    0.577 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   1.553    1.500    1.443    1.168    0.500    1.041    0.764    0.577 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   0.529    0.289    0.462    0.764    0.577    1.504    0.577    0.289 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   0.289    0.577    0.577    0.577    0.000 
> ## standard errors - weighted version for above
> stdError(ik.mat, k = getK(ik.mat), weighted = TRUE)

	Weighted standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : TRUE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   3.624    2.692    2.490    3.476    2.716    2.983    2.819    1.095 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   2.392    3.583    1.604    1.710    1.752    2.596    0.476    2.992 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   3.351    2.224    2.088    2.727    0.000    1.031    2.322    2.188 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   2.954    1.606    2.559    2.265    0.984    0.684    0.128    1.008 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   1.147    1.070    2.020    0.564    0.571    0.526    1.483    0.563 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   1.519    1.417    1.339    1.118    0.509    1.072    0.801    0.606 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   0.580    0.311    0.461    0.773    0.571    1.463    0.595    0.300 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   0.297    0.581    0.585    0.570    0.000 
> 
> ## standard errors - weighted; note this uses more (7) analogues
> ## than the above as this model had lowest LOO error
> stdError(ik.mat, weighted = TRUE)

	Weighted standard deviation of MAT predictions

 k-analogues: 7
 Weighted   : TRUE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   3.205    3.861    3.709    3.841    3.646    3.357    2.575    1.887 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
   2.173    2.658    2.619    2.557    2.058    2.508    1.909    3.326 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
   3.385    2.197    2.847    2.390    1.848    1.972    3.187    2.326 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
   3.068    1.915    1.998    2.710    1.918    0.684    0.786    1.200 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
   1.099    1.332    1.431    0.505    0.914    0.547    1.366    0.661 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
   1.266    1.045    1.289    1.078    1.037    1.082    1.088    0.639 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
   0.731    0.480    0.855    0.887    0.425    1.075    0.484    0.774 
 V20.230    V20.7  V20.234   V18.21  V12.122 
   0.428    0.519    0.432    0.521    0.172 
> 
> ## reconstruct for the V12-122 core data
> coreV12.mat <- predict(ik.mat, V12.122, k = 3)
> ## standard errors
> stdError(coreV12.mat)

	Standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : FALSE

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.577 0.577 0.577 1.607 1.277 1.277 0.866 1.258 1.443 1.323 0.500 0.289 1.607 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.289 1.732 0.929 0.814 0.814 1.168 0.289 1.732 2.255 0.500 0.577 1.419 1.323 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
1.277 1.607 1.803 0.577 1.277 1.155 1.607 1.443 1.258 0.751 1.277 1.277 0.500 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
2.255 0.500 1.419 0.289 0.500 0.289 0.000 1.442 1.277 0.289 1.155 0.577 0.500 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.500 1.277 0.115 1.041 0.289 0.289 0.500 1.277 0.289 0.902 0.404 0.289 0.577 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.764 0.289 0.500 2.255 1.258 0.964 1.442 1.528 1.041 0.500 0.289 0.289 1.442 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
1.155 0.577 0.577 1.803 0.289 1.323 1.041 0.500 1.323 1.277 1.607 2.000 0.764 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
1.041 1.323 0.289 0.289 0.462 0.500 0.289 0.289 0.289 1.443 0.289 1.041 1.443 
 1040  1050  1060  1070  1080  1090 
0.500 1.323 0.289 1.323 1.803 1.323 
> 
> 
> 
> cleanEx()
> nameEx("summary.analog")
> ### * summary.analog
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.analog
> ### Title: Summarise analogue matching results
> ### Aliases: summary.analog print.summary.analog
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## analog matching between SWAP and RLGH core
> ##D swap.analog <- analog(swapdiat, rlgh, method = "chord")
> ##D swap.analog
> ##D summary(swap.analog)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.bootstrap.mat")
> ### * summary.bootstrap.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.bootstrap.mat
> ### Title: Summarise bootstrap resampling for MAT models
> ### Aliases: summary.bootstrap.mat print.summary.bootstrap.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D 
> ##D ## bootstrap training set
> ##D swap.boot <- bootstrap(swap.mat, k = 10, n.boot = 100)
> ##D swap.boot
> ##D summary(swap.boot)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.cma")
> ### * summary.cma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.cma
> ### Title: Summarise the extraction of close modern analogues
> ### Aliases: summary.cma print.summary.cma
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## analog matching between SWAP and RLGH core
> ##D swap.analog <- analog(swapdiat, rlgh, method = "chord")
> ##D swap.analog
> ##D summary(swap.analog)
> ##D 
> ##D ## close modern analogues
> ##D swap.cma <- cma(swap.analog, cutoff = 0.6)
> ##D swap.cma
> ##D summary(swap.cma)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.mat")
> ### * summary.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.mat
> ### Title: Summarise Modern Analogue Technique models
> ### Aliases: summary.mat print.summary.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D swap.mat
> ##D 
> ##D ## model summary
> ##D summary(swap.mat)
> ##D 
> ##D ## model summary - evaluating models using k = 1, ..., 20
> ##D ## analogues instead of the default, 10.
> ##D summary(swap.mat, k = 20)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.predict.mat")
> ### * summary.predict.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.predict.mat
> ### Title: Summarise MAT model predictions
> ### Aliases: summary.predict.mat print.summary.predict.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D 
> ##D ## predict for RLGH data
> ##D swap.pred <- predict(swap.mat, rlgh, bootstrap = FALSE)
> ##D summary(swap.pred)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("swapdiat")
> ### * swapdiat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: swapdiat
> ### Title: SWAP sub-fossil diatom and pH training set
> ### Aliases: swapdiat
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(swapdiat)
> 
> 
> 
> cleanEx()
> nameEx("swappH")
> ### * swappH
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: swappH
> ### Title: SWAP sub-fossil diatom and pH training set
> ### Aliases: swappH
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(swappH)
> str(swappH)
 Named num [1:167] 4.49 5.26 4.9 6.43 5.68 ...
 - attr(*, "names")= chr [1:167] "1.21" "10.21" "11" "113.21" ...
> 
> 
> 
> cleanEx()
> nameEx("timetrack")
> ### * timetrack
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: timetrack
> ### Title: Timetracks of change in species composition
> ### Aliases: timetrack print.timetrack plot.timetrack points.timetrack
> ###   fitted.timetrack scores.timetrack predict.timetrack
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
> ## load the RLGH and SWAP data sets
> data(rlgh, swapdiat)
> 
> ## Fit the timetrack ordination
> mod <- timetrack(swapdiat, rlgh, transform = "hellinger",
+                  method = "rda")
> mod

	Timetrack Ordination

Call: timetrack(X = swapdiat, passive = rlgh, method = "rda", transform
= "hellinger")

Ordination Output:
Call: rda(X = X)

-- Model Summary --

              Inertia Rank
Total          0.6163     
Unconstrained  0.6163  166

Inertia is variance

-- Eigenvalues --

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 
0.11915 0.05669 0.03734 0.03336 0.02803 0.02362 0.01917 0.01520 
(Showing 8 of 166 unconstrained eigenvalues)

> 
> ## Plot the timetrack
> plot(mod, ptype = "b", col = c("forestgreen", "orange"), lwd = 2)
> 
> ## Other options (reorder the time track)
> ord <- rev(seq_len(nrow(rlgh)))
> plot(mod, choices = 2:3, order = ord, ptype = "b",
+      col = c("forestgreen", "orange"), lwd = 2)
> 
> ## illustrating use of the formula
> data(swappH)
> mod2 <- timetrack(swapdiat, rlgh, env = data.frame(pH = swappH),
+                   transform = "hellinger", method = "rda",
+                   formula = ~ pH)
> mod2

	Timetrack Ordination

Call: timetrack(X = swapdiat, passive = rlgh, env = data.frame(pH =
swappH), method = "rda", transform = "hellinger", formula = ~pH)

Ordination Output:
Call: rda(X = X, Y = mf)

-- Model Summary --

              Inertia Proportion Rank
Total         0.61631    1.00000     
Constrained   0.09743    0.15808    1
Unconstrained 0.51888    0.84192  165

Inertia is variance

-- Eigenvalues --

Eigenvalues for constrained axes:
   RDA1 
0.09743 

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 
0.06026 0.03786 0.03356 0.02876 0.02448 0.02205 0.01854 0.01377 
(Showing 8 of 165 unconstrained eigenvalues)

> plot(mod2)
> 
> ## scores and fitted methods
> ## IGNORE_RDIFF_BEGIN
> head(fitted(mod, type = "passive"))
            PC1        PC2
000.3 0.1375142 0.08856751
000.8 0.1863037 0.08457038
001.3 0.1908819 0.08600249
001.8 0.1763641 0.08944730
002.3 0.1957923 0.08841358
002.8 0.1765786 0.07861150
> head(scores(mod, type = "passive"))
                 PC1          PC2
1.21    0.2160382637 -0.029893425
10.21  -0.0348364914  0.021721523
11      0.2096872141  0.004435281
113.21 -0.0008560853  0.071167503
115.11  0.0907404572 -0.015968707
12.11   0.1220684180 -0.237747308
> ## IGNORE_RDIFF_END
> 
> ## predict locations in timetrack for new observations
> take <- rlgh[1:50, ]
> take <- take[ , colSums(take) > 0]
> mod3 <- predict(mod, newdata = take)
> class(mod3) ## returns a timetrack object
[1] "timetrack"
> take <- rlgh[-(1:50), ]
> take <- take[ , colSums(take) > 0]
> mod4 <- predict(mod, newdata = take)
> 
> ## build a plot up from base parts
> plot(mod, type = "n", ptype = "n")
> points(mod, which = "ordination", col = "grey", pch = 19, cex = 0.7)
> points(mod3, which = "passive", col = "red")
> points(mod4, which = "passive", col = "blue")
> 
> ## Fit the timetrack ordination - passing scaling args
> mod <- timetrack(swapdiat, rlgh, transform = "hellinger",
+                  method = "rda", scaling = "sites",
+                  correlation = TRUE)
> mod

	Timetrack Ordination

Call: timetrack(X = swapdiat, passive = rlgh, method = "rda", transform
= "hellinger", scaling = "sites", correlation = TRUE)

Ordination Output:
Call: rda(X = X)

-- Model Summary --

              Inertia Rank
Total          0.6163     
Unconstrained  0.6163  166

Inertia is variance

-- Eigenvalues --

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 
0.11915 0.05669 0.03734 0.03336 0.02803 0.02362 0.01917 0.01520 
(Showing 8 of 166 unconstrained eigenvalues)

> plot(mod)
> 
> 
> 
> 
> cleanEx()
> nameEx("tortula")
> ### * tortula
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tortula
> ### Title: Morphological data for ten taxa of the genus Tortula
> ### Aliases: tortula
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(tortula)
> head(tortula)
              Taxon Hydroid LeafOutline Denticulation ApexShape Length Diameter
1        Calciolens   FALSE        oval        strong   notched   2.00     10.0
2        Caninervis    TRUE       ovate          weak     blunt   2.25      6.4
3 Caninervis-spuria    TRUE        oval        strong   notched   2.25     12.4
4        Intermedia   FALSE       ovate          weak   notched   2.00     11.0
5        Intermedia   FALSE       ovate          weak   rounded   2.13     12.8
6         Norvegica   FALSE        oval        medium   pointed   2.38     17.1
  Papillae
1      4.0
2      2.0
3      3.2
4      2.6
5      4.0
6      4.3
> str(tortula)
'data.frame':	14 obs. of  8 variables:
 $ Taxon        : chr  "Calciolens" "Caninervis" "Caninervis-spuria" "Intermedia" ...
 $ Hydroid      : logi  FALSE TRUE TRUE FALSE FALSE FALSE ...
 $ LeafOutline  : Ord.factor w/ 5 levels "oval"<"oblong"<..: 1 3 1 3 3 1 2 3 3 2 ...
 $ Denticulation: Ord.factor w/ 4 levels "smooth"<"weak"<..: 4 2 4 2 2 3 2 2 2 2 ...
 $ ApexShape    : Ord.factor w/ 4 levels "pointed"<"blunt"<..: 4 2 4 4 3 1 3 3 4 2 ...
 $ Length       : num  2 2.25 2.25 2 2.13 2.38 2.13 2.25 3.25 3.13 ...
 $ Diameter     : num  10 6.4 12.4 11 12.8 17.1 18.7 12 14.2 15.1 ...
 $ Papillae     : num  4 2 3.2 2.6 4 4.3 5.4 3.6 2.6 3.9 ...
> 
> 
> 
> cleanEx()
> nameEx("tran")
> ### * tran
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tran
> ### Title: Common data transformations and standardizations
> ### Aliases: tran tran.default tran.formula
> ### Keywords: multivariate manip methods
> 
> ### ** Examples
> 
> data(swapdiat)
> ## convert percentages to proportions
> sptrans <- tran(swapdiat, "pcent2prop")
> 
> ## apply Hellinger transformation
> spHell <- tran(swapdiat, "hellinger")
> 
> ## Dummy data to illustrate formula method
> d <- data.frame(A = runif(10), B = runif(10), C = runif(10))
> ## simulate some missings
> d[sample(10,3), 1] <- NA
> ## apply tran using formula
> tran(~ . - B, data = d, na.action = na.pass,
+      method = "missing", na.value = 0)
           A          C
1  0.2655087 0.93470523
2  0.3721239 0.21214252
3  0.5728534 0.65167377
4  0.0000000 0.12555510
5  0.2016819 0.26722067
6  0.8983897 0.38611409
7  0.9446753 0.01339033
8  0.6607978 0.38238796
9  0.0000000 0.86969085
10 0.0000000 0.34034900
> 
> 
> 
> cleanEx()
> nameEx("varExpl")
> ### * varExpl
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: varExpl
> ### Title: Variance explained by ordination axes
> ### Aliases: varExpl varExpl.default varExpl.cca varExpl.prcurve
> ### Keywords: multivariate utility
> 
> ### ** Examples
> 
> 
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit PCA
> aber.pca <- rda(abernethy2)
> 
> ## Distance along the first PCA axis
> varExpl(aber.pca)
      PC1 
0.4649883 
> 
> 
> 
> cleanEx()
> nameEx("wa")
> ### * wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: wa
> ### Title: Weighted averaging transfer functions
> ### Aliases: wa wa.default wa.formula print.wa fitted.wa residuals.wa
> ###   coef.wa waFit
> ### Keywords: methods models regression multivariate
> 
> ### ** Examples
> 
> ## Don't show: 
> od <- options(digits = 4)
> ## End(Don't show)
> data(ImbrieKipp)
> data(SumSST)
> 
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## extract the fitted values
> fitted(mod)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   3.731    3.860    4.108    4.294    8.288    9.244    4.076   13.815 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  14.335   16.521   15.804   18.737   18.290   18.459   17.389   20.402 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  19.969   19.709   18.782   22.789   22.408   20.785   22.454   22.181 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  21.562   23.338   23.361   22.845   24.219   25.626   25.499   23.378 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  23.747   23.112   24.517   25.384   25.797   26.258   24.162   25.464 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  26.240   25.824   26.678   26.395   26.091   25.719   25.863   26.339 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  26.790   26.697   26.822   25.987   26.882   26.906   26.515   26.068 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  26.609   27.232   26.765   26.946   26.833 
> 
> ## residuals for the training set
> residuals(mod)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
-1.73096  1.14008  1.39234  2.70609 -1.28758  1.25559  6.92387 -3.81548 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
-1.33451 -4.52130 -1.80440 -4.23654 -3.28960 -3.95871 -1.38856 -2.40198 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
 0.03058 -1.70859  0.21846 -4.28923 -0.90788  0.21451 -1.45437  1.81859 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 2.43767 -0.33794  0.63921  0.15546 -1.21928 -1.62566 -0.49881  2.62209 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 2.25277  2.88753  0.48342  0.61626  0.20316 -1.75849  2.83754  0.73556 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
-1.24017  0.67597 -0.47797 -0.39453 -0.09134  1.28086  1.13732  1.16146 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 0.21024  0.30309  0.17833  1.01263  0.11757  2.09377  1.98466  1.43203 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 0.89117  0.26836  0.23459  0.05406  1.16699 
> 
> ## deshrinking coefficients
> coef(mod)
[1] -5.688  1.266
> 
> ## diagnostics plots
> par(mfrow = c(1,2))
> plot(mod)
> par(mfrow = c(1,1))
> 
> ## caterpillar plot of optima and tolerances
> caterpillarPlot(mod)                 ## observed tolerances
> caterpillarPlot(mod, type = "model") ## with tolerances used in WA model
> 
> ## plot diagnostics for the WA model
> par(mfrow = c(1,2))
> plot(mod)
> par(mfrow = c(1,1))
> 
> ## tolerance DW
> mod2 <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+            min.tol = 2, small.tol = "min")
> mod2

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## compare actual tolerances to working values
> with(mod2, rbind(tolerances, model.tol))
           O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
tolerances  3.746   1.896   1.910   2.125   1.980   1.968  3.941  5.181   5.828
model.tol   3.746   2.125   2.125   2.125   2.125   2.125  3.941  5.181   5.828
           G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR
tolerances   3.109   2.973   2.562   5.898   1.998   4.724  4.162  3.435
model.tol    3.109   2.973   2.562   5.898   2.125   4.724  4.162  3.435
           G.crasf G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin
tolerances   3.354   3.991   2.387   1.555   1.462   3.845   3.109 5.112  4.269
model.tol    3.354   3.991   2.387   2.125   2.125   3.845   3.109 5.112  4.269
           G.hirsu
tolerances   3.942
model.tol    3.942
> 
> ## tolerance DW
> mod3 <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+            min.tol = 2, small.tol = "mean")
> mod3

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "mean",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   1.9924     0.9194     0.0000    -2.5992  

> 
> ## fit a WA model with monotonic deshrinking
> mod4 <- wa(SumSST ~., data = ImbrieKipp, deshrink = "monotonic")
> mod4

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, deshrink = "monotonic") 

Deshrinking  : Monotonic 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   1.6107     0.9474     0.0000    -3.8985  

> 
> ## extract the fitted values
> fitted(mod4)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   5.898    5.959    6.076    6.164    8.127    8.641    6.061   11.563 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  11.971   14.011   13.276   16.804   16.169   16.405   15.003   19.398 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  18.707   18.292   16.870   22.940   22.428   20.008   22.492   22.113 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  21.211   23.637   23.665   23.013   24.660   26.099   25.975   23.686 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  24.126   23.357   24.981   25.863   26.266   26.716   24.597   25.942 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  26.699   26.293   27.127   26.850   26.553   26.190   26.330   26.795 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  27.237   27.146   27.268   26.452   27.328   27.351   26.968   26.530 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  27.060   27.670   27.213   27.390   27.279 
> 
> ## residuals for the training set
> residuals(mod4)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
-3.89845 -0.95914 -0.57578  0.83647 -1.12655  1.85856  4.93907 -1.56333 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
 1.02901 -2.01092  0.72379 -2.30398 -1.16894 -1.90465  0.99722 -1.39764 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
 1.29346 -0.29235  2.13000 -4.44032 -0.92784  0.99173 -1.49153  1.88724 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 2.78850 -0.63728  0.33475 -0.01276 -1.65993 -2.09931 -0.97539  2.31384 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 1.87381  2.64328  0.01900  0.13747 -0.26612 -2.21647  2.40271  0.25827 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
-1.69857  0.20739 -0.92732 -0.84955 -0.55322  0.80957  0.66973  0.70524 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
-0.23696 -0.14589 -0.26826  0.54820 -0.32786  1.64879  1.53212  0.96958 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 0.44048 -0.17039 -0.21308 -0.39015  0.72061 
> 
> ## Don't show: 
> options(od)
> ## End(Don't show)
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("weightedCor")
> ### * weightedCor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: weightedCor
> ### Title: Weighted correlation test of WA reconstruction
> ### Aliases: weightedCor weightedCor.default print.weightedCor
> ###   plot.weightedCor
> ### Keywords: methods
> 
> ### ** Examples
> 
> data(ImbrieKipp, SumSST, V12.122)
> 
> Cor <- weightedCor(ImbrieKipp, env = SumSST,
+                    fossil = V12.122, type = "simulate", sim = 49)
Simulating 49 Weighted Correlations:
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   2%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  12%  |                                                                              |==========                                                            |  14%  |                                                                              |===========                                                           |  16%  |                                                                              |=============                                                         |  18%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  22%  |                                                                              |=================                                                     |  24%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  35%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  41%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  45%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  49%  |                                                                              |====================================                                  |  51%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  55%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  59%  |                                                                              |===========================================                           |  61%  |                                                                              |============================================                          |  63%  |                                                                              |==============================================                        |  65%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |==================================================                    |  71%  |                                                                              |===================================================                   |  73%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  82%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |===================================================================   |  96%  |                                                                              |===================================================================== |  98%  |                                                                              |======================================================================| 100%

> Cor

	Weighted correlation of WA Transfer Function

Call:
weightedCor(x = ImbrieKipp, env = SumSST, fossil = V12.122, type = "simulate", 
    sim = 49)

Test Type           : Simulation
Weighted Correlation: 0.491 (p = 0.56)
Correlation         : 0.437 (p = < 2.22e-16)

> 
> plot(Cor)
> plot(Cor, type = "null")
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  2.358 0.148 2.536 0 0 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
