
R version 3.1.1 Patched (2014-07-11 r66127) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "analogue"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('analogue')
Loading required package: vegan
Loading required package: permute
Loading required package: lattice
This is vegan 2.0-10
This is analogue 0.14-0
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("ImbrieKipp")
> ### * ImbrieKipp
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: ImbrieKipp
> ### Title: Imbrie and Kipp foraminifera training set
> ### Aliases: ImbrieKipp SumSST WinSST Salinity V12.122
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> head(ImbrieKipp)
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0    0.00       0    0.00    0.00  98.97   0.90    0.00
V17.196      0       0    0.00       0    0.00    0.00  98.13   0.94    0.47
V18.110      0       0    0.00       0    0.00    0.00  96.29   1.71    1.00
V16.227      0       0    0.00       0    0.00    0.00  94.33   4.82    0.85
V14.47       0       0    0.11       0    0.11    0.11  68.50   2.71   10.95
V23.22       0       0    0.00       0    0.00    0.00  55.69  16.62   19.90
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0    0.00       0    0.00   0.00      0    0.00
V17.196       0       0       0    0.47       0    0.00   0.00      0    0.00
V18.110       0       0       0    0.00       0    0.57   0.00      0    0.00
V16.227       0       0       0    0.00       0    0.00   0.00      0    0.00
V14.47        0       0       0    1.95       0   14.20   0.11      0    0.43
V23.22        0       0       0    2.29       0    1.57   0.00      0    0.00
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V14.61     0.00    0.00    0.00       0       0       0  0.13   0.00    0.00
V17.196    0.00    0.00    0.00       0       0       0  0.00   0.00    0.00
V18.110    0.00    0.00    0.00       0       0       0  0.43   0.00    0.00
V16.227    0.00    0.00    0.00       0       0       0  0.00   0.00    0.00
V14.47     0.11    0.11    0.11       0       0       0  0.18   0.32    0.00
V23.22     0.00    0.00    0.00       0       0       0  0.65   3.14    0.13
> 
> data(SumSST)
> data(WinSST)
> data(Salinity)
> 
> plot(cbind(SumSST, WinSST, Salinity))
> 
> data(V12.122)
> head(V12.122)
    O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL  G.pacR G.bullo
0  0.01792 0.00489 0.43485 0.00814 0.25570 0.00651      0 0.00163 0.00000
10 0.03203 0.00712 0.37722 0.00356 0.30961 0.00712      0 0.00356 0.00000
20 0.02564 0.01709 0.47009 0.00855 0.20513 0.01709      0 0.01282 0.00427
30 0.01124 0.00562 0.47190 0.01124 0.12360 0.02247      0 0.03933 0.00562
40 0.00671 0.01007 0.43623 0.03020 0.15436 0.01007      0 0.00336 0.00671
50 0.01149 0.00766 0.52873 0.00766 0.12261 0.00000      0 0.00383 0.02299
   G.falco G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf
0  0.00163 0.00326 0.03257 0.08958 0.04560 0.00163 0.00163 0.00000 0.00000
10 0.00000 0.00000 0.02491 0.08185 0.05694 0.00000 0.00712 0.00356 0.00000
20 0.00000 0.00855 0.00855 0.09402 0.05556 0.00000 0.00427 0.00855 0.00000
30 0.00562 0.02247 0.05056 0.07865 0.06742 0.01124 0.00000 0.01685 0.00562
40 0.00336 0.01678 0.08054 0.09396 0.03691 0.04698 0.00336 0.02349 0.01342
50 0.00000 0.01916 0.06897 0.07663 0.04981 0.04215 0.00000 0.02682 0.00766
   G.scitu G.mentu P.obliq C.nitid S.dehis G.digit   Other G.quin G.hirsu
0  0.00163 0.07492 0.00977 0.00651 0.00163       0 0.00000      0       0
10 0.00000 0.05694 0.01423 0.00000 0.00356       0 0.01068      0       0
20 0.00855 0.02991 0.00855 0.00855 0.00000       0 0.00427      0       0
30 0.00562 0.01124 0.02247 0.00000 0.00000       0 0.01124      0       0
40 0.00336 0.01007 0.00671 0.00000 0.00000       0 0.00336      0       0
50 0.00000 0.00000 0.00000 0.00000 0.00000       0 0.00383      0       0
   G.hexag G.cglom cfH.pel
0        0       0       0
10       0       0       0
20       0       0       0
30       0       0       0
40       0       0       0
50       0       0       0
> 
> 
> 
> cleanEx()
> nameEx("Pollen")
> ### * Pollen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Pollen
> ### Title: North American Modern Pollen Database
> ### Aliases: Pollen Biome Climate Location
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(Pollen)
> 
> data(Climate)
> 
> data(Biome)
> 
> data(Location)
> 
> 
> 
> cleanEx()
> nameEx("RMSEP")
> ### * RMSEP
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: RMSEP
> ### Title: Root mean square error of prediction
> ### Aliases: RMSEP RMSEP.default RMSEP.mat RMSEP.bootstrap.mat
> ###   RMSEP.bootstrap.wa
> ### Keywords: methods utilities
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## Leave-one-out RMSEP for the MAT model
> RMSEP(ik.mat)
[1] 1.733353
> 
> ## bootstrap training set
> (ik.boot <- bootstrap(ik.mat, n.boot = 100))

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP     S1    S2 r.squared avg.bias max.bias
LOO       3 1.713      -     -    0.9409   0.1328    5.167
Bootstrap 5 1.953 0.9133 1.726    0.9707   0.3017    5.484

> 
> ## extract the Birks et al (1990) RMSEP
> RMSEP(ik.boot)
[1] 1.952979
> 
> ## Calculate the alternative formulation
> RMSEP(ik.boot, type = "standard")
[1] 1.726244
> 
> 
> 
> cleanEx()
> nameEx("Stratiplot")
> ### * Stratiplot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Stratiplot
> ### Title: Palaeoecological stratigraphic diagrams
> ### Aliases: Stratiplot Stratiplot.default Stratiplot.formula
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data(V12.122)
> Depths <- as.numeric(rownames(V12.122))
> 
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122,  type = c("h","l","g","smooth")))
> 
> ## Order taxa by WA in depth --- ephasises change over time
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("h"), sort = "wa"))
> 
> ## Using the default interface
> spp.want <- c("O.univ","G.ruber","G.tenel","G.pacR")
> (plt <- Stratiplot(V12.122[, spp.want], y = Depths,
+                    type = c("poly", "g")))
> 
> ## Adding zones to a Stratigraphic plot
> ## Default labelling and draw zone legend
> ## Here we choose 4 arbitrary Depths as the zone boundaries
> set.seed(123)
> Zones <-sample(Depths, 4)
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("poly","g"),
+                    zones = Zones))
> 
> ## As before, but supplying your own zone labels
> zone.labs <- c("A","B","C","D","E")
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("poly","g"),
+                    zones = Zones, zoneNames = zone.labs))
> 
> ## Suppress the drawing of the zone legend
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("poly","g"),
+                    zones = Zones, drawLegend = FALSE))
> 
> ## Add zones and draw a legend, but do not label the zones
> (plt <- Stratiplot(Depths ~ O.univ + G.ruber + G.tenel + G.pacR,
+                    data = V12.122, type = c("poly","g"),
+                    zones = Zones, zoneNames = ""))
> 
> ## Show illustration of NA handling
> set.seed(42)
> dat <- data.frame(Depth = 1:20, LOI = runif(20), TC = NA)
> dat <- within(dat, TC[sample(20, 10)] <- runif(10))
> ## default is 'na.action = "na.pass"'
> (Stratiplot(Depth ~ LOI + TC, data = dat, type = c("l","p")))
> ## to remove rows with NA, use 'na.action = "na.omit"'
> (Stratiplot(Depth ~ LOI + TC, data = dat, type = c("l","p"),
+             na.action = "na.omit"))
> 
> ## Example of two proxies measured on different levels of core
> ## (Here measurements on alternate levels)
> set.seed(5)
> dat2a <- data.frame(Depth = seq(1, by = 2, length = 20), LOI = runif(20))
> dat2b <- data.frame(Depth = seq(0, by = 2, length = 20), TC = runif(20))
> dat2 <- join(dat2a, dat2b, na.replace = FALSE, split = FALSE)
> dat2 <- dat2[order(dat2$Depth), ]
> head(dat2)
    Depth       LOI        TC
110     0        NA 0.8902071
1       1 0.2002145        NA
21      2        NA 0.7207010
2       3 0.6852186        NA
31      4        NA 0.2113403
3       5 0.9168758        NA
> 
> ## Default is to allow NA through formula, but drop them when plotting
> (Stratiplot(Depth ~ LOI + TC, data = dat2, type = c("l","p")))
> 
> ## compare with this if we didn't suppress NA in default Stratiplot
> ## method (can't use formula interface for this yet
> (Stratiplot(dat2[,-1], dat2[,1], type = c("l","p"),
+             na.action = "na.pass"))
> ## Notice no lines are draw as there a no "sections" ithout missing
> ## levels. If you want/desire this behaviour then you can't use formula
> ## interface yet as there is no way to specify the na.action separately
> 
> 
> 
> cleanEx()
> nameEx("abernethy")
> ### * abernethy
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: abernethy
> ### Title: Abernethy Forest Pollen Sequence
> ### Aliases: abernethy
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(abernethy)
> head(abernethy)
  Betula Pinus sylvestris Ulmus Quercus Alnus glutinosa Corylus-Myrica Salix
1  15.11            51.82  2.68    3.44            5.54           6.88  0.00
2  21.00            59.48  0.93    1.86            0.93           7.81  0.93
3   9.26            76.23  0.54    1.09            0.73           7.08  0.00
4  20.70            74.84  0.80    0.48            0.00           0.96  0.16
5   6.07            88.06  0.39    1.37            0.20           1.17  0.20
6  11.32            81.57  1.15    1.34            0.19           2.30  0.58
  Juniperus communis Calluna vulgaris Empetrum Gramineae Cyperaceae
1                  0             7.07     0.76      1.34       4.78
2                  0             3.35     0.74      0.56       2.04
3                  0             2.36     0.36      0.18       2.18
4                  0             0.64     0.00      0.32       0.64
5                  0             0.78     0.59      0.39       0.59
6                  0             0.38     0.00      0.38       0.58
  Solidago-type Compositae Artemisia Caryophyllaceae Sagina Silene
1             0          0         0               0      0      0
2             0          0         0               0      0      0
3             0          0         0               0      0      0
4             0          0         0               0      0      0
5             0          0         0               0      0      0
6             0          0         0               0      0      0
  Chenopodiaceae Epilobium-type Papilionaceae Anthyllis vulneraria
1              0              0             0                    0
2              0              0             0                    0
3              0              0             0                    0
4              0              0             0                    0
5              0              0             0                    0
6              0              0             0                    0
  Astragalus alpinus Ononis-type Rosaceae Rubiaceae Ranunculaceae Thalictrum
1                  0           0     0.00         0             0          0
2                  0           0     0.19         0             0          0
3                  0           0     0.00         0             0          0
4                  0           0     0.00         0             0          0
5                  0           0     0.00         0             0          0
6                  0           0     0.19         0             0          0
  Rumex acetosa-type Oxyria-type Parnassia palustris Saxifraga spp1
1                  0           0                   0              0
2                  0           0                   0              0
3                  0           0                   0              0
4                  0           0                   0              0
5                  0           0                   0              0
6                  0           0                   0              0
  Saxifraga spp2 Sedum Urtica Veronica Depth  Age
1              0     0      0        0   300 5515
2              0     0      0        0   305 5632
3              0     0      0        0   310 5749
4              0     0      0        0   315 5866
5              0     0      0        0   320 5983
6              0     0      0        0   325 6100
> 
> (plt <- Stratiplot(Age ~ . - Depth,
+                    data = chooseTaxa(abernethy, n.occ = 5,
+                                      max.abun = 10),
+                    type = "poly"))
> 
> 
> 
> cleanEx()
> nameEx("analog")
> ### * analog
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: analog
> ### Title: Analogue matching
> ### Aliases: analog analog.default analog.distance print.analog
> ### Keywords: multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Imbrie and Kipp foraminfera sea-surface temperature
> 
> ## analog matching between SWAP and RLGH core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.910 0.908 0.910 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.909 0.911 0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.906 0.909 0.910 0.907 0.907 0.912 0.910 0.911 0.907 0.908 0.908 0.910 0.908 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.910 0.907 0.911 0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906 0.911 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.907 0.910 0.910 0.910 0.907 0.907 0.906 0.904 0.906 0.910 0.913 0.906 0.907 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.906 0.910 0.911 0.913 0.907 0.909 0.909 0.912 0.914 0.908 0.907 0.909 0.911 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.914 0.907 0.907 0.908 0.908 0.906 0.907 0.910 0.910 0.910 0.909 0.913 0.912 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.908 0.909 0.909 0.907 0.910 0.909 0.908 0.907 0.911 0.908 0.913 0.910 0.910 
 1040  1050  1060  1070  1080  1090 
0.912 0.906 0.910 0.910 0.908 0.907 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    A180.76   V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   V14.5     V12.79    V22.204   V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V16.21    V15.164   V20.167 
   7  V15.164   V20.230   V20.230   A180.72   V20.234   V20.234   V22.219 
   8  V16.21    V20.167   V14.90    V22.204   V20.230   A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V14.90    V20.230   V12.18  
  10  V20.230   V20.7     V20.167   V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V22.204   V14.90    V19.216   V14.90  
  V16.21    V20.167   V22.204   V9.31     V20.230   V22.172   V19.216 
  V14.90    V16.21    V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    A153.154  V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   V14.90    V14.90    V12.79    V20.167   V12.79  
  V20.167   A179.13   V9.31     V16.21    V22.172   A153.154  V22.204 
  V20.234   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V22.204   V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V9.31     V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V14.90  
  V20.230   V20.167   V10.89    V20.230   V14.90    V14.90    V22.172 
  V20.234   V19.216   V19.216   V16.21    V20.230   V9.31     V9.31   
  V14.90    V16.21    V9.31     V22.172   V10.89    V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V16.21    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V12.79  
  A180.72   V15.164   V16.33    V9.31     V15.164   V20.234   V16.21  
  V16.21    V20.230   V22.172   V22.219   V19.216   V3.128    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V20.167   V20.230   V14.90    V12.122   V22.172   V22.172   A180.72 
  V3.128    V18.21    V14.5     V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   A180.76   V18.21    V12.79    V12.122   V12.79  
  V20.230   V20.234   V20.234   V22.172   V12.122   A180.72   V22.204 
  V20.234   V14.5     V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   A180.72   V10.89    A180.76   V18.21  
  A180.76   A180.76   V15.164   V14.5     V15.164   V20.230   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V10.89  
  V12.122   A180.72   V19.216   V14.90    V22.172   V14.90    V22.172 
  V22.204   V14.5     V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V20.230   V14.90    A180.39   V19.308 
  V14.5     V3.128    V20.230   V16.190   V16.21    V16.190   V16.21  
  V20.234   V22.172   A179.13   V16.21    V10.89    V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V20.167   V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V9.31     V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   A180.76   V20.230 
  V14.90    V14.90    V22.204   V20.230   V14.90    V20.230   V14.90  
  V16.21    V20.234   V12.122   A180.76   V9.31     A180.72   V9.31   
  V22.172   V15.164   V20.234   V3.128    V20.234   V22.172   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V15.164   V22.204   V20.167   V19.216   V20.234 
  V15.164   V20.230   V16.33    V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V20.167   V14.90  
  V20.234   V9.31     V14.90    V18.21    V3.128    V22.172   A180.76 
  V14.90    V14.90    V20.234   V20.234   V14.5     V20.234   V22.204 
  V20.230   V20.234   V20.230   A180.72   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   V12.122   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   V20.230   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   A180.76   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V3.128  
  A180.76   V22.172   V19.216   V14.90    V15.164   V19.216   A180.78 
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  A180.72   V20.230   V20.234   V3.128    V10.89    V19.216   V22.172 
  V12.122   V18.21    V20.230   V19.216   V16.21    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.72   V12.122   V22.172   V12.79  
  V14.90    V14.5     V19.216   A180.78   V15.164   V16.21    V9.31   
  V14.5     V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V20.167   V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V22.204   V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V12.79    V22.172   A180.72   V14.90    V20.167 
  A180.76   A180.78   V14.90    V15.164   A180.76   V22.204   V19.216 
  V9.31     V14.90    A180.72   V16.21    V22.204   V12.122   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V3.128    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V12.79    V20.230 
  V22.204   V20.234   V20.234   V14.90    V20.230   A180.72   V16.33  
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  A180.72   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  V12.122   V14.5     V22.172   V22.172   A180.72   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     V22.172   V9.31     V22.172 
  V20.230   A180.72   V20.167   V3.128    V20.230   V22.204   V22.204 
  V20.234   V3.128    V14.5     V16.33    V12.122   V16.190   V22.219 
  V22.172   V18.21    A180.76   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   V15.164   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V12.122   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V22.172   V12.79    A180.72 
  V19.216   V20.234   V3.128    V20.230   V20.234   V22.172   V3.128  
  V16.21    V12.122   V10.89    V20.167   V20.230   V20.230   V20.167 
  V10.89    V20.230   V19.216   V12.122   V12.79    V12.122   V12.122 
  V15.164   V22.172   V20.167   V19.216   V20.167   V9.31     V20.230 
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V9.31   
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V22.204   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V19.216   V20.167 
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V16.33  
  V14.90    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V16.21    V22.172   A180.72   V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   V3.128    A180.72   V12.79    A180.72   V12.122 
  A180.76   A180.72   A180.76   V14.90    V14.5     V20.167   V16.190 
  V9.31     V20.230   V20.234   V12.79    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V16.21    A180.72   A180.76   V10.89  
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V19.216   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V22.172   V9.31     V19.222   V9.31   
  V22.204   V19.216   V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V9.31     V20.167   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V19.216   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V20.230 
  A180.72   V20.230   V15.164   V10.89    V12.79    V22.172   V16.190 
  V9.31     A180.76   V12.18    V20.230   V20.167   V12.79    A180.39 
  V14.90    A180.72   V9.31     V16.21    A180.72   V9.31     V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V14.90    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V16.21    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V20.230   V12.79    V22.172 
  V19.222   V22.204   V22.172   V14.90    V12.122   V22.172   A180.76 
  V12.79    V22.172   V14.90    V22.172   V9.31     V16.21    V19.216 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V20.167   V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V12.79    A180.72   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   V20.234   A179.13   A180.72   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  A180.76   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  V22.172   V22.204   V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V12.79    V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.204   V19.216   V19.216   V12.122   V22.204 
  V14.90    V14.90    V22.172   V22.172   V14.90  
  V22.172   V12.122   V22.204   V14.90    V19.216 
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V20.234 
  V16.33    V20.234   V22.219   V20.230   V9.31   
  V16.190   A180.78   V9.31     V20.234   A180.72 

Dissimilarities for k-closest analogues

   k      0     10     20     30     40     50     60     70     80     90
   1  0.900  0.902  0.903  0.904  0.904  0.907  0.907  0.908  0.908  0.908
   2  0.903  0.904  0.904  0.904  0.905  0.908  0.908  0.909  0.908  0.910
   3  0.903  0.904  0.906  0.904  0.906  0.908  0.909  0.910  0.909  0.913
   4  0.903  0.906  0.906  0.905  0.906  0.909  0.910  0.910  0.909  0.913
   5  0.905  0.906  0.906  0.905  0.908  0.909  0.910  0.910  0.909  0.914
   6  0.905  0.907  0.906  0.905  0.908  0.909  0.910  0.911  0.910  0.914
   7  0.907  0.907  0.907  0.906  0.908  0.911  0.910  0.911  0.910  0.914
   8  0.907  0.908  0.907  0.906  0.908  0.911  0.911  0.911  0.910  0.914
   9  0.907  0.909  0.907  0.906  0.908  0.911  0.911  0.911  0.911  0.915
  10  0.908  0.910  0.907  0.906  0.908  0.912  0.911  0.911  0.911  0.915
    100    110    120    130    140    150    160    170    180    190    200
  0.910  0.908  0.910  0.909  0.911  0.908  0.908  0.906  0.908  0.909  0.906
  0.911  0.910  0.910  0.909  0.911  0.909  0.910  0.907  0.910  0.910  0.908
  0.911  0.912  0.911  0.910  0.912  0.909  0.910  0.907  0.910  0.910  0.908
  0.912  0.913  0.911  0.911  0.912  0.910  0.910  0.907  0.911  0.910  0.908
  0.913  0.914  0.912  0.911  0.914  0.910  0.910  0.907  0.911  0.912  0.908
  0.913  0.914  0.914  0.913  0.914  0.910  0.910  0.908  0.911  0.912  0.909
  0.913  0.914  0.914  0.913  0.915  0.911  0.910  0.908  0.911  0.912  0.909
  0.913  0.915  0.914  0.914  0.915  0.911  0.910  0.908  0.912  0.913  0.910
  0.914  0.915  0.915  0.914  0.915  0.911  0.911  0.909  0.913  0.914  0.910
  0.914  0.915  0.915  0.914  0.915  0.912  0.911  0.910  0.914  0.914  0.910
    210    220    230    240    250    260    270    280    290    300    310
  0.907  0.906  0.906  0.906  0.906  0.906  0.909  0.910  0.907  0.907  0.912
  0.908  0.909  0.908  0.910  0.908  0.908  0.910  0.911  0.908  0.908  0.913
  0.908  0.909  0.908  0.911  0.909  0.908  0.911  0.911  0.909  0.908  0.913
  0.908  0.909  0.908  0.911  0.910  0.908  0.912  0.911  0.909  0.909  0.914
  0.909  0.909  0.909  0.911  0.910  0.908  0.912  0.912  0.910  0.909  0.915
  0.910  0.909  0.909  0.912  0.911  0.909  0.912  0.912  0.910  0.909  0.916
  0.910  0.909  0.910  0.912  0.911  0.909  0.913  0.912  0.910  0.909  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.912  0.911  0.910  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.913  0.912  0.910  0.916
  0.910  0.910  0.911  0.913  0.911  0.910  0.914  0.914  0.912  0.910  0.917
    320    330    340    350    360    370    380    390    400    410    420
  0.910  0.911  0.907  0.908  0.908  0.910  0.908  0.910  0.907  0.911  0.906
  0.911  0.911  0.908  0.909  0.909  0.910  0.909  0.910  0.907  0.911  0.907
  0.911  0.911  0.908  0.909  0.909  0.911  0.909  0.912  0.909  0.912  0.907
  0.912  0.911  0.909  0.910  0.909  0.912  0.909  0.912  0.910  0.912  0.907
  0.912  0.912  0.909  0.910  0.909  0.912  0.910  0.912  0.910  0.912  0.908
  0.912  0.912  0.910  0.910  0.909  0.912  0.911  0.912  0.910  0.912  0.908
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.910  0.913  0.909
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.914  0.909
    430    440    450    460    470    480    490    500    510    520    530
  0.909  0.905  0.906  0.907  0.906  0.909  0.907  0.906  0.911  0.907  0.910
  0.911  0.908  0.907  0.907  0.906  0.909  0.907  0.907  0.912  0.910  0.911
  0.911  0.909  0.907  0.909  0.907  0.909  0.908  0.908  0.912  0.910  0.911
  0.911  0.909  0.908  0.910  0.907  0.910  0.908  0.908  0.913  0.911  0.911
  0.911  0.910  0.908  0.911  0.907  0.910  0.908  0.908  0.914  0.911  0.911
  0.912  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.911
  0.913  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.912
  0.913  0.911  0.909  0.912  0.907  0.911  0.909  0.910  0.915  0.912  0.912
  0.913  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
  0.914  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
    540    550    560    570    580    590    600    610    620    630    640
  0.910  0.910  0.907  0.907  0.906  0.904  0.906  0.910  0.913  0.906  0.907
  0.911  0.910  0.908  0.907  0.907  0.907  0.908  0.911  0.913  0.910  0.908
  0.911  0.911  0.910  0.909  0.907  0.907  0.908  0.911  0.914  0.910  0.909
  0.911  0.911  0.910  0.909  0.907  0.907  0.909  0.911  0.914  0.910  0.909
  0.912  0.911  0.910  0.909  0.908  0.907  0.910  0.911  0.915  0.910  0.909
  0.912  0.912  0.911  0.909  0.908  0.907  0.910  0.912  0.915  0.910  0.909
  0.913  0.913  0.911  0.910  0.910  0.907  0.910  0.913  0.915  0.911  0.910
  0.913  0.914  0.912  0.910  0.910  0.908  0.911  0.913  0.916  0.911  0.910
  0.913  0.914  0.912  0.910  0.911  0.908  0.911  0.913  0.916  0.912  0.910
  0.914  0.914  0.913  0.911  0.911  0.908  0.911  0.914  0.916  0.912  0.910
    650    660    670    680    690    700    710    720    730    740    750
  0.906  0.910  0.911  0.913  0.907  0.909  0.909  0.912  0.914  0.908  0.907
  0.907  0.910  0.911  0.913  0.909  0.909  0.911  0.913  0.914  0.909  0.909
  0.909  0.910  0.912  0.914  0.909  0.910  0.911  0.914  0.915  0.910  0.909
  0.909  0.910  0.912  0.916  0.909  0.911  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.910  0.912  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.914  0.913  0.913  0.915  0.915  0.910  0.910
  0.910  0.911  0.913  0.917  0.914  0.913  0.913  0.915  0.916  0.911  0.910
  0.911  0.912  0.913  0.918  0.914  0.913  0.913  0.916  0.916  0.911  0.911
  0.911  0.912  0.914  0.918  0.914  0.913  0.913  0.916  0.917  0.911  0.911
  0.911  0.913  0.914  0.919  0.915  0.913  0.914  0.916  0.917  0.911  0.911
    760    770    780    790    800    810    820    830    840    850    860
  0.909  0.911  0.914  0.907  0.907  0.908  0.908  0.906  0.907  0.910  0.910
  0.910  0.911  0.914  0.908  0.908  0.908  0.910  0.910  0.909  0.911  0.911
  0.910  0.913  0.917  0.910  0.909  0.909  0.910  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.910  0.910  0.909  0.911  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.911  0.910  0.909  0.912  0.911  0.912  0.912  0.912
  0.910  0.913  0.918  0.911  0.911  0.909  0.912  0.912  0.912  0.912  0.912
  0.911  0.914  0.918  0.911  0.911  0.909  0.913  0.912  0.913  0.913  0.913
  0.911  0.914  0.919  0.911  0.911  0.910  0.913  0.913  0.913  0.913  0.914
  0.912  0.914  0.919  0.911  0.912  0.910  0.914  0.913  0.914  0.913  0.914
  0.912  0.914  0.919  0.912  0.912  0.910  0.914  0.913  0.914  0.913  0.915
    870    880    890    900    910    920    930    940    950    960    970
  0.910  0.909  0.913  0.912  0.908  0.909  0.909  0.907  0.910  0.909  0.908
  0.910  0.912  0.914  0.915  0.912  0.913  0.910  0.908  0.910  0.910  0.908
  0.910  0.912  0.914  0.916  0.912  0.915  0.912  0.909  0.911  0.910  0.909
  0.911  0.913  0.915  0.916  0.913  0.916  0.913  0.909  0.911  0.911  0.909
  0.912  0.913  0.915  0.917  0.913  0.917  0.914  0.909  0.911  0.911  0.909
  0.913  0.913  0.915  0.918  0.913  0.917  0.915  0.910  0.911  0.911  0.909
  0.913  0.914  0.917  0.918  0.914  0.917  0.915  0.911  0.911  0.911  0.909
  0.913  0.914  0.918  0.918  0.914  0.917  0.915  0.911  0.912  0.911  0.910
  0.915  0.914  0.918  0.919  0.915  0.918  0.915  0.912  0.912  0.912  0.910
  0.915  0.915  0.918  0.920  0.915  0.918  0.916  0.912  0.913  0.912  0.910
    980    990   1000   1010   1020   1030   1040   1050   1060   1070   1080
  0.907  0.911  0.908  0.913  0.910  0.910  0.912  0.906  0.910  0.910  0.908
  0.909  0.912  0.908  0.913  0.914  0.911  0.914  0.909  0.911  0.910  0.908
  0.909  0.912  0.909  0.914  0.914  0.911  0.916  0.909  0.914  0.911  0.909
  0.911  0.912  0.909  0.915  0.915  0.912  0.917  0.909  0.915  0.911  0.909
  0.911  0.913  0.909  0.915  0.915  0.912  0.917  0.911  0.915  0.912  0.910
  0.912  0.914  0.910  0.916  0.916  0.914  0.917  0.912  0.915  0.913  0.911
  0.912  0.914  0.912  0.916  0.916  0.915  0.917  0.912  0.916  0.913  0.911
  0.912  0.915  0.912  0.917  0.917  0.916  0.918  0.912  0.916  0.914  0.911
  0.912  0.915  0.912  0.918  0.918  0.916  0.918  0.913  0.917  0.914  0.911
  0.913  0.915  0.913  0.918  0.918  0.916  0.918  0.913  0.917  0.915  0.911
   1090
  0.907
  0.908
  0.908
  0.908
  0.910
  0.910
  0.911
  0.911
  0.911
  0.911

> 
> ## Can take pre-computed dissimilarity objects
> d1 <- distance(ImbrieKipp, V12.122)
> d2 <- distance(ImbrieKipp)
> ik <- analog(d1, d2, keep.train = TRUE)
> ik

	Analogue matching for fossil samples

Call: analog(x = d1, train = d2, keep.train = TRUE) 
Dissimilarity: euclidean 

Percentiles of the dissimilarities for the training set:

    1%     2%     5%    10%    20% 
0.0669 0.0956 0.1304 0.1739 0.2341 

	Minimum dissimilarity per sample

Dissimilarity: euclidean 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.297 0.296 0.297 0.296 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.296 0.297 0.296 0.297 0.296 0.297 0.296 0.296 0.296 0.296 0.296 0.296 0.296 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.296 0.296 0.296 0.296 0.296 0.296 0.297 0.296 0.296 0.296 0.297 0.296 0.297 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.296 0.296 0.295 0.296 0.296 0.296 0.296 0.296 0.296 0.297 0.297 0.296 0.297 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.296 0.296 0.296 0.297 0.296 0.296 0.296 0.296 0.297 0.296 0.297 0.296 0.296 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.297 0.297 0.296 0.296 0.297 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.296 0.297 0.296 0.296 
 1040  1050  1060  1070  1080  1090 
0.296 0.296 0.297 0.296 0.296 0.296 

> 
> 
> 
> 
> cleanEx()
> nameEx("bayesF")
> ### * bayesF
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bayesF
> ### Title: Bayes factors
> ### Aliases: bayesF print.bayesF plot.bayesF
> ### Keywords: univar methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 12)
> 
> ## fit the ROC curve
> swap.roc <- roc(swap.ana, groups = grps)
> swap.roc

	ROC curve of dissimilarities

Discrimination for all groups:

Optimal Dissimilarity = 0.575 

AUC = 0.974, p-value: < 2.22e-16
No. within: 167   No. outside: 1837 

> 
> ## calculate the Bayes factors of analogue and no-analogue
> ## (uses observed probabilities of analogue/no-analogue
> swap.bayes <- bayesF(swap.roc)
> swap.bayes

	Bayes factors (likelihood ratios)

Object: swap.roc 

Groups (N = 12):
  1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12


Prior probabilities:
Positive: 0.5   Negative: 0.5 

> 
> ## plot the probability of analogue
> plot(swap.bayes)
> 
> ## Not run: 
> ##D ## calculate the Bayes factors of analogue and no-analogue
> ##D ## with prior probabilities c(0.5, 0.05)
> ##D swap.bayes2 <- bayesF(swap.roc, prior = c(0.5, 0.05))
> ##D swap.bayes
> ##D 
> ##D ## plot the probability of analogue
> ##D plot(swap.bayes2)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("bootstrap")
> ### * bootstrap
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootstrap
> ### Title: Bootstrap estimation and errors
> ### Aliases: bootstrap bootstrap.default bootstrap.mat print.bootstrap.mat
> ###   residuals.bootstrap.mat resid.bootstrap.mat
> ###   print.residuals.bootstrap.mat fitted.bootstrap.mat
> ###   print.fitted.bootstrap.mat
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Imbrie and Kipp foraminfera sea-surface temperature 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> 
> ## bootstrap training set
> ik.boot <- bootstrap(ik.mat, n.boot = 100)
> ik.boot

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP     S1    S2 r.squared avg.bias max.bias
LOO       3 1.713      -     -    0.9409   0.1328    5.167
Bootstrap 5 1.953 0.9133 1.726    0.9707   0.3017    5.484

> summary(ik.boot)

	Bootstrap results for palaeoecological models

Model type: MAT 
Weighted mean: FALSE 
Number of bootstrap cycles: 100 

Leave-one-out and bootstrap-derived error estimates:

          k RMSEP     S1    S2 r.squared avg.bias max.bias
LOO       3 1.713      -     -    0.9409   0.1328    5.167
Bootstrap 5 1.953 0.9133 1.726    0.9707   0.3017    5.484


Bootstrap estimated values for training set:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   7.484    6.697    6.831    7.121    7.748    9.164    5.731   13.332 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  13.465   13.969   15.566   15.070   14.451   17.200   14.167   20.237 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  21.208   18.618   16.955   23.597   24.000   21.665   22.544   23.500 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  23.417   24.941   24.504   23.125   23.922   25.633   25.558   24.925 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  24.837   24.668   25.240   25.705   26.011   26.743   24.352   25.476 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  26.420   26.671   26.695   26.718   26.746   26.070   26.828   26.808 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  26.828   27.166   26.582   27.057   27.274   26.591   26.438   27.202 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  27.085   27.251   27.280   27.184   27.031 

Training set assessment:

          Obs    Est    Resid Boot.Est Boot.Resid      s1     s2 RMSEP
V14.61    2.0  7.167  5.16667    7.484    5.48438 1.39633 5.6540 2.466
V17.196   5.0  4.833 -0.16667    6.697    1.69677 1.91685 2.5367 2.650
V18.110   5.5  4.667 -0.83333    6.831    1.33077 1.68322 2.1287 2.428
V16.227   7.0  7.167  0.16667    7.121    0.12105 1.75733 1.7383 2.455
V14.47    7.0  7.667  0.66667    7.748    0.74848 1.41181 1.5789 2.230
V23.22   10.5 10.000 -0.50000    9.164   -1.33636 1.54976 2.0285 2.345
V2.12    11.0  4.833 -6.16667    5.731   -5.26857 1.40499 5.4475 2.290
V23.29   10.0 11.833  1.83333   13.332    3.33200 1.39485 3.6014 2.333
V12.43   13.0 13.500  0.50000   13.465    0.46500 0.98360 1.0768 2.184
R9.7     12.0 13.667  1.66667   13.969    1.96944 1.08676 2.2421 2.308
A157.3   14.0 14.500  0.50000   15.566    1.56579 1.08211 1.8952 2.402
V23.81   14.5 14.333 -0.16667   15.070    0.56977 1.17078 1.2898 2.546
V23.82   15.0 14.167 -0.83333   14.451   -0.54884 1.13376 1.2477 2.636
V12.53   14.5 17.000  2.50000   17.200    2.70000 1.01784 2.8811 2.704
V23.83   16.0 14.500 -1.50000   14.167   -1.83256 0.93852 2.0539 2.794
V12.56   18.0 20.667  2.66667   20.237    2.23714 1.61848 2.7476 3.191
A152.84  20.0 22.000  2.00000   21.208    1.20811 1.54639 1.9458 3.259
V16.50   18.0 17.167 -0.83333   18.618    0.61765 1.41667 1.5262 3.304
V22.122  19.0 15.500 -3.50000   16.955   -2.04524 1.30556 2.4180 3.365
V16.41   18.5 23.333  4.83333   23.597    5.09737 0.84485 5.1651 3.325
V4.32    21.5 24.000  2.50000   24.000    2.50000 0.63896 2.5777 3.388
V12.66   21.0 21.833  0.83333   21.665    0.66486 0.80077 1.0324 3.525
V19.245  21.0 20.833 -0.16667   22.544    1.54390 1.27182 1.9904 3.767
V4.8     24.0 23.833 -0.16667   23.500   -0.50000 1.05603 1.1499 3.804
A180.15  24.0 23.333 -0.66667   23.417   -0.58333 1.02051 1.1606 3.899
V18.34   23.0 25.333  2.33333   24.941    1.94063 0.78200 2.0877 3.937
V20.213  24.0 24.500  0.50000   24.504    0.50387 0.62280 0.7933 4.002
V19.222  23.0 23.833  0.83333   23.125    0.12500 1.05969 1.0538 4.184
A180.39  23.0 24.000  1.00000   23.922    0.92154 0.96338 1.3242 4.254
V16.189  24.0 25.733  1.73333   25.633    1.63333 0.25994 1.6533 4.248
V12.18   25.0 26.067  1.06667   25.558    0.55760 0.41954 0.6927 4.350
V7.67    26.0 25.333 -0.66667   24.925   -1.07500 0.67776 1.2663 4.471
V17.165  26.0 25.333 -0.66667   24.837   -1.16250 0.52397 1.2718 4.539
V19.310  26.0 25.333 -0.66667   24.668   -1.33158 0.85142 1.5745 4.673
V16.190  25.0 25.000  0.00000   25.240    0.24000 0.59783 0.6357 4.718
A153.154 26.0 25.733 -0.26667   25.705   -0.29500 0.27433 0.4002 4.772
V19.308  26.0 25.733 -0.26667   26.011    0.01125 0.46207 0.4574 4.868
V22.172  24.5 26.400  1.90000   26.743    2.24267 0.23326 2.2545 4.934
V10.98   27.0 24.667 -2.33333   24.352   -2.64778 0.63662 2.7212 5.052
V22.219  26.2 25.667 -0.53333   25.476   -0.72381 0.31220 0.7868 5.105
V16.33   25.0 25.733  0.73333   26.420    1.42041 0.52193 1.5114 5.200
V22.204  26.5 26.000 -0.50000   26.671    0.17135 0.44750 0.4735 5.270
V20.167  26.2 26.167 -0.03333   26.695    0.49487 0.56520 0.7458 5.358
V10.89   26.0 27.233  1.23333   26.718    0.71800 0.50893 0.8764 5.427
V12.79   26.0 27.000  1.00000   26.746    0.74615 0.44358 0.8651 5.498
V19.216  27.0 25.667 -1.33333   26.070   -0.92973 0.45195 1.0311 5.577
V14.90   27.0 26.833 -0.16667   26.828   -0.17241 0.35244 0.3869 5.649
A180.72  27.5 26.667 -0.83333   26.808   -0.69231 0.33932 0.7681 5.730
V16.21   27.0 26.400 -0.60000   26.828   -0.17176 0.40392 0.4334 5.820
A180.76  27.0 27.167  0.16667   27.166    0.16579 0.15816 0.2277 5.899
V15.164  27.0 26.733 -0.26667   26.582   -0.41758 0.41239 0.5825 6.004
A180.78  27.0 26.833 -0.16667   27.057    0.05714 0.33544 0.3355 6.099
V14.5    27.0 27.333  0.33333   27.274    0.27371 0.19450 0.3342 6.197
V3.128   29.0 26.067 -2.93333   26.591   -2.40882 0.52035 2.4628 6.320
A179.13  28.5 26.667 -1.83333   26.438   -2.06211 0.29558 2.0826 6.415
V9.31    27.5 27.167 -0.33333   27.202   -0.29765 0.33134 0.4418 6.527
V20.230  27.5 27.333 -0.16667   27.085   -0.41471 0.26115 0.4880 6.637
V20.7    27.5 27.333 -0.16667   27.251   -0.24903 0.23697 0.3411 6.750
V20.234  27.0 27.333  0.33333   27.280    0.28000 0.24160 0.3671 6.864
V18.21   27.0 27.333  0.33333   27.184    0.18364 0.24431 0.3027 6.987
V12.122  28.0 27.000 -1.00000   27.031   -0.96857 0.08908 0.9725 7.122
> 
> ## Bootstrap fitted values for training set
> fitted(ik.boot)

	Modern Analogue Technique: Bootstrap fitted values for the training
	set

No. of analogues (k) : 5 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   7.484    6.697    6.831    7.121    7.748    9.164    5.731   13.332 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  13.465   13.969   15.566   15.070   14.451   17.200   14.167   20.237 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  21.208   18.618   16.955   23.597   24.000   21.665   22.544   23.500 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  23.417   24.941   24.504   23.125   23.922   25.633   25.558   24.925 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  24.837   24.668   25.240   25.705   26.011   26.743   24.352   25.476 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  26.420   26.671   26.695   26.718   26.746   26.070   26.828   26.808 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  26.828   27.166   26.582   27.057   27.274   26.591   26.438   27.202 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  27.085   27.251   27.280   27.184   27.031 
> 
> ## residuals
> resid(ik.boot) # uses abbreviated form

	Bootstrap residuals
Model type: MAT 
Weighted: FALSE 

(k chosen from model with lowest RMSEP)

Model residuals:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.1667  -0.1667  -0.8333   0.1667   0.6667  -0.5000  -6.1667   1.8333 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.5000   1.6667   0.5000  -0.1667  -0.8333   2.5000  -1.5000   2.6667 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  2.0000  -0.8333  -3.5000   4.8333   2.5000   0.8333  -0.1667  -0.1667 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.6667   2.3333   0.5000   0.8333   1.0000   1.7333   1.0667  -0.6667 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.6667  -0.6667   0.0000  -0.2667  -0.2667   1.9000  -2.3333  -0.5333 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  0.7333  -0.5000  -0.0333   1.2333   1.0000  -1.3333  -0.1667  -0.8333 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.6000   0.1667  -0.2667  -0.1667   0.3333  -2.9333  -1.8333  -0.3333 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.1667  -0.1667   0.3333   0.3333  -1.0000 

Bootstrap residuals:
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.5052   0.4839   0.4103   0.3947   0.7424  -1.6212  -6.3095   2.7267 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.8000   1.5926   1.2807   0.1202  -0.5659   2.9065  -1.8333   1.9095 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  1.6982   0.3039  -2.4484   5.0614   2.5667   0.6306   0.5407  -0.4551 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.6389   2.4896   0.8441   0.6417   1.0043   1.5970   0.8427  -0.6417 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.8104  -0.8465  -0.0283  -0.2333  -0.0556   2.0059  -2.7130  -0.6048 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  1.1959   0.1081   0.4111   0.8508   0.8718  -1.1928  -0.0575  -0.7179 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.2598   0.1974  -0.3182  -0.0762   0.3400  -2.5049  -2.0246  -0.2500 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.3245  -0.1989   0.3069   0.2838  -0.9848 

> 
> 
> 
> cleanEx()
> nameEx("bootstrap.wa")
> ### * bootstrap.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bootstrap.wa
> ### Title: Bootstrap estimation and errors for WA models
> ### Aliases: bootstrap.wa print.bootstrap.wa
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp
> data(ImbrieKipp)
> data(SumSST)
> ik.wa <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+             min.tol = 2, small.tol = "min")
> ik.wa

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## compare actual tolerances to working values
> with(ik.wa, rbind(tolerances, model.tol))
             O.univ  G.cglob  G.ruber  G.tenel  G.saccu  G.rubes   G.pacL
tolerances 3.746359 1.895600 1.909561 2.124799 1.979651 1.968294 3.941352
model.tol  3.746359 2.124799 2.124799 2.124799 2.124799 2.124799 3.941352
             G.pacR G.bullo  G.falco  G.calid  G.aequi  G.gluti  G.duter
tolerances 5.181162 5.82798 3.109193 2.973112 2.561697 5.898256 1.998304
model.tol  5.181162 5.82798 3.109193 2.973112 2.561697 5.898256 2.124799
            G.infla   G.trnL  G.trnR  G.crasf  G.scitu  G.mentu  P.obliq
tolerances 4.723884 4.161704 3.43492 3.354021 3.990673 2.386584 1.554762
model.tol  4.723884 4.161704 3.43492 3.354021 3.990673 2.386584 2.124799
            C.nitid S.dehis  G.digit    Other   G.quin  G.hirsu
tolerances 1.461725 3.84473 3.108881 5.112464 4.268777 3.942135
model.tol  2.124799 3.84473 3.108881 5.112464 4.268777 3.942135
> 
> ## bootstrap the WA model
> ik.boot <- bootstrap(ik.wa, n.boot = 100)
Bootstrap sample 100 
> 
> ## performance statistics
> performance(ik.boot)
   RMSEP       R2 Avg.Bias Max.Bias 
   2.385    0.895   -0.178   -3.206 
> 
> 
> 
> cleanEx()
> nameEx("caterpillarPlot")
> ### * caterpillarPlot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: caterpillarPlot
> ### Title: Caterpillar plot of species' WA optima and tolerance range.
> ### Aliases: caterpillarPlot caterpillarPlot.default
> ###   caterpillarPlot.data.frame caterpillarPlot.wa caterpillar
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> data(SumSST)
> 
> ## default plot
> caterpillar(ImbrieKipp, SumSST)
> 
> ## customisation
> opttol <-
+     caterpillar(ImbrieKipp, SumSST, col = "red2",
+                 bg = "yellow", lcol = "blue",
+                 xlab = expression(Summer ~ Sea ~ Surface ~
+                                  Temperature~(degree*C)))
> 
> ## invisibly returns the optima and tolerances
> head(opttol)
          Optima Tolerance
P.obliq 26.94320  1.554762
G.duter 26.49014  1.998304
C.nitid 26.41005  1.461725
G.rubes 26.27479  1.968294
G.saccu 26.18001  1.979651
G.mentu 26.13778  2.386584
> 
> 
> 
> cleanEx()
> nameEx("chooseTaxa")
> ### * chooseTaxa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: chooseTaxa
> ### Title: Select taxa (variables) on basis of maximum abundance attained
> ###   and number of occurrences.
> ### Aliases: chooseTaxa chooseTaxa.default
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> IK2 <- chooseTaxa(ImbrieKipp, n.occ = 5)
> dim(ImbrieKipp)
[1] 61 27
> dim(IK2)
[1] 61 27
> 
> ## return a logical vector to select species/columns
> chooseTaxa(ImbrieKipp, n.occ = 5, value = FALSE)
 O.univ G.cglob G.ruber G.tenel G.saccu G.rubes  G.pacL  G.pacR G.bullo G.falco 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf G.scitu G.mentu 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
P.obliq C.nitid S.dehis G.digit   Other  G.quin G.hirsu 
   TRUE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE 
> 
> 
> 
> cleanEx()
> nameEx("cma")
> ### * cma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cma
> ### Title: Close modern analogues
> ### Aliases: cma cma.default cma.analog cma.mat cma.predict.mat print.cma
> ###   plot.cma
> ### Keywords: methods manip hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAP and RLGH reference samples
> (ik.ana <- analog(ImbrieKipp, V12.122, method = "chord"))

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.910 0.908 0.910 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.909 0.911 0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.906 0.909 0.910 0.907 0.907 0.912 0.910 0.911 0.907 0.908 0.908 0.910 0.908 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.910 0.907 0.911 0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906 0.911 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.907 0.910 0.910 0.910 0.907 0.907 0.906 0.904 0.906 0.910 0.913 0.906 0.907 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.906 0.910 0.911 0.913 0.907 0.909 0.909 0.912 0.914 0.908 0.907 0.909 0.911 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.914 0.907 0.907 0.908 0.908 0.906 0.907 0.910 0.910 0.910 0.909 0.913 0.912 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.908 0.909 0.909 0.907 0.910 0.909 0.908 0.907 0.911 0.908 0.913 0.910 0.910 
 1040  1050  1060  1070  1080  1090 
0.912 0.906 0.910 0.910 0.908 0.907 

> 
> ## close modern analogues --- no analogues are "close"
> (ik.cma <- cma(ik.ana, cutoff = 0.91))

	Close modern analogues of fossil samples

Call: cma(object = ik.ana, cutoff = 0.91) 

Dissimilarity: chord 

     k: Not supplied

Cutoff: 0.91 

	Number of analogues per fossil sample:

   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
  13   12   14   16   14    6    4    4    6    2    1    1    0    3    0    5 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
   3   11    3    2   10    8    9    8    1    4    8    1    1    7    9    0 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
   1    0    5    5    8    1    4    1    3    0   11    1    4   13    3   16 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
   4   14    8    0    2    0    0    0    4    7    7   15    5    0    0    1 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
   8    4    1    0    0    5    2    1    0    0    3    4    2    0    0    3 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
   4    9    3    1    2    1    0    2    1    0    0    1    1    2    6    0 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
   3   10    3    0    6    0    0    0    0    4    0    0    5    5 

> summary(ik.cma)

	Close modern analogues of fossil samples

Call: cma(object = ik.ana, cutoff = 0.91) 

Dissimilarity: chord 

     k: Not supplied

Cutoff: 0.91 

	Number of analogues per fossil sample:

   0   10   20   30   40   50   60   70   80   90  100  110  120  130  140  150 
  13   12   14   16   14    6    4    4    6    2    1    1    0    3    0    5 
 160  170  180  190  200  210  220  230  240  250  260  270  280  290  300  310 
   3   11    3    2   10    8    9    8    1    4    8    1    1    7    9    0 
 320  330  340  350  360  370  380  390  400  410  420  430  440  450  460  470 
   1    0    5    5    8    1    4    1    3    0   11    1    4   13    3   16 
 480  490  500  510  520  530  540  550  560  570  580  590  600  610  620  630 
   4   14    8    0    2    0    0    0    4    7    7   15    5    0    0    1 
 640  650  660  670  680  690  700  710  720  730  740  750  760  770  780  790 
   8    4    1    0    0    5    2    1    0    0    3    4    2    0    0    3 
 800  810  820  830  840  850  860  870  880  890  900  910  920  930  940  950 
   4    9    3    1    2    1    0    2    1    0    0    1    1    2    6    0 
 960  970  980  990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 
   3   10    3    0    6    0    0    0    0    4    0    0    5    5 


Distances:

       0    10    20    30    40    50    60    70    80    90  100   110 120
1  0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.91 0.908    
2  0.903 0.904 0.904 0.904 0.905 0.908 0.908 0.909 0.908 0.910               
3  0.903 0.904 0.906 0.904 0.906 0.908 0.909 0.910 0.909                     
4  0.903 0.906 0.906 0.905 0.906 0.909 0.910 0.910 0.909                     
5  0.905 0.906 0.906 0.905 0.908 0.909             0.909                     
6  0.905 0.907 0.906 0.905 0.908 0.909             0.910                     
7  0.907 0.907 0.907 0.906 0.908                                             
8  0.907 0.908 0.907 0.906 0.908                                             
9  0.907 0.909 0.907 0.906 0.908                                             
10 0.908 0.910 0.907 0.906 0.908                                             
11 0.908 0.910 0.907 0.907 0.908                                             
12 0.909 0.910 0.908 0.908 0.909                                             
13 0.910       0.909 0.908 0.909                                             
14             0.909 0.909 0.909                                             
15                   0.909                                                   
16                   0.909                                                   
     130 140   150   160   170   180   190   200   210   220   230   240   250
1  0.909     0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906
2  0.909     0.909 0.910 0.907 0.910 0.910 0.908 0.908 0.909 0.908       0.908
3  0.910     0.909 0.910 0.907 0.910       0.908 0.908 0.909 0.908       0.909
4            0.910       0.907             0.908 0.908 0.909 0.908       0.910
5            0.910       0.907             0.908 0.909 0.909 0.909            
6                        0.908             0.909 0.910 0.909 0.909            
7                        0.908             0.909 0.910 0.909 0.910            
8                        0.908             0.910 0.910 0.910 0.910            
9                        0.909             0.910       0.910                  
10                       0.910             0.910                              
11                       0.910                                                
12                                                                            
13                                                                            
14                                                                            
15                                                                            
16                                                                            
     260   270  280   290   300 310  320 330   340   350   360  370   380  390
1  0.906 0.909 0.91 0.907 0.907     0.91     0.907 0.908 0.908 0.91 0.908 0.91
2  0.908            0.908 0.908              0.908 0.909 0.909      0.909     
3  0.908            0.909 0.908              0.908 0.909 0.909      0.909     
4  0.908            0.909 0.909              0.909 0.910 0.909      0.909     
5  0.908            0.910 0.909              0.909 0.910 0.909                
6  0.909            0.910 0.909                          0.909                
7  0.909            0.910 0.909                          0.909                
8  0.910                  0.910                          0.909                
9                         0.910                                               
10                                                                            
11                                                                            
12                                                                            
13                                                                            
14                                                                            
15                                                                            
16                                                                            
     400 410   420   430   440   450   460   470   480   490   500 510   520
1  0.907     0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906     0.907
2  0.907     0.907       0.908 0.907 0.907 0.906 0.909 0.907 0.907     0.910
3  0.909     0.907       0.909 0.907 0.909 0.907 0.909 0.908 0.908          
4            0.907       0.909 0.908       0.907 0.910 0.908 0.908          
5            0.908             0.908       0.907       0.908 0.908          
6            0.908             0.908       0.907       0.908 0.909          
7            0.909             0.908       0.907       0.908 0.909          
8            0.909             0.909       0.907       0.909 0.910          
9            0.909             0.909       0.908       0.909                
10           0.909             0.909       0.908       0.909                
11           0.910             0.909       0.908       0.910                
12                             0.910       0.908       0.910                
13                             0.910       0.909       0.910                
14                                         0.909       0.910                
15                                         0.909                            
16                                         0.909                            
   530 540 550   560   570   580   590   600 610 620   630   640   650  660 670
1              0.907 0.907 0.906 0.904 0.906         0.906 0.907 0.906 0.91    
2              0.908 0.907 0.907 0.907 0.908               0.908 0.907         
3              0.910 0.909 0.907 0.907 0.908               0.909 0.909         
4              0.910 0.909 0.907 0.907 0.909               0.909 0.909         
5                    0.909 0.908 0.907 0.910               0.909               
6                    0.909 0.908 0.907                     0.909               
7                    0.910 0.910 0.907                     0.910               
8                                0.908                     0.910               
9                                0.908                                         
10                               0.908                                         
11                               0.909                                         
12                               0.909                                         
13                               0.909                                         
14                               0.909                                         
15                               0.910                                         
16                                                                             
   680   690   700   710 720 730   740   750   760 770 780   790   800   810
1      0.907 0.909 0.909         0.908 0.907 0.909         0.907 0.907 0.908
2      0.909 0.909               0.909 0.909 0.910         0.908 0.908 0.908
3      0.909                     0.910 0.909               0.910 0.909 0.909
4      0.909                           0.910                     0.910 0.909
5      0.910                                                           0.909
6                                                                      0.909
7                                                                      0.909
8                                                                      0.910
9                                                                      0.910
10                                                                          
11                                                                          
12                                                                          
13                                                                          
14                                                                          
15                                                                          
16                                                                          
     820   830   840  850 860  870   880 890 900   910   920   930   940 950
1  0.908 0.906 0.907 0.91     0.91 0.909         0.908 0.909 0.909 0.907    
2  0.910       0.909          0.91                           0.910 0.908    
3  0.910                                                           0.909    
4                                                                  0.909    
5                                                                  0.909    
6                                                                  0.910    
7                                                                           
8                                                                           
9                                                                           
10                                                                          
11                                                                          
12                                                                          
13                                                                          
14                                                                          
15                                                                          
16                                                                          
     960   970   980 990  1000 1010 1020 1030 1040  1050 1060 1070  1080  1090
1  0.909 0.908 0.907     0.908                     0.906           0.908 0.907
2  0.910 0.908 0.909     0.908                     0.909           0.908 0.908
3  0.910 0.909 0.909     0.909                     0.909           0.909 0.908
4        0.909           0.909                     0.909           0.909 0.908
5        0.909           0.909                                     0.910 0.910
6        0.909           0.910                                                
7        0.909                                                                
8        0.910                                                                
9        0.910                                                                
10       0.910                                                                
11                                                                            
12                                                                            
13                                                                            
14                                                                            
15                                                                            
16                                                                            

Samples:

         0      10      20      30      40      50       60      70      80
1  V12.122 V12.122 V12.122 V20.230 V22.172 V22.172  V22.172  V10.89 V22.172
2    V14.5 V20.234 V20.234  V14.90 V20.167 V20.167 A153.154 V22.172 V19.216
3  V20.234   V14.5  V16.21 V22.172 V19.216 V19.216   V10.89  V16.21 V20.167
4   V18.21  V18.21 A180.76   V9.31  V10.89  V10.89  A179.13  V14.90  V16.21
5  A180.76 A180.76   V14.5  V12.79 V22.204  V16.21                   V10.89
6  A180.72 A180.72 V15.164 V19.216  V16.21 V15.164                  V15.164
7  V15.164 V20.230 V20.230 A180.72 V20.234                                 
8   V16.21 V20.167  V14.90 V22.204 V20.230                                 
9  V20.167  V16.21 A180.72 A180.76  V14.90                                 
10 V20.230   V20.7 V20.167 V20.167 V15.164                                 
11  V12.79  V12.79   V9.31 V20.234 A180.72                                 
12 V22.172  V14.90  V18.21  V16.21  V12.79                                 
13  V14.90          V12.79 V15.164 V12.122                                 
14                 V22.172 V12.122 A180.76                                 
15                          V10.89                                         
16                          V3.128                                         
        90     100   110  120     130  140     150     160      170     180
1  V19.216 V19.216 V9.31 None   V9.31 None  V10.89 V20.167  V20.167 A179.13
2  V22.172                     V14.90      V22.172 V20.230   V10.89 V20.167
3                             V19.216      V20.167  V10.89  V20.230  V14.90
4                                          V19.216           V16.21        
5                                           V16.21          V22.172        
6                                                          A153.154        
7                                                            V14.90        
8                                                           A179.13        
9                                                             V9.31        
10                                                          V22.219        
11                                                          V19.216        
12                                                                         
13                                                                         
14                                                                         
15                                                                         
16                                                                         
       190     200     210     220     230    240     250     260    270
1  V19.216 V20.230  V14.90 V12.122 V12.122 V3.128  V14.90  V14.90 V14.90
2  V20.230  V14.90 V22.172  V14.90  V18.21        V22.204 V20.167       
3          V22.172 V20.167 V20.230  V14.90        V22.172 V22.172       
4            V9.31  V3.128  V18.21   V14.5        A180.72  V3.128       
5          V20.167 V12.122 V20.167 A180.76                V12.122       
6          V20.234 V20.230 V20.234 V20.234                A180.72       
7          V12.122 V20.234   V14.5  V3.128                V22.204       
8           V12.79 A180.72 V22.172 A180.72                 V12.79       
9           V16.21         A180.72                                      
10         A180.72                                                      
11                                                                      
12                                                                      
13                                                                      
14                                                                      
15                                                                      
16                                                                      
       280     290     300  310     320  330      340     350     360     370
1  V22.172 V12.122 V22.172 None V19.216 None  V19.216 V20.230 V20.167 V19.216
2           V14.90 V20.167                     V10.89 V20.167 V22.172        
3          A180.72 V19.216                    V22.172   V9.31  V16.21        
4            V14.5 V15.164                   A153.154 V19.216  V10.89        
5          V20.167  V16.21                    V20.167  V14.90  V14.90        
6           V18.21  V10.89                                    V20.234        
7          A180.76  V14.90                                    V15.164        
8                  V20.234                                    V12.122        
9                  V20.230                                                   
10                                                                           
11                                                                           
12                                                                           
13                                                                           
14                                                                           
15                                                                           
16                                                                           
       380     390     400  410     420     430     440     450     460     470
1    V9.31 V19.216   V9.31 None   V9.31 V12.122   V9.31 A180.76 V20.167 V20.167
2  V12.122          V14.90      V20.234          V14.90  V18.21  V3.128 V22.172
3  V20.234         V22.204       V14.90         V20.234 V20.234   V14.5 V20.234
4   V14.90                      V20.230         V20.230 A180.72          V3.128
5                               V22.172                 V12.122          V14.90
6                               V12.122                   V14.5         V20.230
7                               V20.167                 V20.230         A180.76
8                               V15.164                 V15.164         A180.72
9                                V3.128                  V3.128         V22.204
10                              A180.76                  V14.90         V19.216
11                              A180.72                 V20.167          V10.89
12                                                      V22.204          V12.79
13                                                      V22.172         V15.164
14                                                                        V9.31
15                                                                        V14.5
16                                                                       V16.21
       480     490     500  510     520  530  540  550     560     570     580
1   V14.90 V20.234 V12.122 None  V14.90 None None None  V14.90 V20.230 V22.204
2  A180.76  V3.128 V20.234      V22.204                V20.230   V9.31  V12.79
3  V22.204 A180.76 A180.76                             A180.76 A180.78  V14.90
4  V22.172 A180.72 V20.230                               V9.31  V14.90 A180.72
5          V12.122  V18.21                                     A180.72 V22.172
6          V22.204 A180.72                                     V22.204 V20.230
7           V18.21  V3.128                                     A180.76 A180.76
8           V14.90   V14.5                                                    
9            V14.5                                                            
10         V20.230                                                            
11          V12.79                                                            
12         A180.78                                                            
13         V22.172                                                            
14         V20.167                                                            
15                                                                            
16                                                                            
       590     600  610  620    630     640     650    660  670  680     690
1  V20.167  V14.90 None None V14.90 V12.122 V22.204 V14.90 None None A179.13
2  V22.172 A180.72                   V14.90 V12.122                   V16.21
3  V15.164 A180.76                  V20.234 V20.234                   V10.89
4   V16.21 V22.204                  V20.167  V14.90                  V15.164
5   V10.89 V12.122                    V14.5                          V20.167
6  V19.216                          V22.204                                 
7  V20.230                          A180.72                                 
8  V20.234                           V3.128                                 
9   V3.128                                                                  
10  V14.90                                                                  
11 A180.76                                                                  
12 V12.122                                                                  
13   V9.31                                                                  
14 V22.204                                                                  
15 A179.13                                                                  
16                                                                          
       700     710  720  730     740     750     760  770  780     790     800
1  V12.122 V20.167 None None  V14.90 V22.204 V20.234 None None  V18.21 V12.122
2  V22.204                   V22.204 V20.234 V22.204           V12.122  V18.21
3                            A180.72  V14.90                     V14.5   V14.5
4                                    A180.72                           V20.234
5                                                                             
6                                                                             
7                                                                             
8                                                                             
9                                                                             
10                                                                            
11                                                                            
12                                                                            
13                                                                            
14                                                                            
15                                                                            
16                                                                            
       810     820     830     840     850  860     870     880  890  900
1  V12.122  V14.90 V19.216 V19.216 V22.204 None V19.216 V19.216 None None
2   V14.90 V22.204          V16.33              V22.172                  
3  V22.172 V19.216                                                       
4  V22.204                                                               
5  V15.164                                                               
6  V20.234                                                               
7   V12.79                                                               
8    V14.5                                                               
9   V18.21                                                               
10                                                                       
11                                                                       
12                                                                       
13                                                                       
14                                                                       
15                                                                       
16                                                                       
       910     920     930     940  950     960     970     980  990    1000
1  V19.216 V19.216   V9.31 V19.216 None V20.230   V9.31   V9.31 None V19.216
2                  V20.230 V20.230      V12.122 V20.234 V20.230       V14.90
3                            V9.31      V20.234 V20.230  V14.90      V22.172
4                          V20.167              V22.172                V9.31
5                           V14.90              A180.76              V20.230
6                          V22.172              V19.216               V12.79
7                                                V16.21                     
8                                               V20.167                     
9                                               A180.72                     
10                                               V14.90                     
11                                                                          
12                                                                          
13                                                                          
14                                                                          
15                                                                          
16                                                                          
   1010 1020 1030 1040    1050 1060 1070    1080    1090
1  None None None None V19.216 None None V19.216 V22.172
2                      V22.204           V12.122 V22.204
3                       V14.90           V22.172  V14.90
4                      V22.172            V14.90 V19.216
5                                        V22.204  V10.89
6                                                       
7                                                       
8                                                       
9                                                       
10                                                      
11                                                      
12                                                      
13                                                      
14                                                      
15                                                      
16                                                      
> 
> ## plot the results
> plot(ik.cma)
> 
> 
> 
> 
> cleanEx()
> nameEx("compare")
> ### * compare
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: compare
> ### Title: Compare proxies across two data sets
> ### Aliases: compare compare.default
> ### Keywords: methods utility multivariate
> 
> ### ** Examples
> 
> data(ImbrieKipp, V12.122, SumSST)
> compare(ImbrieKipp, V12.122, env = SumSST, ordination = "rda",
+         method = "chord")
     sumMissing sumPoorOpt closestSamp    residLen
0       0.00000    0.00000    29.59716 0.010717787
10      0.00000    0.00000    29.61441 0.009989434
20      0.00000    0.00000    29.58298 0.010953126
30      0.00000    0.00000    29.58222 0.010089393
40      0.00000    0.00000    29.59011 0.009327773
50      0.00000    0.00000    29.55510 0.012228059
60      0.00000    0.00000    29.55327 0.012334105
70      0.00000    0.00000    29.57941 0.009735344
80      0.00000    0.00000    29.57753 0.010859718
90      0.00000    0.00000    29.62131 0.007153104
100     0.00000    0.00000    29.59295 0.009704870
110     0.00000    0.00000    29.61307 0.008160655
120     0.00000    0.00000    29.58028 0.010827828
130     0.00000    0.00000    29.59806 0.008783710
140     0.00000    0.00000    29.57575 0.010405838
150     0.00000    0.00000    29.57993 0.009766353
160     0.00000    0.00000    29.58973 0.008887931
170     0.00000    0.00000    29.57477 0.011110512
180     0.00000    0.00000    29.62846 0.007905512
190     0.00000    0.00000    29.63626 0.008081606
200     0.00000    0.00000    29.63644 0.007634544
210     0.00000    0.00000    29.62998 0.008420406
220     0.00505    0.00505    29.65149 0.007723118
230     0.00474    0.00474    29.64031 0.008275553
240     0.00000    0.00000    29.66013 0.007703899
250     0.00524    0.00524    29.62841 0.007338231
260     0.00000    0.00000    29.64737 0.007140425
270     0.01852    0.01852    29.68784 0.005687661
280     0.01724    0.01724    29.64892 0.006941941
290     0.00518    0.00518    29.65070 0.007122685
300     0.00000    0.00000    29.61796 0.007933554
310     0.00495    0.00495    29.65344 0.005786560
320     0.00000    0.00000    29.59382 0.009116835
330     0.00000    0.00000    29.61592 0.006353057
340     0.00000    0.00000    29.59328 0.008597536
350     0.00000    0.00000    29.62601 0.007367289
360     0.00000    0.00000    29.58535 0.010685638
370     0.00000    0.00000    29.62245 0.008814375
380     0.00422    0.00422    29.63741 0.008133057
390     0.00000    0.00000    29.60813 0.008884824
400     0.00467    0.00467    29.60691 0.007354769
410     0.00000    0.00000    29.63388 0.009211841
420     0.00000    0.00000    29.60942 0.009856581
430     0.00966    0.00966    29.61615 0.009637343
440     0.00649    0.00649    29.61936 0.008311455
450     0.00741    0.00741    29.65269 0.007499648
460     0.00000    0.00000    29.64589 0.007653134
470     0.00000    0.00000    29.60071 0.008713360
480     0.00000    0.00000    29.58647 0.009003201
490     0.00000    0.00000    29.65092 0.007571722
500     0.00000    0.00000    29.62015 0.009442010
510     0.00000    0.00000    29.65456 0.006723777
520     0.00000    0.00000    29.61925 0.007740763
530     0.00800    0.00800    29.55988 0.011081269
540     0.00543    0.00543    29.53572 0.012583966
550     0.00000    0.00000    29.61118 0.006235741
560     0.00000    0.00000    29.62794 0.006508411
570     0.00000    0.00000    29.61558 0.006786947
580     0.00000    0.00000    29.60942 0.007104210
590     0.00000    0.00000    29.58392 0.010732812
600     0.00000    0.00000    29.64794 0.006227589
610     0.00000    0.00000    29.65351 0.006776688
620     0.01478    0.01478    29.66524 0.005498646
630     0.00671    0.00671    29.63843 0.006650115
640     0.00000    0.00000    29.65057 0.006772370
650     0.00719    0.00719    29.64611 0.006924435
660     0.00000    0.00000    29.61538 0.007776705
670     0.00617    0.00617    29.61486 0.008587976
680     0.03015    0.03015    29.65654 0.007273772
690     0.00000    0.00000    29.61081 0.010065633
700     0.00000    0.00000    29.62900 0.007623946
710     0.00000    0.00000    29.62772 0.008854370
720     0.00000    0.00000    29.63361 0.007300729
730     0.02174    0.02174    29.66599 0.006393351
740     0.00535    0.00535    29.63834 0.006951244
750     0.02532    0.02532    29.65012 0.006350255
760     0.02050    0.02050    29.62643 0.007739255
770     0.01190    0.01190    29.60128 0.010976789
780     0.05362    0.05362    29.68196 0.007120291
790     0.02602    0.02602    29.65471 0.008157727
800     0.02090    0.02090    29.64507 0.007953222
810     0.02756    0.02756    29.64670 0.006978752
820     0.02106    0.02106    29.66631 0.004877637
830     0.03572    0.03572    29.63650 0.006206497
840     0.00957    0.00957    29.60969 0.007858339
850     0.00858    0.00858    29.64550 0.006768174
860     0.00308    0.00308    29.60779 0.008545812
870     0.00658    0.00658    29.57878 0.011732939
880     0.00000    0.00000    29.62335 0.007315723
890     0.00338    0.00338    29.62378 0.005181313
900     0.00000    0.00000    29.60686 0.007292905
910     0.00000    0.00000    29.58209 0.008350816
920     0.00348    0.00348    29.61948 0.007604988
930     0.00508    0.00508    29.63927 0.007068426
940     0.00985    0.00985    29.61894 0.008133211
950     0.00735    0.00735    29.64179 0.007309983
960     0.01210    0.01210    29.59823 0.009136771
970     0.01493    0.01493    29.57890 0.009919157
980     0.00000    0.00000    29.60641 0.008236236
990     0.00000    0.00000    29.63809 0.006757469
1000    0.00000    0.00000    29.63248 0.006815332
1010    0.00000    0.00000    29.65252 0.005490630
1020    0.00000    0.00000    29.63384 0.005174208
1030    0.00000    0.00000    29.61341 0.006255757
1040    0.00000    0.00000    29.60268 0.006851327
1050    0.00000    0.00000    29.62339 0.006551518
1060    0.00000    0.00000    29.65691 0.005359522
1070    0.00000    0.00000    29.60088 0.006868555
1080    0.00559    0.00559    29.64297 0.006542620
1090    0.00000    0.00000    29.61947 0.006756146
> 
> 
> 
> cleanEx()
> nameEx("crossval")
> ### * crossval
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: crossval
> ### Title: Cross-validation of palaeoecological transfer function models
> ### Aliases: crossval crossval.wa crossval.pcr print.crossval
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
>      
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## Leave one out CV
> cv.loo <- crossval(mod)
> cv.loo
	Model Cross-validation:

crossval(obj = mod)

Method: LOO

       R2   avgBias maxBias  RMSEP RMSEP2 s1 s2
1 0.90028 -0.013652 -4.5985 2.2179     NA NA NA
> 
> ## k-fold CV (k == 10)
> cv.kfold <- crossval(mod, method = "kfold", kfold = 10, folds = 1)
> cv.kfold
	Model Cross-validation:

crossval(obj = mod, method = "kfold", folds = 1, kfold = 10)

Method: kfold
k: 10
No. of folds: 1

       R2   avgBias maxBias  RMSEP RMSEP2 s1 s2
1 0.90107 0.0070881 -4.4826 2.2102     NA NA NA
> 
> ## n k-fold CV (k == 10, n = 10)
> cv.nkfold <- crossval(mod, method = "kfold", kfold = 10, folds = 10)
> cv.nkfold
	Model Cross-validation:

crossval(obj = mod, method = "kfold", folds = 10, kfold = 10)

Method: kfold
k: 10
No. of folds: 10

      R2    avgBias maxBias  RMSEP RMSEP2      s1     s2
1 0.9009 -0.0095555 -4.4787 2.2111 2.2203 0.20205 2.2111
> 
> ## bootstrap with 100 bootstrap samples
> cv.boot <- crossval(mod, method = "bootstrap", nboot = 100)
> cv.boot
	Model Cross-validation:

crossval(obj = mod, method = "bootstrap", nboot = 100)

Method: bootstrap
No. Bootstraps: 100

       R2   avgBias maxBias  RMSEP RMSEP2      s1     s2
1 0.89898 -0.055311 -4.8169 2.2338  2.285 0.48114 2.2338
> 
> ## extract fitted values and residuals
> fitted(cv.boot)
 [1]  4.119975  3.530722  3.955451  3.910994  8.401368  9.354911  3.043464
 [8] 14.816874 14.432710 17.077844 16.121631 19.108131 18.718219 18.861796
[15] 17.557246 20.697800 19.956844 20.059232 18.657255 23.017531 22.492660
[22] 20.847321 22.533473 22.076781 21.419312 23.500948 23.372827 22.890145
[29] 24.292602 25.713317 25.518983 23.321790 23.724287 23.019422 24.571983
[36] 25.420092 25.824666 26.335258 24.046304 25.480527 26.321834 25.839000
[43] 26.764327 26.437182 26.169108 25.733600 25.853777 26.329405 26.829482
[50] 26.703907 26.864403 26.001962 26.936604 26.820792 26.466440 26.039658
[57] 26.606546 27.229268 26.761941 26.938834 26.823182
> resid(cv.boot)
 [1] -2.11997495  1.46927850  1.54454899  3.08900569 -1.40136781  1.14508924
 [7]  7.95653648 -4.81687383 -1.43270981 -5.07784438 -2.12163085 -4.60813083
[13] -3.71821936 -4.36179569 -1.55724615 -2.69779985  0.04315646 -2.05923196
[19]  0.34274541 -4.51753089 -0.99265995  0.15267941 -1.53347325  1.92321865
[25]  2.58068841 -0.50094761  0.62717280  0.10985520 -1.29260222 -1.71331668
[31] -0.51898266  2.67821000  2.27571284  2.98057772  0.42801653  0.57990829
[37]  0.17533363 -1.83525832  2.95369601  0.71947278 -1.32183430  0.66099987
[43] -0.56432691 -0.43718235 -0.16910755  1.26640047  1.14622329  1.17059537
[49]  0.17051766  0.29609301  0.13559703  0.99803814  0.06339552  2.17920772
[55]  2.03355996  1.46034159  0.89345394  0.27073180  0.23805907  0.06116570
[61]  1.17681753
> 
> ## Principal Components Regression
> mpcr <- pcr(SumSST ~., data = ImbrieKipp, ncomp = 10)
> crossval(mpcr, method = "kfold", kfold = 10, folds = 2, ncomp = 10)
	Model Cross-validation:

crossval(obj = mpcr, method = "kfold", ncomp = 10, folds = 2, 
    kfold = 10)

Method: kfold
k: 10
No. of folds: 2

   comp      R2     avgBias maxBias  RMSEP RMSEP2      s1     s2
1     1 0.93417 -0.06594066 -6.7033 2.5117 2.5526 0.45522 2.5117
2     2 0.95327 -0.01632488 -5.3460 2.1208 2.1249 0.13128 2.1208
3     3 0.95785 -0.01158445 -4.3149 2.0167 2.0221 0.14725 2.0167
4     4 0.95763 -0.00576925 -4.0229 2.0217 2.0291 0.17311 2.0217
5     5 0.95892 -0.00368902 -5.6606 1.9916 2.0111 0.27917 1.9916
6     6 0.96063 -0.03985927 -5.0776 1.9507 1.9667 0.25049 1.9507
7     7 0.95873  0.01335811 -4.3962 1.9977 2.0207 0.30368 1.9977
8     8 0.96168  0.00048673 -4.8165 1.9259 1.9503 0.30728 1.9259
9     9 0.96222 -0.04508615 -4.9545 1.9123 1.9446 0.35286 1.9123
10   10 0.96126  0.02659237 -5.0612 1.9352 1.9652 0.34239 1.9352
> 
> crossval(mpcr, method = "bootstrap", nboot = 100, ncomp = 10)
	Model Cross-validation:

crossval(obj = mpcr, method = "bootstrap", ncomp = 10, nboot = 100)

Method: bootstrap
No. Bootstraps: 100

   comp      R2    avgBias maxBias  RMSEP RMSEP2      s1     s2
1     1 0.94904 -0.1197866 -6.4528 2.3511 2.8135 1.54527 2.3511
2     2 0.95217  0.0042596 -5.3885 2.1464 2.2058 0.50835 2.1464
3     3 0.95592 -0.0117201 -4.4598 2.0620 2.1423 0.58099 2.0620
4     4 0.95586 -0.0331085 -4.3257 2.0637 2.1703 0.67179 2.0637
5     5 0.95808 -0.0216407 -5.0249 2.0125 2.1439 0.73892 2.0125
6     6 0.95873 -0.0367555 -4.7715 1.9972 2.1434 0.77781 1.9972
7     7 0.95944 -0.0249644 -4.5656 1.9804 2.1369 0.80265 1.9804
8     8 0.96102 -0.0236016 -4.5126 1.9423 2.1109 0.82659 1.9423
9     9 0.96102 -0.0279639 -4.6421 1.9414 2.1234 0.86014 1.9414
10   10 0.96189 -0.0382749 -4.5822 1.9200 2.1119 0.87962 1.9200
> 
> 
> 
> cleanEx()
> nameEx("densityplot.residLen")
> ### * densityplot.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: densityplot.residLen
> ### Title: Lattice density plot for residual lengths
> ### Aliases: densityplot.residLen densityplot
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                50%  75%  90%  95%  99%
Training Set: 0.854 1.56 2.45 2.61 3.72
Passive:      1.004 1.50 1.87 2.17 2.55
> 
> ## plot the density functions of the residual distances
> densityplot(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("dissimilarities")
> ### * dissimilarities
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dissimilarities
> ### Title: Extract dissimilarity coefficients from models
> ### Aliases: dissimilarities dissimilarities.analog dissimilarities.mat
> ###   dissim
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAPImbrie & Kipp and V12.122 core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.910 0.908 0.910 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.909 0.911 0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.906 0.909 0.910 0.907 0.907 0.912 0.910 0.911 0.907 0.908 0.908 0.910 0.908 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.910 0.907 0.911 0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906 0.911 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.907 0.910 0.910 0.910 0.907 0.907 0.906 0.904 0.906 0.910 0.913 0.906 0.907 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.906 0.910 0.911 0.913 0.907 0.909 0.909 0.912 0.914 0.908 0.907 0.909 0.911 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.914 0.907 0.907 0.908 0.908 0.906 0.907 0.910 0.910 0.910 0.909 0.913 0.912 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.908 0.909 0.909 0.907 0.910 0.909 0.908 0.907 0.911 0.908 0.913 0.910 0.910 
 1040  1050  1060  1070  1080  1090 
0.912 0.906 0.910 0.910 0.908 0.907 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    A180.76   V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   V14.5     V12.79    V22.204   V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V16.21    V15.164   V20.167 
   7  V15.164   V20.230   V20.230   A180.72   V20.234   V20.234   V22.219 
   8  V16.21    V20.167   V14.90    V22.204   V20.230   A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V14.90    V20.230   V12.18  
  10  V20.230   V20.7     V20.167   V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V22.204   V14.90    V19.216   V14.90  
  V16.21    V20.167   V22.204   V9.31     V20.230   V22.172   V19.216 
  V14.90    V16.21    V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    A153.154  V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   V14.90    V14.90    V12.79    V20.167   V12.79  
  V20.167   A179.13   V9.31     V16.21    V22.172   A153.154  V22.204 
  V20.234   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V22.204   V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V9.31     V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V14.90  
  V20.230   V20.167   V10.89    V20.230   V14.90    V14.90    V22.172 
  V20.234   V19.216   V19.216   V16.21    V20.230   V9.31     V9.31   
  V14.90    V16.21    V9.31     V22.172   V10.89    V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V16.21    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V12.79  
  A180.72   V15.164   V16.33    V9.31     V15.164   V20.234   V16.21  
  V16.21    V20.230   V22.172   V22.219   V19.216   V3.128    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V20.167   V20.230   V14.90    V12.122   V22.172   V22.172   A180.72 
  V3.128    V18.21    V14.5     V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   A180.76   V18.21    V12.79    V12.122   V12.79  
  V20.230   V20.234   V20.234   V22.172   V12.122   A180.72   V22.204 
  V20.234   V14.5     V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   A180.72   V10.89    A180.76   V18.21  
  A180.76   A180.76   V15.164   V14.5     V15.164   V20.230   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V10.89  
  V12.122   A180.72   V19.216   V14.90    V22.172   V14.90    V22.172 
  V22.204   V14.5     V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V20.230   V14.90    A180.39   V19.308 
  V14.5     V3.128    V20.230   V16.190   V16.21    V16.190   V16.21  
  V20.234   V22.172   A179.13   V16.21    V10.89    V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V20.167   V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V9.31     V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   A180.76   V20.230 
  V14.90    V14.90    V22.204   V20.230   V14.90    V20.230   V14.90  
  V16.21    V20.234   V12.122   A180.76   V9.31     A180.72   V9.31   
  V22.172   V15.164   V20.234   V3.128    V20.234   V22.172   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V15.164   V22.204   V20.167   V19.216   V20.234 
  V15.164   V20.230   V16.33    V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V20.167   V14.90  
  V20.234   V9.31     V14.90    V18.21    V3.128    V22.172   A180.76 
  V14.90    V14.90    V20.234   V20.234   V14.5     V20.234   V22.204 
  V20.230   V20.234   V20.230   A180.72   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   V12.122   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   V20.230   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   A180.76   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V3.128  
  A180.76   V22.172   V19.216   V14.90    V15.164   V19.216   A180.78 
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  A180.72   V20.230   V20.234   V3.128    V10.89    V19.216   V22.172 
  V12.122   V18.21    V20.230   V19.216   V16.21    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.72   V12.122   V22.172   V12.79  
  V14.90    V14.5     V19.216   A180.78   V15.164   V16.21    V9.31   
  V14.5     V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V20.167   V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V22.204   V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V12.79    V22.172   A180.72   V14.90    V20.167 
  A180.76   A180.78   V14.90    V15.164   A180.76   V22.204   V19.216 
  V9.31     V14.90    A180.72   V16.21    V22.204   V12.122   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V3.128    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V12.79    V20.230 
  V22.204   V20.234   V20.234   V14.90    V20.230   A180.72   V16.33  
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  A180.72   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  V12.122   V14.5     V22.172   V22.172   A180.72   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     V22.172   V9.31     V22.172 
  V20.230   A180.72   V20.167   V3.128    V20.230   V22.204   V22.204 
  V20.234   V3.128    V14.5     V16.33    V12.122   V16.190   V22.219 
  V22.172   V18.21    A180.76   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   V15.164   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V12.122   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V22.172   V12.79    A180.72 
  V19.216   V20.234   V3.128    V20.230   V20.234   V22.172   V3.128  
  V16.21    V12.122   V10.89    V20.167   V20.230   V20.230   V20.167 
  V10.89    V20.230   V19.216   V12.122   V12.79    V12.122   V12.122 
  V15.164   V22.172   V20.167   V19.216   V20.167   V9.31     V20.230 
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V9.31   
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V22.204   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V19.216   V20.167 
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V16.33  
  V14.90    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V16.21    V22.172   A180.72   V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   V3.128    A180.72   V12.79    A180.72   V12.122 
  A180.76   A180.72   A180.76   V14.90    V14.5     V20.167   V16.190 
  V9.31     V20.230   V20.234   V12.79    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V16.21    A180.72   A180.76   V10.89  
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V19.216   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V22.172   V9.31     V19.222   V9.31   
  V22.204   V19.216   V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V9.31     V20.167   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V19.216   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V20.230 
  A180.72   V20.230   V15.164   V10.89    V12.79    V22.172   V16.190 
  V9.31     A180.76   V12.18    V20.230   V20.167   V12.79    A180.39 
  V14.90    A180.72   V9.31     V16.21    A180.72   V9.31     V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V14.90    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V16.21    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V20.230   V12.79    V22.172 
  V19.222   V22.204   V22.172   V14.90    V12.122   V22.172   A180.76 
  V12.79    V22.172   V14.90    V22.172   V9.31     V16.21    V19.216 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V20.167   V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V12.79    A180.72   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   V20.234   A179.13   A180.72   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  A180.76   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  V22.172   V22.204   V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V12.79    V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.204   V19.216   V19.216   V12.122   V22.204 
  V14.90    V14.90    V22.172   V22.172   V14.90  
  V22.172   V12.122   V22.204   V14.90    V19.216 
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V20.234 
  V16.33    V20.234   V22.219   V20.230   V9.31   
  V16.190   A180.78   V9.31     V20.234   A180.72 

Dissimilarities for k-closest analogues

   k      0     10     20     30     40     50     60     70     80     90
   1  0.900  0.902  0.903  0.904  0.904  0.907  0.907  0.908  0.908  0.908
   2  0.903  0.904  0.904  0.904  0.905  0.908  0.908  0.909  0.908  0.910
   3  0.903  0.904  0.906  0.904  0.906  0.908  0.909  0.910  0.909  0.913
   4  0.903  0.906  0.906  0.905  0.906  0.909  0.910  0.910  0.909  0.913
   5  0.905  0.906  0.906  0.905  0.908  0.909  0.910  0.910  0.909  0.914
   6  0.905  0.907  0.906  0.905  0.908  0.909  0.910  0.911  0.910  0.914
   7  0.907  0.907  0.907  0.906  0.908  0.911  0.910  0.911  0.910  0.914
   8  0.907  0.908  0.907  0.906  0.908  0.911  0.911  0.911  0.910  0.914
   9  0.907  0.909  0.907  0.906  0.908  0.911  0.911  0.911  0.911  0.915
  10  0.908  0.910  0.907  0.906  0.908  0.912  0.911  0.911  0.911  0.915
    100    110    120    130    140    150    160    170    180    190    200
  0.910  0.908  0.910  0.909  0.911  0.908  0.908  0.906  0.908  0.909  0.906
  0.911  0.910  0.910  0.909  0.911  0.909  0.910  0.907  0.910  0.910  0.908
  0.911  0.912  0.911  0.910  0.912  0.909  0.910  0.907  0.910  0.910  0.908
  0.912  0.913  0.911  0.911  0.912  0.910  0.910  0.907  0.911  0.910  0.908
  0.913  0.914  0.912  0.911  0.914  0.910  0.910  0.907  0.911  0.912  0.908
  0.913  0.914  0.914  0.913  0.914  0.910  0.910  0.908  0.911  0.912  0.909
  0.913  0.914  0.914  0.913  0.915  0.911  0.910  0.908  0.911  0.912  0.909
  0.913  0.915  0.914  0.914  0.915  0.911  0.910  0.908  0.912  0.913  0.910
  0.914  0.915  0.915  0.914  0.915  0.911  0.911  0.909  0.913  0.914  0.910
  0.914  0.915  0.915  0.914  0.915  0.912  0.911  0.910  0.914  0.914  0.910
    210    220    230    240    250    260    270    280    290    300    310
  0.907  0.906  0.906  0.906  0.906  0.906  0.909  0.910  0.907  0.907  0.912
  0.908  0.909  0.908  0.910  0.908  0.908  0.910  0.911  0.908  0.908  0.913
  0.908  0.909  0.908  0.911  0.909  0.908  0.911  0.911  0.909  0.908  0.913
  0.908  0.909  0.908  0.911  0.910  0.908  0.912  0.911  0.909  0.909  0.914
  0.909  0.909  0.909  0.911  0.910  0.908  0.912  0.912  0.910  0.909  0.915
  0.910  0.909  0.909  0.912  0.911  0.909  0.912  0.912  0.910  0.909  0.916
  0.910  0.909  0.910  0.912  0.911  0.909  0.913  0.912  0.910  0.909  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.912  0.911  0.910  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.913  0.912  0.910  0.916
  0.910  0.910  0.911  0.913  0.911  0.910  0.914  0.914  0.912  0.910  0.917
    320    330    340    350    360    370    380    390    400    410    420
  0.910  0.911  0.907  0.908  0.908  0.910  0.908  0.910  0.907  0.911  0.906
  0.911  0.911  0.908  0.909  0.909  0.910  0.909  0.910  0.907  0.911  0.907
  0.911  0.911  0.908  0.909  0.909  0.911  0.909  0.912  0.909  0.912  0.907
  0.912  0.911  0.909  0.910  0.909  0.912  0.909  0.912  0.910  0.912  0.907
  0.912  0.912  0.909  0.910  0.909  0.912  0.910  0.912  0.910  0.912  0.908
  0.912  0.912  0.910  0.910  0.909  0.912  0.911  0.912  0.910  0.912  0.908
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.910  0.913  0.909
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.914  0.909
    430    440    450    460    470    480    490    500    510    520    530
  0.909  0.905  0.906  0.907  0.906  0.909  0.907  0.906  0.911  0.907  0.910
  0.911  0.908  0.907  0.907  0.906  0.909  0.907  0.907  0.912  0.910  0.911
  0.911  0.909  0.907  0.909  0.907  0.909  0.908  0.908  0.912  0.910  0.911
  0.911  0.909  0.908  0.910  0.907  0.910  0.908  0.908  0.913  0.911  0.911
  0.911  0.910  0.908  0.911  0.907  0.910  0.908  0.908  0.914  0.911  0.911
  0.912  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.911
  0.913  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.912
  0.913  0.911  0.909  0.912  0.907  0.911  0.909  0.910  0.915  0.912  0.912
  0.913  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
  0.914  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
    540    550    560    570    580    590    600    610    620    630    640
  0.910  0.910  0.907  0.907  0.906  0.904  0.906  0.910  0.913  0.906  0.907
  0.911  0.910  0.908  0.907  0.907  0.907  0.908  0.911  0.913  0.910  0.908
  0.911  0.911  0.910  0.909  0.907  0.907  0.908  0.911  0.914  0.910  0.909
  0.911  0.911  0.910  0.909  0.907  0.907  0.909  0.911  0.914  0.910  0.909
  0.912  0.911  0.910  0.909  0.908  0.907  0.910  0.911  0.915  0.910  0.909
  0.912  0.912  0.911  0.909  0.908  0.907  0.910  0.912  0.915  0.910  0.909
  0.913  0.913  0.911  0.910  0.910  0.907  0.910  0.913  0.915  0.911  0.910
  0.913  0.914  0.912  0.910  0.910  0.908  0.911  0.913  0.916  0.911  0.910
  0.913  0.914  0.912  0.910  0.911  0.908  0.911  0.913  0.916  0.912  0.910
  0.914  0.914  0.913  0.911  0.911  0.908  0.911  0.914  0.916  0.912  0.910
    650    660    670    680    690    700    710    720    730    740    750
  0.906  0.910  0.911  0.913  0.907  0.909  0.909  0.912  0.914  0.908  0.907
  0.907  0.910  0.911  0.913  0.909  0.909  0.911  0.913  0.914  0.909  0.909
  0.909  0.910  0.912  0.914  0.909  0.910  0.911  0.914  0.915  0.910  0.909
  0.909  0.910  0.912  0.916  0.909  0.911  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.910  0.912  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.914  0.913  0.913  0.915  0.915  0.910  0.910
  0.910  0.911  0.913  0.917  0.914  0.913  0.913  0.915  0.916  0.911  0.910
  0.911  0.912  0.913  0.918  0.914  0.913  0.913  0.916  0.916  0.911  0.911
  0.911  0.912  0.914  0.918  0.914  0.913  0.913  0.916  0.917  0.911  0.911
  0.911  0.913  0.914  0.919  0.915  0.913  0.914  0.916  0.917  0.911  0.911
    760    770    780    790    800    810    820    830    840    850    860
  0.909  0.911  0.914  0.907  0.907  0.908  0.908  0.906  0.907  0.910  0.910
  0.910  0.911  0.914  0.908  0.908  0.908  0.910  0.910  0.909  0.911  0.911
  0.910  0.913  0.917  0.910  0.909  0.909  0.910  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.910  0.910  0.909  0.911  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.911  0.910  0.909  0.912  0.911  0.912  0.912  0.912
  0.910  0.913  0.918  0.911  0.911  0.909  0.912  0.912  0.912  0.912  0.912
  0.911  0.914  0.918  0.911  0.911  0.909  0.913  0.912  0.913  0.913  0.913
  0.911  0.914  0.919  0.911  0.911  0.910  0.913  0.913  0.913  0.913  0.914
  0.912  0.914  0.919  0.911  0.912  0.910  0.914  0.913  0.914  0.913  0.914
  0.912  0.914  0.919  0.912  0.912  0.910  0.914  0.913  0.914  0.913  0.915
    870    880    890    900    910    920    930    940    950    960    970
  0.910  0.909  0.913  0.912  0.908  0.909  0.909  0.907  0.910  0.909  0.908
  0.910  0.912  0.914  0.915  0.912  0.913  0.910  0.908  0.910  0.910  0.908
  0.910  0.912  0.914  0.916  0.912  0.915  0.912  0.909  0.911  0.910  0.909
  0.911  0.913  0.915  0.916  0.913  0.916  0.913  0.909  0.911  0.911  0.909
  0.912  0.913  0.915  0.917  0.913  0.917  0.914  0.909  0.911  0.911  0.909
  0.913  0.913  0.915  0.918  0.913  0.917  0.915  0.910  0.911  0.911  0.909
  0.913  0.914  0.917  0.918  0.914  0.917  0.915  0.911  0.911  0.911  0.909
  0.913  0.914  0.918  0.918  0.914  0.917  0.915  0.911  0.912  0.911  0.910
  0.915  0.914  0.918  0.919  0.915  0.918  0.915  0.912  0.912  0.912  0.910
  0.915  0.915  0.918  0.920  0.915  0.918  0.916  0.912  0.913  0.912  0.910
    980    990   1000   1010   1020   1030   1040   1050   1060   1070   1080
  0.907  0.911  0.908  0.913  0.910  0.910  0.912  0.906  0.910  0.910  0.908
  0.909  0.912  0.908  0.913  0.914  0.911  0.914  0.909  0.911  0.910  0.908
  0.909  0.912  0.909  0.914  0.914  0.911  0.916  0.909  0.914  0.911  0.909
  0.911  0.912  0.909  0.915  0.915  0.912  0.917  0.909  0.915  0.911  0.909
  0.911  0.913  0.909  0.915  0.915  0.912  0.917  0.911  0.915  0.912  0.910
  0.912  0.914  0.910  0.916  0.916  0.914  0.917  0.912  0.915  0.913  0.911
  0.912  0.914  0.912  0.916  0.916  0.915  0.917  0.912  0.916  0.913  0.911
  0.912  0.915  0.912  0.917  0.917  0.916  0.918  0.912  0.916  0.914  0.911
  0.912  0.915  0.912  0.918  0.918  0.916  0.918  0.913  0.917  0.914  0.911
  0.913  0.915  0.913  0.918  0.918  0.916  0.918  0.913  0.917  0.915  0.911
   1090
  0.907
  0.908
  0.908
  0.908
  0.910
  0.910
  0.911
  0.911
  0.911
  0.911

> 
> ## compare training set dissimilarities with normals
> ## and derive cut-offs
> ik.dij <- dissim(ik.analog)
> plot(ik.dij)
> 
> 
> 
> 
> cleanEx()
> nameEx("distance")
> ### * distance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: distance
> ### Title: Flexibly calculate dissimilarity or distance measures
> ### Aliases: distance distance.default distance.join oldDistance
> ###   oldDistance.default oldDistance.join
> ### Keywords: multivariate methods
> 
> ### ** Examples
> 
> ## simple example using dummy data
> train <- data.frame(matrix(abs(runif(200)), ncol = 10))
> rownames(train) <- LETTERS[1:20]
> colnames(train) <- as.character(1:10)
> fossil <- data.frame(matrix(abs(runif(100)), ncol = 10))
> colnames(fossil) <- as.character(1:10)
> rownames(fossil) <- letters[1:10]
> 
> ## calculate distances/dissimilarities between train and fossil
> ## samples
> test <- distance(train, fossil)
> 
> ## using a different coefficient, chi-square distance
> test <- distance(train, fossil, method = "chi.distance")
> 
> ## calculate pairwise distances/dissimilarities for training
> ## set samples
> test2 <- distance(train)
> 
> ## Using distance on an object of class join
> dists <- distance(join(train, fossil))
> str(dists)
 distance [1:20, 1:10] 1.16 1.45 1.17 1.43 1.59 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:20] "A" "B" "C" "D" ...
  ..$ : chr [1:10] "a" "b" "c" "d" ...
 - attr(*, "method")= chr "euclidean"
 - attr(*, "class")= chr [1:2] "distance" "matrix"
 - attr(*, "type")= chr "asymmetric"
> 
> ## calculate Gower's general coefficient for mixed data
> ## first, make a couple of variables factors
> 
> fossil[,4] <- factor(sample(rep(1:4, length = 10), 10))
> train[,4] <- factor(sample(rep(1:4, length = 20), 20))
> ## now fit the mixed coefficient
> test3 <- distance(train, fossil, "mixed")
> 
> ## Example from page 260 of Legendre & Legendre (1998)
> x1 <- t(c(2,2,NA,2,2,4,2,6))
> x2 <- t(c(1,3,3,1,2,2,2,5))
> Rj <- c(1,4,2,4,1,3,2,5) # supplied ranges
> 
> 1 - distance(x1, x2, method = "mixed", R = Rj)
          [,1]
[1,] 0.6619048
attr(,"method")
[1] "mixed"
attr(,"class")
[1] "distance" "matrix"  
attr(,"type")
[1] "asymmetric"
> 
> ## note this gives ~0.66 as Legendre & Legendre describe the
> ## coefficient as a similarity coefficient. Hence here we do
> ## 1 - Dij here to get the same answer. 
> 
> 
> 
> cleanEx()
> nameEx("evenlySampled")
> ### * evenlySampled
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: evenSample
> ### Title: Number of samples per gradient segments
> ### Aliases: evenSample
> ### Keywords: utilities
> 
> ### ** Examples
> 
> data(SumSST)
> ev <- evenSample(SumSST) ## not an even sample...
> plot(ev)
> 
> 
> 
> cleanEx()
> nameEx("fuse")
> ### * fuse
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fuse
> ### Title: Fused dissimilarities
> ### Aliases: fuse fuse.matrix fuse.dist
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> train1 <- data.frame(matrix(abs(runif(100)), ncol = 10))
> train2 <- data.frame(matrix(sample(c(0,1), 100, replace = TRUE),
+                      ncol = 10))
> rownames(train1) <- rownames(train2) <- LETTERS[1:10]
> colnames(train1) <- colnames(train2) <- as.character(1:10)
> 
> d1 <- vegdist(train1, method = "bray")
> d2 <- vegdist(train2, method = "jaccard")
> 
> dd <- fuse(d1, d2, weights = c(0.6, 0.4))
> dd
          A         B         C         D         E         F         G
B 0.6574699                                                            
C 0.7678571 0.8463106                                                  
D 0.8335390 0.9301081 0.7700357                                        
E 0.6349894 0.7438099 0.7062610 0.6380231                              
F 0.7778098 0.8058696 0.6951139 0.6341402 0.7489699                    
G 0.7000000 0.7026529 0.6907921 0.7786377 0.5990220 0.7094210          
H 0.6632811 0.8960981 0.5972781 0.6418683 0.7107027 0.6199487 0.7337576
I 0.7185972 0.7498738 0.5217183 0.5311071 0.6236645 0.5930525 0.7349763
J 0.4682803 0.7718535 0.7022256 0.7009347 0.5463553 0.6132729 0.5951744
          H         I
B                    
C                    
D                    
E                    
F                    
G                    
H                    
I 0.7077601          
J 0.4566551 0.6414854
> str(dd)
Class 'dist'  atomic [1:45] 0.657 0.768 0.834 0.635 0.778 ...
  ..- attr(*, "Labels")= chr [1:10] "A" "B" "C" "D" ...
  ..- attr(*, "Size")= int 10
  ..- attr(*, "Diag")= logi FALSE
  ..- attr(*, "Upper")= logi FALSE
  ..- attr(*, "method")= chr "fuse"
  ..- attr(*, "weights")= num [1:2] 0.6 0.4
  ..- attr(*, "call")= language fuse.dist(d1, d2, weights = c(0.6, 0.4))
> 
> 
> 
> cleanEx()
> nameEx("getK")
> ### * getK
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: getK
> ### Title: Extract and set the number of analogues
> ### Aliases: getK getK.default getK.mat getK.bootstrap.mat getK.predict.mat
> ###   setK<- setK<-.default setK<-.mat
> ### Keywords: utilities manip
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit a MAT model
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> 
> ## How many analogues gives lowest RMSE?
> getK(ik.mat)
[1] 3
attr(,"auto")
[1] TRUE
attr(,"weighted")
[1] FALSE
> ## note that this value was chosen automatically
> 
> ## Now set k to be 10
> setK(ik.mat) <- 10
> 
> ## check
> getK(ik.mat)
[1] 10
attr(,"auto")
[1] FALSE
attr(,"weighted")
[1] FALSE
> 
> 
> 
> 
> cleanEx()
> nameEx("gradientDist")
> ### * gradientDist
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: gradientDist
> ### Title: Positions of samples along a unit-length ordination gradient.
> ### Aliases: gradientDist gradientDist.default gradientDist.cca
> ###   gradientDist.prcurve
> ### Keywords: multivariate utility
> 
> ### ** Examples
> 
> 
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit PCA
> aber.pca <- rda(abernethy2)
> 
> ## Distance along the first PCA axis
> gradientDist(aber.pca)
 [1] 0.34172583 0.30240442 0.11451277 0.16889765 0.00000000 0.07556094
 [7] 0.15850388 0.15179676 0.34544036 0.33863684 0.37796456 0.35447305
[13] 0.37725714 0.43590145 0.52614525 0.83212029 0.91442163 0.94000421
[19] 0.94470578 0.95980762 0.96907601 0.96296241 0.99047280 0.98153216
[25] 0.96405261 1.00000000 0.97592084 0.95435245 0.97401520 0.91746396
[31] 0.94109965 0.88969437 0.80369973 0.75290552 0.71033293 0.72969928
[37] 0.71642084 0.75419351 0.74347844 0.77265593 0.75973303 0.81801884
[43] 0.86196277 0.82424335 0.81704433 0.74625922 0.73571176 0.69173333
[49] 0.71982710
attr(,"class")
[1] "gradientDist"
> 
> 
> 
> cleanEx()
> nameEx("hist.residLen")
> ### * hist.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: hist.residLen
> ### Title: Histogram plot for residual lengths
> ### Aliases: hist.residLen
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                50%  75%  90%  95%  99%
Training Set: 0.854 1.56 2.45 2.61 3.72
Passive:      1.004 1.50 1.87 2.17 2.55
> 
> ## plot a histogram of the residual distances
> hist(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("histogram.residLen")
> ### * histogram.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: histogram.residLen
> ### Title: Lattice histogram plot for residual lengths
> ### Aliases: histogram.residLen histogram
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                50%  75%  90%  95%  99%
Training Set: 0.854 1.56 2.45 2.61 3.72
Passive:      1.004 1.50 1.87 2.17 2.55
> 
> ## plot a histogram of the residual distances
> histogram(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("join")
> ### * join
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: join
> ### Title: Merge species data sets on common columns (species)
> ### Aliases: join head.join tail.join
> ### Keywords: multivariate manip
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## merge training and test set using left join
> head(join(swapdiat, rlgh, verbose = TRUE, type = "left"))

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  277
Merged:      268  277

$swapdiat
       AC001A AC002A AC004A AC013A AC014A AC014B AC014C AC017A AC018A AC019A
1.21        0      0      0 0.0019      0      0 0.0057 0.0096      0 0.0000
10.21       0      0      0 0.0406      0      0 0.0101 0.0000      0 0.0118
11          0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0000
113.21      0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0000
115.11      0      0      0 0.0000      0      0 0.0000 0.0000      0 0.0031
12.11       0      0      0 0.0000      0      0 0.0403 0.0000      0 0.0000
       AC022A AC025A AC028A AC029A AC030A AC034A AC035A AC039A AC042A AC044A
1.21   0.0631 0.0000      0 0.0000      0      0      0      0      0 0.0076
10.21  0.0000 0.0000      0 0.0017      0      0      0      0      0 0.0000
11     0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
113.21 0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
115.11 0.0000 0.0016      0 0.0000      0      0      0      0      0 0.0000
12.11  0.1194 0.0000      0 0.0000      0      0      0      0      0 0.0045
       AC046A AC048A AC9964 AC9965 AC9968 AC9969 AC9975 AC9996 AM001A AM001B
1.21        0      0      0      0      0      0      0      0 0.0000      0
10.21       0      0      0      0      0      0      0      0 0.0000      0
11          0      0      0      0      0      0      0      0 0.0000      0
113.21      0      0      0      0      0      0      0      0 0.0142      0
115.11      0      0      0      0      0      0      0      0 0.0000      0
12.11       0      0      0      0      0      0      0      0 0.0000      0
       AM001D AS001A AS003A AT001A AU001C AU002A AU003B AU003D AU004A AU004B
1.21        0      0 0.0019 0.0000      0      0      0      0 0.0000      0
10.21       0      0 0.0000 0.0000      0      0      0      0 0.0000      0
11          0      0 0.0000 0.0040      0      0      0      0 0.0000      0
113.21      0      0 0.0000 0.0000      0      0      0      0 0.0000      0
115.11      0      0 0.0000 0.0016      0      0      0      0 0.0313      0
12.11       0      0 0.0000 0.0000      0      0      0      0 0.0000      0
       AU004C AU004D AU005A AU005B AU005D AU005E AU005J AU005L AU009A AU009B
1.21        0      0 0.0000      0      0 0.0000      0      0      0      0
10.21       0      0 0.0000      0      0 0.0000      0      0      0      0
11          0      0 0.0000      0      0 0.0000      0      0      0      0
113.21      0      0 0.0000      0      0 0.0000      0      0      0      0
115.11      0      0 0.0016      0      0 0.0110      0      0      0      0
12.11       0      0 0.0298      0      0 0.0776      0      0      0      0
       AU010A AU010B AU014A AU022A AU023A AU9983 AU9984 AU9987 AU9988 BR001A
1.21        0      0      0      0      0      0      0      0      0 0.0115
10.21       0      0      0      0      0      0      0      0      0 0.2149
11          0      0      0      0      0      0      0      0      0 0.0020
113.21      0      0      0      0      0      0      0      0      0 0.2131
115.11      0      0      0      0      0      0      0      0      0 0.0579
12.11       0      0      0      0      0      0      0      0      0 0.0060
       BR003A BR004A BR005A BR006A BR9997 CA018A CC001A CM004A CM010A CM013A
1.21   0.0000 0.0019      0 0.0287  0.000      0      0 0.0000 0.0096      0
10.21  0.0000 0.0034      0 0.0846  0.000      0      0 0.0000 0.0085      0
11     0.0299 0.0140      0 0.0798  0.022      0      0 0.0000 0.0140      0
113.21 0.0000 0.0057      0 0.0000  0.000      0      0 0.0000 0.0426      0
115.11 0.0141 0.0078      0 0.0438  0.000      0      0 0.0047 0.0078      0
12.11  0.0015 0.0000      0 0.0254  0.000      0      0 0.0060 0.0000      0
       CM014A CM015A CM015B CM017A CM020A CM031A CM031C CM038A CM048A CM050A
1.21        0 0.0000      0 0.0019      0 0.0000 0.0000 0.0000 0.0000      0
10.21       0 0.0051      0 0.0051      0 0.0000 0.0101 0.0000 0.0000      0
11          0 0.0000      0 0.0120      0 0.0000 0.0000 0.0000 0.0000      0
113.21      0 0.0455      0 0.0028      0 0.0142 0.0000 0.0057 0.0057      0
115.11      0 0.0000      0 0.0016      0 0.0000 0.0000 0.0000 0.0329      0
12.11       0 0.0000      0 0.0119      0 0.0000 0.0239 0.0000 0.0060      0
       CM051A CM052A CM101B CM9989 CM9995 CO001A CO001B CY001A CY002A CY003A
1.21        0      0      0      0      0      0      0      0      0      0
10.21       0      0      0      0      0      0      0      0      0      0
11          0      0      0      0      0      0      0      0      0      0
113.21      0      0      0      0      0      0      0      0      0      0
115.11      0      0      0      0      0      0      0      0      0      0
12.11       0      0      0      0      0      0      0      0      0      0
       CY004A CY007A CY010A CY013A CY9991 DE001A DT002A DT003A DT004B EU002A
1.21        0      0      0      0 0.0000      0      0      0      0 0.0000
10.21       0      0      0      0 0.0778      0      0      0      0 0.0051
11          0      0      0      0 0.0000      0      0      0      0 0.0000
113.21      0      0      0      0 0.0000      0      0      0      0 0.0000
115.11      0      0      0      0 0.0391      0      0      0      0 0.0000
12.11       0      0      0      0 0.0493      0      0      0      0 0.0000
       EU002B EU002D EU002E EU002K EU003A EU004A EU009A EU009C EU011A EU013A
1.21   0.0153      0      0 0.0076 0.0019 0.0229 0.0325      0  0.000  0.000
10.21  0.0051      0      0 0.0000 0.0017 0.0220 0.0169      0  0.000  0.000
11     0.0000      0      0 0.0000 0.0000 0.0000 0.0080      0  0.018  0.000
113.21 0.0085      0      0 0.0000 0.0000 0.0142 0.0142      0  0.000  0.000
115.11 0.0047      0      0 0.0000 0.0000 0.0282 0.0078      0  0.000  0.000
12.11  0.0000      0      0 0.0000 0.0000 0.0000 0.0463      0  0.000  0.003
       EU014A EU015A EU016A EU017A EU019A EU020A EU021A EU022A EU025A EU027A
1.21    0.000 0.0019      0 0.0019  0.000 0.0057      0      0      0 0.0019
10.21   0.000 0.0000      0 0.0000  0.000 0.0085      0      0      0 0.0000
11      0.002 0.0000      0 0.0000  0.004 0.0020      0      0      0 0.0000
113.21  0.000 0.0000      0 0.0085  0.000 0.0142      0      0      0 0.0000
115.11  0.000 0.0047      0 0.0000  0.000 0.0219      0      0      0 0.0000
12.11   0.000 0.0000      0 0.0000  0.000 0.0104      0      0      0 0.0000
       EU028A EU028B EU031A EU034A EU039A EU040A EU046C EU047A EU048A EU049A
1.21   0.0306      0  0.000      0 0.0019      0      0 0.0880 0.0401 0.0000
10.21  0.0000      0  0.000      0 0.0000      0      0 0.0288 0.0068 0.0000
11     0.0000      0  0.002      0 0.0000      0      0 0.0120 0.0140 0.0000
113.21 0.0000      0  0.000      0 0.0000      0      0 0.0085 0.0000 0.0057
115.11 0.0000      0  0.000      0 0.0047      0      0 0.0250 0.0125 0.0000
12.11  0.0000      0  0.000      0 0.0179      0      0 0.0284 0.0627 0.0000
       EU049B EU051A EU051B EU056A EU057A EU058A EU9961 EU9962 EU9965 EU9969
1.21        0 0.0019      0      0  0.000      0      0      0      0      0
10.21       0 0.0017      0      0  0.000      0      0      0      0      0
11          0 0.0020      0      0  0.002      0      0      0      0      0
113.21      0 0.0085      0      0  0.000      0      0      0      0      0
115.11      0 0.0000      0      0  0.000      0      0      0      0      0
12.11       0 0.0000      0      0  0.000      0      0      0      0      0
       FR001A FR001B FR002A FR002C FR005A FR005D FR006A FR007A FR008A FR009F
1.21        0      0      0      0      0 0.0057      0      0      0      0
10.21       0      0      0      0      0 0.0457      0      0      0      0
11          0      0      0      0      0 0.0000      0      0      0      0
113.21      0      0      0      0      0 0.0114      0      0      0      0
115.11      0      0      0      0      0 0.0031      0      0      0      0
12.11       0      0      0      0      0 0.0000      0      0      0      0
       FR010A FR011A FR015A FR018A FR9991 FU002A FU002B FU002F GO003A GO004A
1.21        0      0 0.0076      0 0.0038 0.0076 0.0535      0 0.0000 0.0000
10.21       0      0 0.0000      0 0.0000 0.0271 0.1049      0 0.0000 0.0051
11          0      0 0.0000      0 0.0000 0.0938 0.3253      0 0.0000 0.0000
113.21      0      0 0.0000      0 0.0000 0.0085 0.0625      0 0.0057 0.0000
115.11      0      0 0.0000      0 0.0000 0.0689 0.1878      0 0.0000 0.0000
12.11       0      0 0.0000      0 0.0000 0.0060 0.0597      0 0.0000 0.0000
       GO006C GO013A GO023A GO025B GO025F GY005A HN001A ME019A NA002A NA003A
1.21        0 0.0019      0      0      0      0      0      0      0  0.000
10.21       0 0.0000      0      0      0      0      0      0      0  0.044
11          0 0.0000      0      0      0      0      0      0      0  0.000
113.21      0 0.0000      0      0      0      0      0      0      0  0.000
115.11      0 0.0000      0      0      0      0      0      0      0  0.000
12.11       0 0.0000      0      0      0      0      0      0      0  0.000
       NA003B NA005A NA005B NA006A NA006B NA007A NA008A NA013A NA014A NA015A
1.21        0      0      0 0.0096      0      0      0      0 0.0000      0
10.21       0      0      0 0.0000      0      0      0      0 0.0000      0
11          0      0      0 0.0160      0      0      0      0 0.0000      0
113.21      0      0      0 0.0085      0      0      0      0 0.0000      0
115.11      0      0      0 0.0031      0      0      0      0 0.0016      0
12.11       0      0      0 0.0060      0      0      0      0 0.0000      0
       NA016A NA032A NA033A NA037A NA038A NA042A NA043A NA044A NA045A NA046A
1.21        0 0.0000 0.0019      0 0.0076 0.0000      0 0.0000      0      0
10.21       0 0.0000 0.0000      0 0.0000 0.0000      0 0.0034      0      0
11          0 0.0000 0.0220      0 0.0000 0.0000      0 0.0000      0      0
113.21      0 0.0171 0.0000      0 0.0000 0.0341      0 0.0000      0      0
115.11      0 0.0063 0.0000      0 0.0000 0.0000      0 0.0016      0      0
12.11       0 0.0000 0.0000      0 0.0000 0.0000      0 0.0701      0      0
       NA048A NA063A NA068A NA084A NA086A NA099A NA101A NA102A NA112D NA113A
1.21   0.0019      0      0      0      0  0.000      0      0      0      0
10.21  0.0000      0      0      0      0  0.000      0      0      0      0
11     0.0000      0      0      0      0  0.004      0      0      0      0
113.21 0.0000      0      0      0      0  0.000      0      0      0      0
115.11 0.0000      0      0      0      0  0.000      0      0      0      0
12.11  0.0000      0      0      0      0  0.000      0      0      0      0
       NA114A NA115A NA129A NA133A NA135A NA140A NA149A NA151A NA156A NA158A
1.21        0      0      0      0 0.0000 0.0153      0      0 0.0994      0
10.21       0      0      0      0 0.0051 0.0000      0      0 0.0000      0
11          0      0      0      0 0.0000 0.0120      0      0 0.0439      0
113.21      0      0      0      0 0.0000 0.0000      0      0 0.0142      0
115.11      0      0      0      0 0.0000 0.0000      0      0 0.0203      0
12.11       0      0      0      0 0.0000 0.0000      0      0 0.0015      0
       NA160A NA167A NA170A NA9904 NA9919 NA9955 NA9963 NA9964 NE003A NE003B
1.21   0.0000 0.0153      0      0      0      0      0      0 0.0000 0.0038
10.21  0.0017 0.0338      0      0      0      0      0      0 0.0051 0.0000
11     0.0000 0.0479      0      0      0      0      0      0 0.0080 0.0000
113.21 0.0000 0.0341      0      0      0      0      0      0 0.0028 0.0000
115.11 0.0000 0.0297      0      0      0      0      0      0 0.0016 0.0000
12.11  0.0000 0.0000      0      0      0      0      0      0 0.0000 0.0000
       NE003C NE004A NE012A NE020A NE023A NI002A NI005A NI008A NI009A NI009B
1.21        0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0000 0.0000
10.21       0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0068 0.0000
11          0 0.0000      0 0.0000      0 0.0000      0 0.0000 0.0000 0.0000
113.21      0 0.0028      0 0.0028      0 0.0114      0 0.0028 0.0227 0.0171
115.11      0 0.0000      0 0.0000      0 0.0000      0 0.0031 0.0000 0.0125
12.11       0 0.0000      0 0.0090      0 0.0000      0 0.0000 0.0030 0.0000
       NI017A NI021A NI026A NI027A NI152A NI9984 OP001A PE002A PI005A PI007A
1.21   0.0000 0.0000      0 0.0000 0.0000      0      0 0.0038 0.0000      0
10.21  0.0017 0.0000      0 0.0000 0.0101      0      0 0.0152 0.0000      0
11     0.0000 0.0000      0 0.0000 0.0000      0      0 0.0040 0.0000      0
113.21 0.0000 0.0171      0 0.0114 0.0000      0      0 0.0000 0.0000      0
115.11 0.0000 0.0047      0 0.0000 0.0000      0      0 0.0000 0.0047      0
12.11  0.0000 0.0000      0 0.0000 0.0000      0      0 0.0119 0.0000      0
       PI011A PI014A PI015A PI016A PI018A PI018B PI022B PI023A PI055A PI056A
1.21   0.0000 0.0000 0.0000      0 0.0019      0 0.0057      0      0  0.000
10.21  0.0000 0.0000 0.0000      0 0.0118      0 0.0000      0      0  0.000
11     0.0020 0.0000 0.0020      0 0.0080      0 0.0000      0      0  0.006
113.21 0.0000 0.0284 0.0000      0 0.0000      0 0.0000      0      0  0.000
115.11 0.0078 0.0000 0.0078      0 0.0000      0 0.0000      0      0  0.000
12.11  0.0000 0.0000 0.0045      0 0.0119      0 0.0239      0      0  0.000
       PI139A PI164A RH006B SA001A SA001B SA006A SA042A SE001A SP002A ST004A
1.21        0 0.0115      0 0.0000      0      0 0.0000 0.0344 0.0000      0
10.21       0 0.0000      0 0.0000      0      0 0.0000 0.0000 0.0000      0
11          0 0.0000      0 0.0000      0      0 0.0000 0.0299 0.0040      0
113.21      0 0.0114      0 0.0028      0      0 0.0000 0.0000 0.0000      0
115.11      0 0.0000      0 0.0016      0      0 0.0047 0.0094 0.0016      0
12.11       0 0.0000      0 0.0000      0      0 0.0015 0.0015 0.0000      0
       ST010A SU002A SU004A SU005A SU006A SY002A SY003A SY004A SY009A SY010A
1.21        0      0      0 0.0019 0.0038      0      0      0 0.0000 0.0000
10.21       0      0      0 0.0068 0.0051      0      0      0 0.0017 0.0000
11          0      0      0 0.0000 0.0040      0      0      0 0.0000 0.0000
113.21      0      0      0 0.0000 0.0000      0      0      0 0.0000 0.0028
115.11      0      0      0 0.0016 0.0047      0      0      0 0.0000 0.0000
12.11       0      0      0 0.0030 0.0075      0      0      0 0.0000 0.0000
       SY013A SY043A TA001A TA002A TA003A TA004A TA9996
1.21        0 0.0000 0.0096      0 0.1128 0.0249      0
10.21       0 0.0068 0.0372      0 0.0000 0.0034      0
11          0 0.0000 0.0140      0 0.0080 0.0419      0
113.21      0 0.0000 0.0739      0 0.0000 0.0000      0
115.11      0 0.0000 0.0266      0 0.0000 0.0000      0
12.11       0 0.0000 0.0239      0 0.0015 0.0000      0

$rlgh
      AC001A AC002A AC004A AC013A AC014A AC014B AC014C AC017A AC018A AC019A
000.3      0      0 0.0000 0.0086 0.0017      0      0      0      0      0
000.8      0      0 0.0038 0.0038 0.0000      0      0      0      0      0
001.3      0      0 0.0000 0.0055 0.0055      0      0      0      0      0
001.8      0      0 0.0000 0.0018 0.0036      0      0      0      0      0
002.3      0      0 0.0037 0.0000 0.0019      0      0      0      0      0
002.8      0      0 0.0000 0.0091 0.0000      0      0      0      0      0
      AC022A AC025A AC028A AC029A AC030A AC034A AC035A AC039A AC042A AC044A
000.3 0.0189 0.0000      0      0      0      0      0      0      0      0
000.8 0.0250 0.0000      0      0      0      0      0      0      0      0
001.3 0.0148 0.0018      0      0      0      0      0      0      0      0
001.8 0.0089 0.0000      0      0      0      0      0      0      0      0
002.3 0.0318 0.0000      0      0      0      0      0      0      0      0
002.8 0.0145 0.0018      0      0      0      0      0      0      0      0
      AC046A AC048A AC9964 AC9965 AC9968 AC9969 AC9975 AC9996 AM001A AM001B
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      AM001D AS001A AS003A AT001A AU001C AU002A AU003B AU003D AU004A AU004B
000.3      0      0      0      0      0      0      0      0 0.0000      0
000.8      0      0      0      0      0      0      0      0 0.0000      0
001.3      0      0      0      0      0      0      0      0 0.0000      0
001.8      0      0      0      0      0      0      0      0 0.0053      0
002.3      0      0      0      0      0      0      0      0 0.0019      0
002.8      0      0      0      0      0      0      0      0 0.0018      0
      AU004C AU004D AU005A AU005B AU005D AU005E AU005J AU005L AU009A AU009B
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      AU010A AU010B AU014A AU022A AU023A AU9983 AU9984 AU9987 AU9988 BR001A
000.3 0.0154      0      0      0      0      0      0      0 0.0069 0.0274
000.8 0.0134      0      0      0      0      0      0      0 0.0000 0.0307
001.3 0.0074      0      0      0      0      0      0      0 0.0037 0.0203
001.8 0.0160      0      0      0      0      0      0      0 0.0018 0.0391
002.3 0.0037      0      0      0      0      0      0      0 0.0169 0.0262
002.8 0.0109      0      0      0      0      0      0      0 0.0000 0.0181
      BR003A BR004A BR005A BR006A BR9997 CA018A CC001A CM004A CM010A CM013A
000.3 0.0000      0      0 0.0515 0.0069      0      0 0.0034 0.0086      0
000.8 0.0038      0      0 0.0768 0.0019      0      0 0.0000 0.0096      0
001.3 0.0037      0      0 0.0425 0.0037      0      0 0.0000 0.0018      0
001.8 0.0018      0      0 0.0196 0.0000      0      0 0.0000 0.0018      0
002.3 0.0037      0      0 0.0356 0.0000      0      0 0.0000 0.0056      0
002.8 0.0036      0      0 0.0381 0.0000      0      0 0.0000 0.0054      0
      CM014A CM015A CM015B CM017A CM020A CM031A CM031C CM038A CM048A CM050A
000.3 0.0034      0      0 0.0034 0.0120      0      0      0 0.0000      0
000.8 0.0038      0      0 0.0058 0.0000      0      0      0 0.0038      0
001.3 0.0074      0      0 0.0185 0.0000      0      0      0 0.0037      0
001.8 0.0089      0      0 0.0036 0.0000      0      0      0 0.0107      0
002.3 0.0112      0      0 0.0000 0.0112      0      0      0 0.0094      0
002.8 0.0073      0      0 0.0000 0.0000      0      0      0 0.0036      0
      CM051A CM052A CM101B CM9989 CM9995 CO001A CO001B CY001A CY002A CY003A
000.3      0      0      0      0      0      0      0      0      0      0
000.8      0      0      0      0      0      0      0      0      0      0
001.3      0      0      0      0      0      0      0      0      0      0
001.8      0      0      0      0      0      0      0      0      0      0
002.3      0      0      0      0      0      0      0      0      0      0
002.8      0      0      0      0      0      0      0      0      0      0
      CY004A CY007A CY010A CY013A CY9991 DE001A DT002A DT003A DT004B EU002A
000.3      0      0      0      0 0.0069      0      0      0      0 0.0017
000.8      0      0      0      0 0.0000      0      0      0      0 0.0038
001.3      0      0      0      0 0.0000      0      0      0      0 0.0018
001.8      0      0      0      0 0.0018      0      0      0      0 0.0018
002.3      0      0      0      0 0.0000      0      0      0      0 0.0019
002.8      0      0      0      0 0.0018      0      0      0      0 0.0036
      EU002B EU002D EU002E EU002K EU003A EU004A EU009A EU009C EU011A EU013A
000.3 0.0429      0 0.0051 0.0000 0.0000 0.0154 0.0172      0 0.0000      0
000.8 0.0384      0 0.0019 0.0019 0.0019 0.0038 0.0134      0 0.0000      0
001.3 0.0444      0 0.0000 0.0037 0.0000 0.0111 0.0203      0 0.0018      0
001.8 0.0302      0 0.0053 0.0000 0.0018 0.0089 0.0125      0 0.0036      0
002.3 0.0243      0 0.0037 0.0019 0.0000 0.0094 0.0131      0 0.0037      0
002.8 0.0254      0 0.0018 0.0018 0.0000 0.0200 0.0109      0 0.0000      0
      EU014A EU015A EU016A EU017A EU019A EU020A EU021A EU022A EU025A EU027A
000.3 0.0034 0.0000 0.0017 0.0000 0.0000 0.0051 0.0000      0      0      0
000.8 0.0077 0.0096 0.0038 0.0000 0.0000 0.0000 0.0000      0      0      0
001.3 0.0055 0.0055 0.0000 0.0000 0.0000 0.0018 0.0000      0      0      0
001.8 0.0071 0.0018 0.0036 0.0000 0.0018 0.0000 0.0000      0      0      0
002.3 0.0019 0.0037 0.0019 0.0000 0.0000 0.0037 0.0000      0      0      0
002.8 0.0000 0.0127 0.0000 0.0018 0.0000 0.0000 0.0036      0      0      0
      EU028A EU028B EU031A EU034A EU039A EU040A EU046C EU047A EU048A EU049A
000.3      0      0      0      0      0      0      0 0.1235 0.0309 0.0051
000.8      0      0      0      0      0      0      0 0.1228 0.0307 0.0019
001.3      0      0      0      0      0      0      0 0.1128 0.0203 0.0018
001.8      0      0      0      0      0      0      0 0.1281 0.0374 0.0018
002.3      0      0      0      0      0      0      0 0.1236 0.0318 0.0000
002.8      0      0      0      0      0      0      0 0.1180 0.0635 0.0000
      EU049B EU051A EU051B EU056A EU057A EU058A EU9961 EU9962 EU9965 EU9969
000.3 0.0000 0.0000      0      0      0      0      0      0      0      0
000.8 0.0000 0.0000      0      0      0      0      0      0      0      0
001.3 0.0000 0.0018      0      0      0      0      0      0      0      0
001.8 0.0000 0.0018      0      0      0      0      0      0      0      0
002.3 0.0000 0.0019      0      0      0      0      0      0      0      0
002.8 0.0018 0.0073      0      0      0      0      0      0      0      0
      FR001A FR001B FR002A FR002C FR005A FR005D FR006A FR007A FR008A FR009F
000.3      0      0      0      0      0 0.0292      0      0      0      0
000.8      0      0      0      0      0 0.0211      0      0      0      0
001.3      0      0      0      0      0 0.0203      0      0      0      0
001.8      0      0      0      0      0 0.0178      0      0      0      0
002.3      0      0      0      0      0 0.0187      0      0      0      0
002.8      0      0      0      0      0 0.0127      0      0      0      0
      FR010A FR011A FR015A FR018A FR9991 FU002A FU002B FU002F GO003A GO004A
000.3      0      0      0      0      0 0.0172 0.0738      0      0 0.0017
000.8      0      0      0      0      0 0.0326 0.0480      0      0 0.0000
001.3      0      0      0      0      0 0.0370 0.0702      0      0 0.0000
001.8      0      0      0      0      0 0.0445 0.0801      0      0 0.0000
002.3      0      0      0      0      0 0.0300 0.0674      0      0 0.0000
002.8      0      0      0      0      0 0.0363 0.0744      0      0 0.0000
      GO006C GO013A GO023A GO025B GO025F GY005A HN001A ME019A NA002A NA003A
000.3      0 0.0017      0      0      0      0      0      0      0      0
000.8      0 0.0000      0      0      0      0      0      0      0      0
001.3      0 0.0000      0      0      0      0      0      0      0      0
001.8      0 0.0000      0      0      0      0      0      0      0      0
002.3      0 0.0000      0      0      0      0      0      0      0      0
002.8      0 0.0000      0      0      0      0      0      0      0      0
      NA003B NA005A NA005B NA006A NA006B NA007A NA008A NA013A NA014A NA015A
000.3 0.0034 0.0017      0 0.0000      0      0      0      0      0 0.0017
000.8 0.0000 0.0000      0 0.0000      0      0      0      0      0 0.0000
001.3 0.0000 0.0000      0 0.0055      0      0      0      0      0 0.0000
001.8 0.0000 0.0018      0 0.0107      0      0      0      0      0 0.0000
002.3 0.0037 0.0019      0 0.0112      0      0      0      0      0 0.0000
002.8 0.0000 0.0000      0 0.0018      0      0      0      0      0 0.0000
      NA016A NA032A NA033A NA037A NA038A NA042A NA043A NA044A NA045A NA046A
000.3      0 0.0034      0 0.0240      0      0      0      0 0.0051      0
000.8      0 0.0058      0 0.0000      0      0      0      0 0.0000      0
001.3      0 0.0037      0 0.0037      0      0      0      0 0.0000      0
001.8      0 0.0018      0 0.0071      0      0      0      0 0.0000      0
002.3      0 0.0019      0 0.0000      0      0      0      0 0.0000      0
002.8      0 0.0018      0 0.0109      0      0      0      0 0.0000      0
      NA048A NA063A NA068A NA084A NA086A NA099A NA101A NA102A NA112D NA113A
000.3      0      0 0.0034      0      0 0.0000      0      0 0.0000      0
000.8      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
001.3      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
001.8      0      0 0.0000      0      0 0.0000      0      0 0.0000      0
002.3      0      0 0.0000      0      0 0.0000      0      0 0.0019      0
002.8      0      0 0.0036      0      0 0.0036      0      0 0.0000      0
      NA114A NA115A NA129A NA133A NA135A NA140A NA149A NA151A NA156A NA158A
000.3      0      0      0      0      0 0.0309      0      0 0.0635 0.0069
000.8      0      0      0      0      0 0.0403      0      0 0.0653 0.0115
001.3      0      0      0      0      0 0.0351      0      0 0.0869 0.0185
001.8      0      0      0      0      0 0.0409      0      0 0.0765 0.0142
002.3      0      0      0      0      0 0.0393      0      0 0.0674 0.0169
002.8      0      0      0      0      0 0.0218      0      0 0.0581 0.0163
      NA160A NA167A NA170A NA9904 NA9919 NA9955 NA9963 NA9964 NE003A NE003B
000.3      0 0.0326      0      0      0      0      0      0      0      0
000.8      0 0.0365      0      0      0      0      0      0      0      0
001.3      0 0.0555      0      0      0      0      0      0      0      0
001.8      0 0.0427      0      0      0      0      0      0      0      0
002.3      0 0.0300      0      0      0      0      0      0      0      0
002.8      0 0.0399      0      0      0      0      0      0      0      0
      NE003C NE004A NE012A NE020A NE023A NI002A NI005A NI008A NI009A NI009B
000.3      0 0.0000      0      0      0 0.0000 0.0051      0      0      0
000.8      0 0.0019      0      0      0 0.0000 0.0000      0      0      0
001.3      0 0.0000      0      0      0 0.0000 0.0018      0      0      0
001.8      0 0.0000      0      0      0 0.0036 0.0000      0      0      0
002.3      0 0.0019      0      0      0 0.0000 0.0000      0      0      0
002.8      0 0.0073      0      0      0 0.0000 0.0000      0      0      0
      NI017A NI021A NI026A NI027A NI152A NI9984 OP001A PE002A PI005A PI007A
000.3      0      0      0      0      0      0      0 0.0069 0.0017 0.0000
000.8      0      0      0      0      0      0      0 0.0288 0.0000 0.0000
001.3      0      0      0      0      0      0      0 0.0259 0.0000 0.0018
001.8      0      0      0      0      0      0      0 0.0409 0.0000 0.0000
002.3      0      0      0      0      0      0      0 0.0318 0.0000 0.0000
002.8      0      0      0      0      0      0      0 0.0436 0.0000 0.0018
      PI011A PI014A PI015A PI016A PI018A PI018B PI022B PI023A PI055A PI056A
000.3 0.0000 0.0000      0 0.0017 0.0017      0 0.0000      0      0      0
000.8 0.0019 0.0000      0 0.0000 0.0019      0 0.0019      0      0      0
001.3 0.0000 0.0000      0 0.0000 0.0000      0 0.0000      0      0      0
001.8 0.0053 0.0018      0 0.0018 0.0089      0 0.0000      0      0      0
002.3 0.0019 0.0000      0 0.0019 0.0037      0 0.0000      0      0      0
002.8 0.0036 0.0000      0 0.0018 0.0018      0 0.0000      0      0      0
      PI139A PI164A RH006B SA001A SA001B SA006A SA042A SE001A SP002A ST004A
000.3      0      0      0 0.0017 0.0017      0      0      0 0.0000      0
000.8      0      0      0 0.0000 0.0000      0      0      0 0.0000      0
001.3      0      0      0 0.0000 0.0037      0      0      0 0.0018      0
001.8      0      0      0 0.0000 0.0036      0      0      0 0.0000      0
002.3      0      0      0 0.0000 0.0000      0      0      0 0.0000      0
002.8      0      0      0 0.0000 0.0036      0      0      0 0.0000      0
      ST010A SU002A SU004A SU005A SU006A SY002A SY003A SY004A SY009A SY010A
000.3      0      0      0 0.0000 0.0137      0      0      0      0      0
000.8      0      0      0 0.0000 0.0134      0      0      0      0      0
001.3      0      0      0 0.0000 0.0055      0      0      0      0      0
001.8      0      0      0 0.0036 0.0053      0      0      0      0      0
002.3      0      0      0 0.0019 0.0075      0      0      0      0      0
002.8      0      0      0 0.0000 0.0091      0      0      0      0      0
      SY013A SY043A TA001A TA002A TA003A TA004A TA9996
000.3      0      0 0.0103      0 0.0172 0.0806      0
000.8      0      0 0.0115      0 0.0154 0.1440      0
001.3      0      0 0.0055      0 0.0203 0.1165      0
001.8      0      0 0.0053      0 0.0178 0.1352      0
002.3      0      0 0.0075      0 0.0112 0.1517      0
002.8      0      0 0.0181      0 0.0091 0.1234      0

> 
> ## load the example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## show just the first few lines of each data set
> head(dat, n = 4)
$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0       0       0       0       0  98.97   0.90    0.00
V17.196      0       0       0       0       0       0  98.13   0.94    0.47
V18.110      0       0       0       0       0       0  96.29   1.71    1.00
V16.227      0       0       0       0       0       0  94.33   4.82    0.85
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0    0.00       0    0.00      0      0       0
V17.196       0       0       0    0.47       0    0.00      0      0       0
V18.110       0       0       0    0.00       0    0.57      0      0       0
V16.227       0       0       0    0.00       0    0.00      0      0       0
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V14.61        0       0       0       0       0       0  0.13      0       0
V17.196       0       0       0       0       0       0  0.00      0       0
V18.110       0       0       0       0       0       0  0.43      0       0
V16.227       0       0       0       0       0       0  0.00      0       0
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0

$V12.122
    O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL  G.pacR G.bullo
0  0.01792 0.00489 0.43485 0.00814 0.25570 0.00651      0 0.00163 0.00000
10 0.03203 0.00712 0.37722 0.00356 0.30961 0.00712      0 0.00356 0.00000
20 0.02564 0.01709 0.47009 0.00855 0.20513 0.01709      0 0.01282 0.00427
30 0.01124 0.00562 0.47190 0.01124 0.12360 0.02247      0 0.03933 0.00562
   G.falco G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf
0  0.00163 0.00326 0.03257 0.08958 0.04560 0.00163 0.00163 0.00000 0.00000
10 0.00000 0.00000 0.02491 0.08185 0.05694 0.00000 0.00712 0.00356 0.00000
20 0.00000 0.00855 0.00855 0.09402 0.05556 0.00000 0.00427 0.00855 0.00000
30 0.00562 0.02247 0.05056 0.07865 0.06742 0.01124 0.00000 0.01685 0.00562
   G.scitu G.mentu P.obliq C.nitid S.dehis G.digit   Other G.quin G.hirsu
0  0.00163 0.07492 0.00977 0.00651 0.00163       0 0.00000      0       0
10 0.00000 0.05694 0.01423 0.00000 0.00356       0 0.01068      0       0
20 0.00855 0.02991 0.00855 0.00855 0.00000       0 0.00427      0       0
30 0.00562 0.01124 0.02247 0.00000 0.00000       0 0.01124      0       0
   G.hexag G.cglom cfH.pel
0        0       0       0
10       0       0       0
20       0       0       0
30       0       0       0

> 
> ## show just the last few lines of each data set
> tail(dat, n = 4)
$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V20.7     3.08    0.00   60.50    0.00   21.03    0.00      0   0.00    0.00
V20.234   1.09    0.00   46.28    1.09   29.04    0.54      0   0.36    0.18
V18.21    0.21    0.42   47.47    0.21   18.99    0.00      0   0.00    0.00
V12.122   1.79    0.49   43.49    0.81   25.57    0.65      0   0.16    0.00
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V20.7      0.00    0.00    3.08    0.00    7.70    0.00   0.00   0.00       0
V20.234    0.00    1.09    3.27    7.99    2.00    0.00   0.00   0.54       0
V18.21     0.00    1.05    4.43    6.54    2.53    0.00   0.00   0.00       0
V12.122    0.16    0.33    3.26    8.96    4.56    0.16   0.16   0.00       0
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit Other G.quin G.hirsu
V20.7      0.00    3.08    0.00    0.00    0.00       0  1.54      0       0
V20.234    1.27    3.63    0.91    0.00    0.18       0  0.54      0       0
V18.21     0.63   12.45    3.38    0.21    0.42       0  1.05      0       0
V12.122    0.16    7.49    0.98    0.65    0.16       0  0.00      0       0
        G.hexag G.cglom cfH.pel
V20.7         0       0       0
V20.234       0       0       0
V18.21        0       0       0
V12.122       0       0       0

$V12.122
      O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL  G.pacR G.bullo
1060 0.01878 0.00469 0.24883 0.01878 0.14085 0.01408      0 0.09390 0.00939
1070 0.02286 0.02286 0.37143 0.01714 0.08000 0.01714      0 0.08000 0.04571
1080 0.03911 0.02793 0.32961 0.01117 0.14525 0.01117      0 0.02793 0.00559
1090 0.00658 0.00658 0.34869 0.04605 0.15789 0.01316      0 0.03947 0.01974
     G.falco G.calid G.aequi G.gluti G.duter G.infla  G.trnL  G.trnR G.crasf
1060       0 0.01878 0.02347 0.06103 0.15493 0.07512 0.00000 0.01408 0.00000
1070       0 0.02857 0.03429 0.08000 0.05714 0.05143 0.00571 0.05714 0.00571
1080       0 0.01676 0.05028 0.10056 0.11732 0.03911 0.00000 0.01117 0.01117
1090       0 0.03289 0.02632 0.09210 0.05921 0.03289 0.00658 0.03289 0.01974
     G.scitu G.mentu P.obliq C.nitid S.dehis G.digit   Other G.quin G.hirsu
1060 0.00469 0.09390 0.00000       0       0       0 0.00469      0       0
1070 0.00000 0.02286 0.00000       0       0       0 0.00000      0       0
1080 0.00000 0.04469 0.00559       0       0       0 0.00000      0       0
1090 0.00000 0.03289 0.00000       0       0       0 0.02632      0       0
     G.hexag G.cglom cfH.pel
1060 0.00000       0       0
1070 0.00000       0       0
1080 0.00559       0       0
1090 0.00000       0       0

> 
> ## merge training and test set using inner join
> head(join(ImbrieKipp, V12.122, verbose = TRUE, type = "inner"))

Summary:

            Rows Cols
Data set 1:   61   30
Data set 2:  110   30
Merged:      171   30

$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0  0.0000       0  0.0000  0.0000 0.9897 0.0090  0.0000
V17.196      0       0  0.0000       0  0.0000  0.0000 0.9813 0.0094  0.0047
V18.110      0       0  0.0000       0  0.0000  0.0000 0.9629 0.0171  0.0100
V16.227      0       0  0.0000       0  0.0000  0.0000 0.9433 0.0482  0.0085
V14.47       0       0  0.0011       0  0.0011  0.0011 0.6850 0.0271  0.1095
V23.22       0       0  0.0000       0  0.0000  0.0000 0.5569 0.1662  0.1990
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V17.196       0       0       0  0.0047       0  0.0000 0.0000      0  0.0000
V18.110       0       0       0  0.0000       0  0.0057 0.0000      0  0.0000
V16.227       0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V14.47        0       0       0  0.0195       0  0.1420 0.0011      0  0.0043
V23.22        0       0       0  0.0229       0  0.0157 0.0000      0  0.0000
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit  Other G.quin G.hirsu
V14.61   0.0000  0.0000  0.0000       0       0       0 0.0013 0.0000  0.0000
V17.196  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V18.110  0.0000  0.0000  0.0000       0       0       0 0.0043 0.0000  0.0000
V16.227  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V14.47   0.0011  0.0011  0.0011       0       0       0 0.0018 0.0032  0.0000
V23.22   0.0000  0.0000  0.0000       0       0       0 0.0065 0.0314  0.0013
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0
V14.47        0       0       0
V23.22        0       0       0

$V12.122
      O.univ   G.cglob   G.ruber   G.tenel   G.saccu   G.rubes G.pacL    G.pacR
0  0.0001792 0.0000489 0.0043485 0.0000814 0.0025570 0.0000651      0 0.0000163
10 0.0003203 0.0000712 0.0037722 0.0000356 0.0030961 0.0000712      0 0.0000356
20 0.0002564 0.0001709 0.0047009 0.0000855 0.0020513 0.0001709      0 0.0001282
30 0.0001124 0.0000562 0.0047190 0.0001124 0.0012360 0.0002247      0 0.0003933
40 0.0000671 0.0001007 0.0043623 0.0003020 0.0015436 0.0001007      0 0.0000336
50 0.0001149 0.0000766 0.0052873 0.0000766 0.0012261 0.0000000      0 0.0000383
     G.bullo  G.falco   G.calid   G.aequi   G.gluti   G.duter   G.infla
0  0.0000000 1.63e-05 0.0000326 0.0003257 0.0008958 0.0004560 0.0000163
10 0.0000000 0.00e+00 0.0000000 0.0002491 0.0008185 0.0005694 0.0000000
20 0.0000427 0.00e+00 0.0000855 0.0000855 0.0009402 0.0005556 0.0000000
30 0.0000562 5.62e-05 0.0002247 0.0005056 0.0007865 0.0006742 0.0001124
40 0.0000671 3.36e-05 0.0001678 0.0008054 0.0009396 0.0003691 0.0004698
50 0.0002299 0.00e+00 0.0001916 0.0006897 0.0007663 0.0004981 0.0004215
     G.trnL    G.trnR   G.crasf  G.scitu   G.mentu   P.obliq  C.nitid  S.dehis
0  1.63e-05 0.0000000 0.0000000 1.63e-05 0.0007492 0.0000977 6.51e-05 1.63e-05
10 7.12e-05 0.0000356 0.0000000 0.00e+00 0.0005694 0.0001423 0.00e+00 3.56e-05
20 4.27e-05 0.0000855 0.0000000 8.55e-05 0.0002991 0.0000855 8.55e-05 0.00e+00
30 0.00e+00 0.0001685 0.0000562 5.62e-05 0.0001124 0.0002247 0.00e+00 0.00e+00
40 3.36e-05 0.0002349 0.0001342 3.36e-05 0.0001007 0.0000671 0.00e+00 0.00e+00
50 0.00e+00 0.0002682 0.0000766 0.00e+00 0.0000000 0.0000000 0.00e+00 0.00e+00
   G.digit     Other G.quin G.hirsu G.hexag G.cglom cfH.pel
0        0 0.0000000      0       0       0       0       0
10       0 0.0001068      0       0       0       0       0
20       0 0.0000427      0       0       0       0       0
30       0 0.0001124      0       0       0       0       0
40       0 0.0000336      0       0       0       0       0
50       0 0.0000383      0       0       0       0       0

> 
> ## merge training and test set using outer join and replace
> ## NA with -99.9
> head(join(ImbrieKipp, V12.122, verbose = TRUE, value = -99.9))

Summary:

            Rows Cols
Data set 1:   61   30
Data set 2:  110   30
Merged:      171   30

$ImbrieKipp
        O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
V14.61       0       0  0.0000       0  0.0000  0.0000 0.9897 0.0090  0.0000
V17.196      0       0  0.0000       0  0.0000  0.0000 0.9813 0.0094  0.0047
V18.110      0       0  0.0000       0  0.0000  0.0000 0.9629 0.0171  0.0100
V16.227      0       0  0.0000       0  0.0000  0.0000 0.9433 0.0482  0.0085
V14.47       0       0  0.0011       0  0.0011  0.0011 0.6850 0.0271  0.1095
V23.22       0       0  0.0000       0  0.0000  0.0000 0.5569 0.1662  0.1990
        G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR G.crasf
V14.61        0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V17.196       0       0       0  0.0047       0  0.0000 0.0000      0  0.0000
V18.110       0       0       0  0.0000       0  0.0057 0.0000      0  0.0000
V16.227       0       0       0  0.0000       0  0.0000 0.0000      0  0.0000
V14.47        0       0       0  0.0195       0  0.1420 0.0011      0  0.0043
V23.22        0       0       0  0.0229       0  0.0157 0.0000      0  0.0000
        G.scitu G.mentu P.obliq C.nitid S.dehis G.digit  Other G.quin G.hirsu
V14.61   0.0000  0.0000  0.0000       0       0       0 0.0013 0.0000  0.0000
V17.196  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V18.110  0.0000  0.0000  0.0000       0       0       0 0.0043 0.0000  0.0000
V16.227  0.0000  0.0000  0.0000       0       0       0 0.0000 0.0000  0.0000
V14.47   0.0011  0.0011  0.0011       0       0       0 0.0018 0.0032  0.0000
V23.22   0.0000  0.0000  0.0000       0       0       0 0.0065 0.0314  0.0013
        G.hexag G.cglom cfH.pel
V14.61        0       0       0
V17.196       0       0       0
V18.110       0       0       0
V16.227       0       0       0
V14.47        0       0       0
V23.22        0       0       0

$V12.122
      O.univ   G.cglob   G.ruber   G.tenel   G.saccu   G.rubes G.pacL    G.pacR
0  0.0001792 0.0000489 0.0043485 0.0000814 0.0025570 0.0000651      0 0.0000163
10 0.0003203 0.0000712 0.0037722 0.0000356 0.0030961 0.0000712      0 0.0000356
20 0.0002564 0.0001709 0.0047009 0.0000855 0.0020513 0.0001709      0 0.0001282
30 0.0001124 0.0000562 0.0047190 0.0001124 0.0012360 0.0002247      0 0.0003933
40 0.0000671 0.0001007 0.0043623 0.0003020 0.0015436 0.0001007      0 0.0000336
50 0.0001149 0.0000766 0.0052873 0.0000766 0.0012261 0.0000000      0 0.0000383
     G.bullo  G.falco   G.calid   G.aequi   G.gluti   G.duter   G.infla
0  0.0000000 1.63e-05 0.0000326 0.0003257 0.0008958 0.0004560 0.0000163
10 0.0000000 0.00e+00 0.0000000 0.0002491 0.0008185 0.0005694 0.0000000
20 0.0000427 0.00e+00 0.0000855 0.0000855 0.0009402 0.0005556 0.0000000
30 0.0000562 5.62e-05 0.0002247 0.0005056 0.0007865 0.0006742 0.0001124
40 0.0000671 3.36e-05 0.0001678 0.0008054 0.0009396 0.0003691 0.0004698
50 0.0002299 0.00e+00 0.0001916 0.0006897 0.0007663 0.0004981 0.0004215
     G.trnL    G.trnR   G.crasf  G.scitu   G.mentu   P.obliq  C.nitid  S.dehis
0  1.63e-05 0.0000000 0.0000000 1.63e-05 0.0007492 0.0000977 6.51e-05 1.63e-05
10 7.12e-05 0.0000356 0.0000000 0.00e+00 0.0005694 0.0001423 0.00e+00 3.56e-05
20 4.27e-05 0.0000855 0.0000000 8.55e-05 0.0002991 0.0000855 8.55e-05 0.00e+00
30 0.00e+00 0.0001685 0.0000562 5.62e-05 0.0001124 0.0002247 0.00e+00 0.00e+00
40 3.36e-05 0.0002349 0.0001342 3.36e-05 0.0001007 0.0000671 0.00e+00 0.00e+00
50 0.00e+00 0.0002682 0.0000766 0.00e+00 0.0000000 0.0000000 0.00e+00 0.00e+00
   G.digit     Other G.quin G.hirsu G.hexag G.cglom cfH.pel
0        0 0.0000000      0       0       0       0       0
10       0 0.0001068      0       0       0       0       0
20       0 0.0000427      0       0       0       0       0
30       0 0.0001124      0       0       0       0       0
40       0 0.0000336      0       0       0       0       0
50       0 0.0000383      0       0       0       0       0

> 
> 
> 
> cleanEx()
> nameEx("logitreg")
> ### * logitreg
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: logitreg
> ### Title: Logistic regression models for assessing analogues/non-analogues
> ### Aliases: logitreg logitreg.default logitreg.analog print.logitreg
> ###   summary.logitreg print.summary.logitreg
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 6)
> 
> ## fit the logit models to the analog object
> swap.lrm <- logitreg(swap.ana, grps)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
> swap.lrm

Object of class: "logitreg"
Number of models: 7

For groups:
[1] "1"        "2"        "3"        "4"        "5"        "6"        "Combined"

> 
> ## summary statistics
> summary(swap.lrm)

Logit regression models

          In Out E[Dij]    SE      Z    p-value Dij(p=0.9) SE (Dij)
1         46 121  -15.8  2.80  -5.63 1.8454e-08      0.338   0.0332
2         35 132  -32.2  6.87  -4.68 2.8597e-06      0.409   0.0200
3         22 145  -34.1 10.19  -3.35 0.00081417      0.366   0.0264
4         24 143  -27.2  6.74  -4.03 5.6098e-05      0.495   0.0274
5         25 142  -16.2  3.93  -4.12 3.7464e-05      0.461   0.0494
6         15 152  -11.0  2.71  -4.06 4.8045e-05      0.283   0.0794
Combined 167 835  -16.2  1.41 -11.51 < 2.22e-16      0.359   0.0166

> 
> ## plot the fitted logit curves
> plot(swap.lrm, conf.type = "polygon")
> 
> ## extract fitted posterior probabilities for training samples
> ## for the individual groups
> fit <- fitted(swap.lrm)
> head(fit)
          1           2         3         4         5         6
1 0.7704741 0.992926550 0.9705455 0.9967696 0.9977100 0.8004397
2 0.9480710 0.008663829 0.9961969 0.7215776 0.9573624 0.4823301
3 0.9740472 0.847497770 0.9714598 0.6919208 0.9965144 0.2744509
4 0.7168113 0.847497770 0.9535765 0.3007374 0.9990662 0.2870750
5 0.9661203 0.997014448 0.9970177 0.9946234 0.9178795 0.4975797
6 0.9740472 0.445288611 0.3826365 0.7858915 0.9990662 0.2870750
> 
> ## compute posterior probabilities of analogue-ness for the rlgh
> ## samples. Here we take the dissimilarities between fossil and
> ## training samples from the `swap.ana` object rather than re-
> ## compute them
> pred <- predict(swap.lrm, newdata = swap.ana$analogs)
> head(pred)
              1          2         3           4            5          6
000.3 0.8888987 0.08607136 0.0541194 0.005482089 8.536340e-05 0.03915959
000.8 0.9508126 0.01931803 0.4638425 0.070408351 1.349192e-05 0.02206208
001.3 0.9423900 0.04554104 0.7782695 0.043191558 1.474048e-05 0.01984818
001.8 0.9523237 0.03181413 0.3485667 0.010448649 2.326359e-05 0.02003420
002.3 0.9372000 0.02182155 0.3034852 0.031319684 1.133939e-05 0.01383880
002.8 0.9732644 0.05464832 0.5834611 0.027163318 4.119295e-05 0.03144971
> 
> ## Bias reduction
> ## fit the logit models to the analog object
> swap.brlrm <- logitreg(swap.ana, grps, biasReduced = TRUE)
> summary(swap.brlrm)

Logit regression models

          In Out E[Dij]   SE      Z    p-value Dij(p=0.9) SE (Dij)
1         46 121  -15.1 2.68  -5.63 1.7690e-08      0.331   0.0346
2         35 132  -29.5 6.08  -4.85 1.2174e-06      0.403   0.0212
3         22 145  -28.5 7.82  -3.65 0.00026651      0.353   0.0287
4         24 143  -24.2 5.73  -4.22 2.4163e-05      0.485   0.0298
5         25 142  -14.5 3.34  -4.33 1.4819e-05      0.442   0.0530
6         15 152  -10.1 2.44  -4.15 3.3636e-05      0.260   0.0858
Combined 167 835  -16.0 1.38 -11.55 < 2.22e-16      0.357   0.0167

> 
> 
> 
> cleanEx()
> nameEx("mat")
> ### * mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mat
> ### Title: Modern Analogue Technique transfer function models
> ### Aliases: mat mat.default mat.formula fitted.mat residuals.mat resid.mat
> ###   print.residuals.mat print.mat print.fitted.mat
> ### Keywords: models multivariate methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> ik.mat

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## model summary
> summary(ik.mat)

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP   R2 Avg Bias Max Bias
  1  2.50 0.88     0.32     9.00
  2  1.87 0.93     0.28     6.00
  3  1.71 0.94     0.13     5.17
  4  1.80 0.94     0.18     5.12
  5  1.75 0.94     0.21     5.10
  6  1.72 0.94     0.28     5.67
  7  1.76 0.94     0.38     6.43
  8  1.83 0.94     0.39     6.62
  9  1.91 0.94     0.45     7.22
 10  2.04 0.93     0.58     7.50

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP   R2 Avg Bias Max Bias
  1  2.50 0.88     0.32     9.00
  2  1.89 0.93     0.26     6.18
  3  1.73 0.94     0.14     5.47
  4  1.77 0.94     0.17     5.38
  5  1.75 0.94     0.19     5.37
  6  1.71 0.94     0.22     5.49
  7  1.71 0.94     0.25     5.63
  8  1.76 0.94     0.25     5.69
  9  1.78 0.94     0.27     5.84
 10  1.86 0.94     0.36     5.93

Results for training set

  * (W.)Est and (W.)Resi are based on k=10-closest analogues
  * minDC is the minimum distance to another sample in the training set
  * min(W.)Resi is the minimum residual for a k-closest model,
    where k = 1,...,10. Column k(.W) displays which k has minResi

           Obs    Est   Resi  W.Est   W.Resi  minDC  minResi   k  minW.Resi
V14.61     2.0   9.50   7.50   7.93   5.9273  0.104   5.1000   5   5.37e+00
V17.196    5.0   9.20   4.20   6.86   1.8572  0.130   0.1667   3   4.61e-01
V18.110    5.5   9.15   3.65   7.13   1.6290  0.134   0.5000   1   4.84e-01
V16.227    7.0   9.00   2.00   7.16   0.1554  0.134   0.1667   3   2.62e-02
V14.47     7.0   9.00   2.00   8.66   1.6594  0.452   0.0000   4   3.63e-02
V23.22    10.5   8.65  -1.85   8.68  -1.8229  0.467   0.5000   3   7.43e-01
V2.12     11.0   8.60  -2.40   5.70  -5.2971  0.119   2.4000  10   5.30e+00
V23.29    10.0  13.65   3.65  13.33   3.3347  0.467   1.2500   2   1.41e+00
V12.43    13.0  13.25   0.25  13.31   0.3135  0.490   0.0000   5   1.71e-01
R9.7      12.0  14.85   2.85  14.29   2.2876  0.432   1.0000   2   4.65e-01
A157.3    14.0  16.30   2.30  16.04   2.0418  0.407   0.5000   2   3.14e-01
V23.81    14.5  15.45   0.95  15.40   0.8996  0.299   0.1667   3   8.08e-02
V23.82    15.0  16.20   1.20  15.84   0.8369  0.299   0.1429   7   1.40e-01
V12.53    14.5  17.80   3.30  17.76   3.2607  0.442   2.3571   7   2.55e+00
V23.83    16.0  15.30  -0.70  15.02  -0.9814  0.295   0.7000  10   9.81e-01
V12.56    18.0  20.90   2.90  20.78   2.7832  0.380   1.0000   2   1.03e+00
A152.84   20.0  21.60   1.60  21.64   1.6374  0.361   0.1429   7   5.77e-01
V16.50    18.0  20.50   2.50  20.28   2.2759  0.429   0.0000   1   0.00e+00
V22.122   19.0  17.95  -1.05  17.58  -1.4223  0.429   1.0500  10   1.42e+00
V16.41    18.5  23.90   5.40  23.64   5.1402  0.380   2.5000   1   2.50e+00
V4.32     21.5  23.60   2.10  23.62   2.1185  0.333   1.6250   8   1.73e+00
V12.66    21.0  21.10   0.10  21.12   0.1228  0.421   0.0000   1   0.00e+00
V19.245   21.0  23.20   2.20  22.72   1.7177  0.331   0.1667   3   4.41e-01
V4.8      24.0  23.35  -0.65  23.38  -0.6203  0.280   0.0000   1   0.00e+00
A180.15   24.0  22.95  -1.05  22.99  -1.0083  0.292   0.0000   1   0.00e+00
V18.34    23.0  24.35   1.35  24.49   1.4904  0.411   1.3500  10   1.49e+00
V20.213   24.0  24.57   0.57  24.56   0.5565  0.326   0.0833   6   1.38e-01
V19.222   23.0  23.00   0.00  23.06   0.0580  0.384   0.0000  10   3.83e-02
A180.39   23.0  24.25   1.25  24.24   1.2366  0.347   0.4167   6   5.12e-01
V16.189   24.0  25.89   1.89  25.85   1.8495  0.399   1.0000   1   1.00e+00
V12.18    25.0  25.39   0.39  25.48   0.4751  0.289   0.3000   9   4.19e-01
V7.67     26.0  23.45  -2.55  23.76  -2.2436  0.308   0.0000   1   0.00e+00
V17.165   26.0  24.77  -1.23  24.80  -1.2021  0.308   0.0000   1   0.00e+00
V19.310   26.0  23.75  -2.25  23.97  -2.0257  0.296   0.0000   1   0.00e+00
V16.190   25.0  25.32   0.32  25.34   0.3424  0.324   0.0000   2   3.98e-02
A153.154  26.0  25.67  -0.33  25.73  -0.2694  0.222   0.1000   2   1.11e-01
V19.308   26.0  25.99  -0.01  25.98  -0.0223  0.222   0.0100  10   2.23e-02
V22.172   24.5  26.72   2.22  26.71   2.2110  0.307   1.5000   1   1.50e+00
V10.98    27.0  24.82  -2.18  24.77  -2.2349  0.330   2.0000   1   2.00e+00
V22.219   26.2  25.65  -0.55  25.63  -0.5709  0.189   0.2000   1   2.00e-01
V16.33    25.0  26.37   1.37  26.37   1.3703  0.493   0.7333   3   7.48e-01
V22.204   26.5  26.80   0.30  26.74   0.2362  0.325   0.0000   6   3.12e-02
V20.167   26.2  26.90   0.70  26.87   0.6732  0.257   0.0333   3   1.17e-02
V10.89    26.0  26.04   0.04  26.12   0.1184  0.308   0.0400  10   1.18e-01
V12.79    26.0  26.90   0.90  26.88   0.8813  0.249   0.3750   4   5.16e-01
V19.216   27.0  25.27  -1.73  25.32  -1.6776  0.363   0.9000   7   9.65e-01
V14.90    27.0  26.95  -0.05  26.89  -0.1113  0.249   0.0000   4   2.56e-02
A180.72   27.5  26.75  -0.75  26.74  -0.7623  0.185   0.4286   7   5.18e-01
V16.21    27.0  26.87  -0.13  26.85  -0.1453  0.247   0.0000   1   0.00e+00
A180.76   27.0  27.15   0.15  27.16   0.1582  0.233   0.0000   6   3.86e-02
V15.164   27.0  26.82  -0.18  26.79  -0.2081  0.257   0.0000   1   0.00e+00
A180.78   27.0  27.20   0.20  27.19   0.1940  0.405   0.0000   5   1.03e-04
V14.5     27.0  27.02   0.02  27.07   0.0730  0.219   0.0000   1   3.55e-15
V3.128    29.0  26.72  -2.28  26.69  -2.3050  0.366   2.1500   2   2.17e+00
A179.13   28.5  26.09  -2.41  26.13  -2.3699  0.327   1.8333   3   1.85e+00
V9.31     27.5  26.87  -0.63  26.92  -0.5805  0.309   0.0000   1   0.00e+00
V20.230   27.5  26.87  -0.63  26.90  -0.6015  0.291   0.1667   3   1.77e-01
V20.7     27.5  27.27  -0.23  27.25  -0.2452  0.431   0.0000   2   1.06e-03
V20.234   27.0  27.02   0.02  27.08   0.0788  0.228   0.0000   1   0.00e+00
V18.21    27.0  26.77  -0.23  26.87  -0.1318  0.252   0.0000   1   3.55e-15
V12.122   28.0  26.92  -1.08  26.94  -1.0561  0.228   0.9000   5   9.17e-01
          k.W
V14.61      5
V17.196     3
V18.110     2
V16.227     9
V14.47      6
V23.22      3
V2.12      10
V23.29      2
V12.43      5
R9.7        2
A157.3      2
V23.81      4
V23.82      7
V12.53      7
V23.83     10
V12.56      2
A152.84     7
V16.50      1
V22.122    10
V16.41      1
V4.32       8
V12.66      1
V19.245     4
V4.8        1
A180.15     1
V18.34     10
V20.213     6
V19.222     9
A180.39     6
V16.189     1
V12.18      9
V7.67       1
V17.165     1
V19.310     1
V16.190     3
A153.154    2
V19.308    10
V22.172     1
V10.98      1
V22.219     2
V16.33      3
V22.204     7
V20.167     4
V10.89     10
V12.79      4
V19.216     7
V14.90      4
A180.72     7
V16.21      1
A180.76     7
V15.164     1
A180.78     5
V14.5       1
V3.128      2
A179.13     3
V9.31       1
V20.230     3
V20.7       2
V20.234     1
V18.21      1
V12.122     5

> 
> ## fitted values
> fitted(ik.mat)

	Modern Analogue Technique: Fitted values

No. of analogues (k) : 3 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
   7.167    4.833    4.667    7.167    7.667   10.000    4.833   11.833 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  13.500   13.667   14.500   14.333   14.167   17.000   14.500   20.667 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  22.000   17.167   15.500   23.333   24.000   21.833   20.833   23.833 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  23.333   25.333   24.500   23.833   24.000   25.733   26.067   25.333 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  25.333   25.333   25.000   25.733   25.733   26.400   24.667   25.667 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  25.733   26.000   26.167   27.233   27.000   25.667   26.833   26.667 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  26.400   27.167   26.733   26.833   27.333   26.067   26.667   27.167 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  27.333   27.333   27.333   27.333   27.000 
> 
> ## model residuals
> resid(ik.mat)

	Modern Analogue Technique Residuals

No. of analogues (k) : 3 
User supplied k?     : FALSE 
Weighted analysis?   : FALSE 

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.1667  -0.1667  -0.8333   0.1667   0.6667  -0.5000  -6.1667   1.8333 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  0.5000   1.6667   0.5000  -0.1667  -0.8333   2.5000  -1.5000   2.6667 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  2.0000  -0.8333  -3.5000   4.8333   2.5000   0.8333  -0.1667  -0.1667 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 -0.6667   2.3333   0.5000   0.8333   1.0000   1.7333   1.0667  -0.6667 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 -0.6667  -0.6667   0.0000  -0.2667  -0.2667   1.9000  -2.3333  -0.5333 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  0.7333  -0.5000  -0.0333   1.2333   1.0000  -1.3333  -0.1667  -0.8333 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 -0.6000   0.1667  -0.2667  -0.1667   0.3333  -2.9333  -1.8333  -0.3333 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 -0.1667  -0.1667   0.3333   0.3333  -1.0000 
> 
> ## draw summary plots of the model
> par(mfrow = c(2,2))
> plot(ik.mat)
> par(mfrow = c(1,1))
> 
> ## reconstruct for the V12.122 core data
> coreV12.mat <- predict(ik.mat, V12.122, k = 3)
> coreV12.mat

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? FALSE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
   1.7130    0.9409    0.1328    5.1667 

Predicted values:
    0    10    20    30    40    50    60    70    80    90   100   110   120 
27.33 27.33 27.33 26.33 25.90 25.90 25.50 25.83 26.17 26.00 27.00 27.33 26.33 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
27.17 26.50 25.57 26.57 26.57 27.23 27.33 26.50 26.83 27.50 27.33 27.73 26.00 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
25.90 26.33 26.50 27.33 25.90 26.33 26.33 26.17 25.83 27.07 25.90 25.90 27.50 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
26.83 27.00 27.73 27.17 27.50 27.17 27.00 27.40 25.90 26.83 27.67 27.33 27.00 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
27.00 25.90 26.07 26.17 27.33 27.33 26.50 25.90 27.17 27.07 26.57 27.17 27.33 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
27.17 26.83 27.00 26.83 27.17 26.90 27.40 26.17 27.83 27.00 26.83 26.83 27.40 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
27.67 27.33 27.33 26.50 26.83 25.50 26.17 27.00 26.00 25.90 26.33 25.00 26.83 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
26.17 26.50 27.33 27.33 26.73 27.50 27.33 27.33 27.33 26.17 27.33 26.17 26.17 
 1040  1050  1060  1070  1080  1090 
27.00 26.00 26.83 25.50 26.50 26.00 
> summary(coreV12.mat)

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? FALSE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
   1.7130    0.9409    0.1328    5.1667 

Predicted values:
    0    10    20    30    40    50    60    70    80    90   100   110   120 
27.33 27.33 27.33 26.33 25.90 25.90 25.50 25.83 26.17 26.00 27.00 27.33 26.33 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
27.17 26.50 25.57 26.57 26.57 27.23 27.33 26.50 26.83 27.50 27.33 27.73 26.00 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
25.90 26.33 26.50 27.33 25.90 26.33 26.33 26.17 25.83 27.07 25.90 25.90 27.50 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
26.83 27.00 27.73 27.17 27.50 27.17 27.00 27.40 25.90 26.83 27.67 27.33 27.00 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
27.00 25.90 26.07 26.17 27.33 27.33 26.50 25.90 27.17 27.07 26.57 27.17 27.33 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
27.17 26.83 27.00 26.83 27.17 26.90 27.40 26.17 27.83 27.00 26.83 26.83 27.40 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
27.67 27.33 27.33 26.50 26.83 25.50 26.17 27.00 26.00 25.90 26.33 25.00 26.83 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
26.17 26.50 27.33 27.33 26.73 27.50 27.33 27.33 27.33 26.17 27.33 26.17 26.17 
 1040  1050  1060  1070  1080  1090 
27.00 26.00 26.83 25.50 26.50 26.00 

Training set assessment:

          Obs    Est    Resid
V14.61    2.0  7.167  5.16667
V17.196   5.0  4.833 -0.16667
V18.110   5.5  4.667 -0.83333
V16.227   7.0  7.167  0.16667
V14.47    7.0  7.667  0.66667
V23.22   10.5 10.000 -0.50000
V2.12    11.0  4.833 -6.16667
V23.29   10.0 11.833  1.83333
V12.43   13.0 13.500  0.50000
R9.7     12.0 13.667  1.66667
A157.3   14.0 14.500  0.50000
V23.81   14.5 14.333 -0.16667
V23.82   15.0 14.167 -0.83333
V12.53   14.5 17.000  2.50000
V23.83   16.0 14.500 -1.50000
V12.56   18.0 20.667  2.66667
A152.84  20.0 22.000  2.00000
V16.50   18.0 17.167 -0.83333
V22.122  19.0 15.500 -3.50000
V16.41   18.5 23.333  4.83333
V4.32    21.5 24.000  2.50000
V12.66   21.0 21.833  0.83333
V19.245  21.0 20.833 -0.16667
V4.8     24.0 23.833 -0.16667
A180.15  24.0 23.333 -0.66667
V18.34   23.0 25.333  2.33333
V20.213  24.0 24.500  0.50000
V19.222  23.0 23.833  0.83333
A180.39  23.0 24.000  1.00000
V16.189  24.0 25.733  1.73333
V12.18   25.0 26.067  1.06667
V7.67    26.0 25.333 -0.66667
V17.165  26.0 25.333 -0.66667
V19.310  26.0 25.333 -0.66667
V16.190  25.0 25.000  0.00000
A153.154 26.0 25.733 -0.26667
V19.308  26.0 25.733 -0.26667
V22.172  24.5 26.400  1.90000
V10.98   27.0 24.667 -2.33333
V22.219  26.2 25.667 -0.53333
V16.33   25.0 25.733  0.73333
V22.204  26.5 26.000 -0.50000
V20.167  26.2 26.167 -0.03333
V10.89   26.0 27.233  1.23333
V12.79   26.0 27.000  1.00000
V19.216  27.0 25.667 -1.33333
V14.90   27.0 26.833 -0.16667
A180.72  27.5 26.667 -0.83333
V16.21   27.0 26.400 -0.60000
A180.76  27.0 27.167  0.16667
V15.164  27.0 26.733 -0.26667
A180.78  27.0 26.833 -0.16667
V14.5    27.0 27.333  0.33333
V3.128   29.0 26.067 -2.93333
A179.13  28.5 26.667 -1.83333
V9.31    27.5 27.167 -0.33333
V20.230  27.5 27.333 -0.16667
V20.7    27.5 27.333 -0.16667
V20.234  27.0 27.333  0.33333
V18.21   27.0 27.333  0.33333
V12.122  28.0 27.000 -1.00000
> 
> ## draw the reconstruction
> reconPlot(coreV12.mat, use.labels = TRUE, display.error = "bars",
+           xlab = "Depth", ylab = "SumSST")
> 
> ## fit the MAT model using the squared chord distance measure
> ## and restrict the number of analogues we fit models for to 1:20
> ik.mat2 <- mat(ImbrieKipp, SumSST, method = "chord", kmax = 20)
> ik.mat2

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord", kmax = 20) 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("mcarlo")
> ### * mcarlo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: mcarlo
> ### Title: Monte Carlo simulation of dissimilarities
> ### Aliases: mcarlo mcarlo.default mcarlo.mat mcarlo.analog print.mcarlo
> ### Keywords: multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## perform the modified method of Sawada (2004) - paired sampling,
> ## with replacement
> ik.mcarlo <- mcarlo(ImbrieKipp, method = "chord", nsamp = 1000,
+                     type = "paired", replace = FALSE)
> ik.mcarlo

	Simulated Dissimilarities

Simulation type : paired 
No. simulations : 1000 
Coefficient     : chord 

Summary of simulated distribution:
    Min 1st Qu.  Median    Mean 3rd Qu.     Max 
 0.0917  1.2921  1.3694  1.2293  1.4052  1.4119 

Percentiles of simulated distribution:
    1%   2.5%     5%    10%    90%    95%  97.5%    99% 
0.0917 0.1035 0.1343 0.6572 1.4111 1.4115 1.4116 1.4119 

> 
> ## plot the simulated distribution
> layout(matrix(1:2, ncol = 1))
> plot(ik.mcarlo)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("minDC")
> ### * minDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: minDC
> ### Title: Extract minimum dissimilarities
> ### Aliases: minDC minDC.default minDC.predict.mat minDC.analog minDC.wa
> ###   print.minDC
> ### Keywords: utilities manip methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> ik.mat

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "SQchord") 

Percentiles of the dissimilarities for the training set:

    1%     2%     5%    10%    20% 
0.0483 0.0786 0.1163 0.1710 0.2512 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.926 0.927    0.244    6.364
  3 1.770 0.937    0.139    5.771
  4 1.772 0.937    0.166    5.674
  5 1.758 0.938    0.172    5.667
  6 1.717 0.941    0.186    5.688
  7 1.717 0.941    0.200    5.705
  8 1.753 0.939    0.197    5.712
  9 1.765 0.938    0.205    5.729
 10 1.822 0.934    0.262    5.740

> 
> ## reconstruct for the V12-122 core data
> v12.mat <- predict(ik.mat, V12.122)
> 
> ## extract the minimum DC values
> v12.mdc <- minDC(v12.mat)
> v12.mdc

	Minimum dissimilarity per sample

Dissimilarity: SQchord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.810 0.814 0.816 0.817 0.817 0.822 0.823 0.825 0.824 0.825 0.828 0.825 0.829 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.826 0.830 0.825 0.824 0.821 0.825 0.826 0.821 0.823 0.822 0.820 0.821 0.821 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.821 0.826 0.828 0.823 0.823 0.831 0.828 0.829 0.823 0.825 0.824 0.828 0.825 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.827 0.822 0.830 0.822 0.826 0.819 0.822 0.823 0.821 0.826 0.823 0.822 0.829 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.823 0.828 0.829 0.828 0.824 0.823 0.822 0.818 0.821 0.829 0.834 0.821 0.823 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.822 0.828 0.830 0.833 0.822 0.826 0.827 0.832 0.835 0.825 0.823 0.826 0.830 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.835 0.823 0.823 0.824 0.825 0.821 0.823 0.828 0.829 0.828 0.826 0.833 0.832 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.825 0.826 0.826 0.822 0.828 0.827 0.824 0.822 0.830 0.824 0.833 0.829 0.829 
 1040  1050  1060  1070  1080  1090 
0.832 0.821 0.828 0.828 0.824 0.823 
> 
> ## draw a plot of minimum DC by time
> plot(v12.mdc, use.labels = TRUE, xlab = "Depth (cm.)")
> 
> 
> 
> cleanEx()
> nameEx("n2")
> ### * n2
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: n2
> ### Title: Calculate Hill's N2 diversity measure
> ### Aliases: n2 n2.default
> ### Keywords: methods multivariate utilities
> 
> ### ** Examples
> 
> data(swapdiat)
> sppN2 <- n2(swapdiat, "species")
> head(sppN2)
   AC001A    AC002A    AC004A    AC013A    AC014A    AC014B 
 8.248589 12.128209 10.997128 46.072440  3.025195  9.190233 
> sampN2 <- n2(swapdiat, "sites")
> head(sampN2)
     1.21     10.21        11    113.21    115.11     12.11 
15.501849 11.026197  6.702897 10.712509 11.370488 15.094376 
> 
> 
> 
> cleanEx()
> nameEx("optima")
> ### * optima
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: optima
> ### Title: Weighted averaging optima and tolerance ranges
> ### Aliases: optima optima.default print.optima print.tolerance
> ###   tolerance.default as.data.frame.optima as.data.frame.tolerance
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## WA optima
> (opt <- optima(ImbrieKipp, SumSST))

	Weighted Average Optima For: SumSST

   O.univ   G.cglob   G.ruber   G.tenel   G.saccu   G.rubes    G.pacL    G.pacR 
24.337228 25.726081 26.067809 25.574791 26.180014 26.274793  7.333465 16.980489 
  G.bullo   G.falco   G.calid   G.aequi   G.gluti   G.duter   G.infla    G.trnL 
17.514873 23.287148 24.527161 25.541789 22.265921 26.490136 19.873421 22.378081 
   G.trnR   G.crasf   G.scitu   G.mentu   P.obliq   C.nitid   S.dehis   G.digit 
24.552945 24.863128 22.617220 26.137781 26.943196 26.410054 24.077808 25.114701 
    Other    G.quin   G.hirsu 
22.716838 12.878463 22.279986 
> 
> ## WA tolerances
> (tol <- tolerance(ImbrieKipp, SumSST, useN2 = TRUE))

	Weighted Average Tolerances For: SumSST

  O.univ  G.cglob  G.ruber  G.tenel  G.saccu  G.rubes   G.pacL   G.pacR 
3.746359 1.895600 1.909561 2.124799 1.979651 1.968294 3.941352 5.181162 
 G.bullo  G.falco  G.calid  G.aequi  G.gluti  G.duter  G.infla   G.trnL 
5.827980 3.109193 2.973112 2.561697 5.898256 1.998304 4.723884 4.161704 
  G.trnR  G.crasf  G.scitu  G.mentu  P.obliq  C.nitid  S.dehis  G.digit 
3.434920 3.354021 3.990673 2.386584 1.554762 1.461725 3.844730 3.108881 
   Other   G.quin  G.hirsu 
5.112464 4.268777 3.942135 
> 
> ## caterpillar plot
> caterpillarPlot(opt, tol)
> 
> ## convert to data frame
> as.data.frame(opt)
              Opt
O.univ  24.337228
G.cglob 25.726081
G.ruber 26.067809
G.tenel 25.574791
G.saccu 26.180014
G.rubes 26.274793
G.pacL   7.333465
G.pacR  16.980489
G.bullo 17.514873
G.falco 23.287148
G.calid 24.527161
G.aequi 25.541789
G.gluti 22.265921
G.duter 26.490136
G.infla 19.873421
G.trnL  22.378081
G.trnR  24.552945
G.crasf 24.863128
G.scitu 22.617220
G.mentu 26.137781
P.obliq 26.943196
C.nitid 26.410054
S.dehis 24.077808
G.digit 25.114701
Other   22.716838
G.quin  12.878463
G.hirsu 22.279986
> as.data.frame(tol)
             Tol
O.univ  3.746359
G.cglob 1.895600
G.ruber 1.909561
G.tenel 2.124799
G.saccu 1.979651
G.rubes 1.968294
G.pacL  3.941352
G.pacR  5.181162
G.bullo 5.827980
G.falco 3.109193
G.calid 2.973112
G.aequi 2.561697
G.gluti 5.898256
G.duter 1.998304
G.infla 4.723884
G.trnL  4.161704
G.trnR  3.434920
G.crasf 3.354021
G.scitu 3.990673
G.mentu 2.386584
P.obliq 1.554762
C.nitid 1.461725
S.dehis 3.844730
G.digit 3.108881
Other   5.112464
G.quin  4.268777
G.hirsu 3.942135
> 
> ## bootstrap WA optima - 100 resamples too low for SD & pCI
> bopt <- optima(ImbrieKipp, SumSST, boot = TRUE, nboot = 100)
> head(bopt)
          Optima  optBoot     optSD     2.5%    97.5%
O.univ  24.33723 24.43556 0.6520349 23.16890 25.38180
G.cglob 25.72608 25.73901 0.3693470 25.10997 26.39830
G.ruber 26.06781 26.08493 0.2194281 25.65242 26.49674
G.tenel 25.57479 25.51535 0.4521986 24.57122 26.27378
G.saccu 26.18001 26.23577 0.2603136 25.67568 26.68661
G.rubes 26.27479 26.23109 0.2738244 25.74904 26.72047
> 
> 
> 
> 
> cleanEx()
> nameEx("pcr")
> ### * pcr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pcr
> ### Title: Prinicpal component regression transfer function models
> ### Aliases: pcr pcr.default pcr.formula print.pcr Hellinger ChiSquare
> ###   performance.pcr fitted.pcr coef.pcr residuals.pcr screeplot.pcr
> ###   eigenvals.pcr
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## normal interface and apply Hellinger transformation
> mod <- pcr(ImbrieKipp, SumSST, tranFun = Hellinger)
> mod

	Principal Component Regression Model

Call:
pcr(x = ImbrieKipp, y = SumSST, tranFun = Hellinger)

No. of Components: 27

RMSE (Apparent):
     PC1      PC2      PC3      PC4      PC5      PC6      PC7      PC8 
2.381215 1.707588 1.680896 1.679774 1.608903 1.535145 1.507995 1.496939 
     PC9     PC10     PC11     PC12     PC13     PC14     PC15     PC16 
1.496908 1.432142 1.426444 1.405155 1.391348 1.349172 1.349172 1.315284 
    PC17     PC18     PC19     PC20     PC21     PC22     PC23     PC24 
1.313187 1.311801 1.291201 1.206484 1.188438 1.187503 1.171215 1.170947 
    PC25     PC26     PC27 
1.170380 1.162497 1.162355 
> 
> ## formula interface, but as above
> mod2 <- pcr(SumSST ~ ., data = ImbrieKipp, tranFun = Hellinger)
> mod2

	Principal Component Regression Model

Call:
pcr(formula = SumSST ~ ., data = ImbrieKipp, tranFun = Hellinger)

No. of Components: 27

RMSE (Apparent):
     PC1      PC2      PC3      PC4      PC5      PC6      PC7      PC8 
2.381215 1.707588 1.680896 1.679774 1.608903 1.535145 1.507995 1.496939 
     PC9     PC10     PC11     PC12     PC13     PC14     PC15     PC16 
1.496908 1.432142 1.426444 1.405155 1.391348 1.349172 1.349172 1.315284 
    PC17     PC18     PC19     PC20     PC21     PC22     PC23     PC24 
1.313187 1.311801 1.291201 1.206484 1.188438 1.187503 1.171215 1.170947 
    PC25     PC26     PC27 
1.170380 1.162497 1.162355 
> 
> ## Several standard methods are available
> fitted(mod, comps = 1:4)
               PC1       PC2       PC3       PC4
V14.61   10.555808  6.619315  6.231607  6.223489
V17.196  10.426913  6.642886  6.321525  6.331140
V18.110  10.046044  6.588254  6.229915  6.213675
V16.227   9.934414  6.385660  6.125620  6.122140
V14.47   10.344901  8.688447  8.462348  8.415080
V23.22    9.380071  7.894699  8.078653  8.121775
V2.12    10.327887  6.574059  6.254559  6.245294
V23.29   11.220420 11.010411 11.624394 11.747316
V12.43   10.262113 10.898128 11.104700 11.068104
R9.7     12.341125 12.821689 13.524704 13.647164
A157.3   11.858419 12.965630 13.111907 13.066726
V23.81   14.593051 16.556046 17.227016 17.277798
V23.82   13.336231 14.880487 15.434312 15.449878
V12.53   13.710271 16.082667 16.071022 16.031209
V23.83   12.848861 14.545725 15.164077 15.181428
V12.56   16.776159 19.280888 18.991744 18.968327
A152.84  17.077391 19.199983 19.242103 19.297802
V16.50   16.263966 18.370537 18.123056 18.017602
V22.122  14.919350 17.161238 17.120519 16.994304
V16.41   21.781309 23.324942 23.009634 22.922366
V4.32    20.986958 22.505015 22.408206 22.462948
V12.66   19.028806 20.660237 20.722466 20.672507
V19.245  21.247213 22.864519 22.688461 22.571391
V4.8     20.751607 22.455502 22.271175 22.373501
A180.15  19.780414 21.697544 21.557218 21.601158
V18.34   21.872722 23.281368 22.901843 22.877120
V20.213  22.441029 23.899982 23.607650 23.642023
V19.222  22.079376 23.527630 23.455039 23.419094
A180.39  24.324601 25.324928 25.201835 25.156614
V16.189  26.545437 26.689606 26.485185 26.482065
V12.18   25.921284 26.412748 26.169977 26.243723
V7.67    22.963671 24.469206 24.259184 24.257127
V17.165  22.963501 24.371047 23.989180 24.069959
V19.310  22.547546 24.259671 24.000703 24.001026
V16.190  24.465707 25.339617 25.171419 25.161826
A153.154 25.998933 26.517402 26.140467 26.233199
V19.308  26.524374 26.827078 26.364425 26.460970
V22.172  27.461512 27.008179 27.100808 27.101809
V10.98   23.296429 24.340573 24.058102 24.033477
V22.219  25.575392 26.028292 25.614264 25.698634
V16.33   26.871770 26.473815 26.393492 26.301020
V22.204  26.415256 26.199712 26.432944 26.417952
V20.167  28.638137 27.643128 27.607118 27.617569
V10.89   27.604368 27.152325 27.013009 27.101828
V12.79   26.985569 26.512017 26.775884 26.753831
V19.216  26.318526 26.447055 26.447463 26.376106
V14.90   26.549162 25.911084 26.210126 26.227570
A180.72  27.195719 26.297326 26.561474 26.539114
V16.21   28.761788 27.523073 27.513898 27.575058
A180.76  28.066329 26.901275 27.191136 27.188959
V15.164  28.684206 27.361226 27.427899 27.467281
A180.78  25.584535 24.635575 25.160030 25.050603
V14.5    28.541053 27.094016 27.361091 27.330425
V3.128   28.020994 26.998395 27.075575 27.024086
A179.13  27.854058 26.920927 26.758398 26.900515
V9.31    26.315023 25.337387 25.675590 25.682354
V20.230  27.958050 26.757884 27.073016 27.065162
V20.7    28.472945 26.743289 26.778757 26.706427
V20.234  28.285842 26.960325 27.241527 27.229153
V18.21   28.619852 27.033444 27.307550 27.256230
V12.122  28.375604 27.024886 27.273001 27.225971
> resid(mod, comps = 1:4)
                 PC1         PC2         PC3         PC4
V14.61   -8.55580828 -4.61931539 -4.23160689 -4.22348927
V17.196  -5.42691346 -1.64288550 -1.32152484 -1.33114042
V18.110  -4.54604377 -1.08825356 -0.72991536 -0.71367516
V16.227  -2.93441364  0.61433992  0.87437956  0.87785995
V14.47   -3.34490101 -1.68844684 -1.46234814 -1.41507982
V23.22    1.11992858  2.60530095  2.42134659  2.37822477
V2.12     0.67211261  4.42594079  4.74544141  4.75470567
V23.29   -1.22042034 -1.01041144 -1.62439376 -1.74731557
V12.43    2.73788748  2.10187177  1.89529962  1.93189598
R9.7     -0.34112536 -0.82168936 -1.52470351 -1.64716394
A157.3    2.14158093  1.03436954  0.88809328  0.93327443
V23.81   -0.09305088 -2.05604621 -2.72701564 -2.77779830
V23.82    1.66376884  0.11951252 -0.43431226 -0.44987757
V12.53    0.78972926 -1.58266660 -1.57102151 -1.53120873
V23.83    3.15113866  1.45427521  0.83592257  0.81857207
V12.56    1.22384150 -1.28088823 -0.99174384 -0.96832655
A152.84   2.92260950  0.80001714  0.75789671  0.70219785
V16.50    1.73603415 -0.37053699 -0.12305564 -0.01760185
V22.122   4.08064989  1.83876237  1.87948061  2.00569618
V16.41   -3.28130912 -4.82494212 -4.50963378 -4.42236632
V4.32     0.51304180 -1.00501470 -0.90820579 -0.96294823
V12.66    1.97119373  0.33976296  0.27753388  0.32749338
V19.245  -0.24721268 -1.86451920 -1.68846065 -1.57139122
V4.8      3.24839261  1.54449833  1.72882462  1.62649913
A180.15   4.21958575  2.30245555  2.44278198  2.39884202
V18.34    1.12727837 -0.28136770  0.09815736  0.12288040
V20.213   1.55897133  0.10001846  0.39235035  0.35797682
V19.222   0.92062407 -0.52762978 -0.45503949 -0.41909357
A180.39  -1.32460093 -2.32492753 -2.20183543 -2.15661410
V16.189  -2.54543712 -2.68960583 -2.48518493 -2.48206451
V12.18   -0.92128430 -1.41274773 -1.16997716 -1.24372269
V7.67     3.03632898  1.53079362  1.74081620  1.74287253
V17.165   3.03649858  1.62895270  2.01081972  1.93004135
V19.310   3.45245449  1.74032881  1.99929681  1.99897351
V16.190   0.53429312 -0.33961708 -0.17141935 -0.16182624
A153.154  0.00106744 -0.51740153 -0.14046678 -0.23319938
V19.308  -0.52437386 -0.82707755 -0.36442472 -0.46096976
V22.172  -2.96151168 -2.50817888 -2.60080768 -2.60180880
V10.98    3.70357142  2.65942657  2.94189846  2.96652266
V22.219   0.62460843  0.17170781  0.58573582  0.50136556
V16.33   -1.87177023 -1.47381459 -1.39349177 -1.30101973
V22.204   0.08474448  0.30028792  0.06705632  0.08204839
V20.167  -2.43813701 -1.44312826 -1.40711830 -1.41756903
V10.89   -1.60436848 -1.15232531 -1.01300912 -1.10182847
V12.79   -0.98556944 -0.51201684 -0.77588414 -0.75383126
V19.216   0.68147388  0.55294527  0.55253680  0.62389450
V14.90    0.45083830  1.08891559  0.78987351  0.77242971
A180.72   0.30428130  1.20267358  0.93852585  0.96088599
V16.21   -1.76178778 -0.52307300 -0.51389825 -0.57505766
A180.76  -1.06632860  0.09872517 -0.19113579 -0.18895925
V15.164  -1.68420625 -0.36122600 -0.42789930 -0.46728143
A180.78   1.41546459  2.36442498  1.83997023  1.94939711
V14.5    -1.54105274 -0.09401624 -0.36109103 -0.33042474
V3.128    0.97900593  2.00160534  1.92442533  1.97591411
A179.13   0.64594244  1.57907275  1.74160153  1.59948509
V9.31     1.18497719  2.16261291  1.82440952  1.81764617
V20.230  -0.45805035  0.74211555  0.42698439  0.43483780
V20.7    -0.97294453  0.75671106  0.72124311  0.79357341
V20.234  -1.28584195  0.03967503 -0.24152719 -0.22915280
V18.21   -1.61985198 -0.03344370 -0.30754956 -0.25622958
V12.122  -0.37560386  0.97511353  0.72699945  0.77402942
> coef(mod, comps = 1:4)
                PC1        PC2          PC3         PC4
O.univ   0.97960861  1.2016603   1.13015179   1.1128268
G.cglob  1.13276639  1.1471271   1.00706123   1.0353731
G.ruber  8.65297976  8.4754988   8.14705363   8.2402103
G.tenel  1.24482761  1.3677458   1.21179400   1.3121058
G.saccu  4.75959547  4.2246275   4.52885172   4.3579999
G.rubes  1.02476239  0.9544143   0.94733705   0.9961300
G.pacL  -7.17321578 -9.9353151 -10.45254750 -10.4565564
G.pacR  -3.90121839 -2.3776793  -1.67789328  -1.7008174
G.bullo -3.13326388 -1.4979098  -1.17933855  -1.0882139
G.falco  0.73594411  2.1020478   1.54570170   1.6164401
G.calid  1.19625271  1.5937153   1.39718760   1.4306745
G.aequi  2.43986501  2.5052818   2.46842828   2.4770908
G.gluti  1.14851354  1.7835416   2.39612953   2.5787239
G.duter  1.69404223  1.5003410   1.70327333   1.5826949
G.infla -2.20267657  0.5541993   0.08307447  -0.1458796
G.trnL  -0.03914596  1.1190751   0.58123923   0.5835277
G.trnR   1.08435617  1.5664182   1.37083689   1.4156359
G.crasf  0.54353847  0.7381725   0.62418317   0.5621548
G.scitu  0.22989678  0.7283892   0.72644944   0.7652869
G.mentu  2.22457439  1.9158889   2.20559117   2.0235286
P.obliq  1.52543742  1.1961121   1.53168829   1.4341713
C.nitid  0.40742311  0.3362025   0.31750482   0.3386641
S.dehis  0.24717152  0.2328456   0.24478974   0.2258191
G.digit  0.41418305  0.4783198   0.43292016   0.4492291
Other    0.42771518  0.9316359   0.96369184   0.9914426
G.quin  -1.41219311 -1.0681350  -0.74369293  -0.6525037
G.hirsu -0.19363169  0.7346868   0.44297993   0.4546855
> 
> ## Eigenvalues can be extracted
> eigenvals(mod)
        PC1         PC2         PC3         PC4         PC5         PC6 
12.83557461  6.36679233  1.95151000  1.01340354  0.55172707  0.43074829 
        PC7         PC8         PC9        PC10        PC11        PC12 
 0.34535328  0.26040498  0.23688898  0.21194092  0.17845946  0.17727005 
       PC13        PC14        PC15        PC16        PC17        PC18 
 0.15110942  0.13603337  0.09872344  0.08822732  0.08410382  0.06901474 
       PC19        PC20        PC21        PC22        PC23        PC24 
 0.06059469  0.05572210  0.04438095  0.04006814  0.03096008  0.02463006 
       PC25        PC26        PC27 
 0.01848773  0.01713097  0.01028315 
> 
> ## screeplot method
> screeplot(mod)
> 
> 
> 
> cleanEx()
> nameEx("performance")
> ### * performance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: performance
> ### Title: Transfer function model performance statistics
> ### Aliases: performance print.performance performance.wa
> ###   performance.predict.wa performance.bootstrap.wa performance.crossval
> ### Keywords: methods utilities
> 
> ### ** Examples
> 
> data(ImbrieKipp)
> data(SumSST)
> 
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## the model performance statistics
> performance(mod)
    RMSE       R2 Avg.Bias Max.Bias 
   2.019    0.917    0.000   -3.815 
> 
> 
> 
> cleanEx()
> nameEx("plot.dissimilarities")
> ### * plot.dissimilarities
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.dissimilarities
> ### Title: Plots the distribution of extracted dissimilarities
> ### Aliases: plot.dissimilarities
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## analog matching between SWAPImbrie & Kipp and V12.122 core
> ik.analog <- analog(ImbrieKipp, V12.122, method = "chord")
> ik.analog

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

	Minimum dissimilarity per sample

Dissimilarity: chord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.910 0.908 0.910 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.909 0.911 0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.906 0.909 0.910 0.907 0.907 0.912 0.910 0.911 0.907 0.908 0.908 0.910 0.908 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.910 0.907 0.911 0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906 0.911 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.907 0.910 0.910 0.910 0.907 0.907 0.906 0.904 0.906 0.910 0.913 0.906 0.907 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.906 0.910 0.911 0.913 0.907 0.909 0.909 0.912 0.914 0.908 0.907 0.909 0.911 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.914 0.907 0.907 0.908 0.908 0.906 0.907 0.910 0.910 0.910 0.909 0.913 0.912 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.908 0.909 0.909 0.907 0.910 0.909 0.908 0.907 0.911 0.908 0.913 0.910 0.910 
 1040  1050  1060  1070  1080  1090 
0.912 0.906 0.910 0.910 0.908 0.907 

> summary(ik.analog)

	Analogue matching for fossil samples

Call: analog(x = ImbrieKipp, y = V12.122, method = "chord") 
Dissimilarity: chord 
k-closest: 10 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

k-closest analogues

   k         0        10        20        30        40        50        60
   1  V12.122   V12.122   V12.122   V20.230   V22.172   V22.172   V22.172 
   2  V14.5     V20.234   V20.234   V14.90    V20.167   V20.167   A153.154
   3  V20.234   V14.5     V16.21    V22.172   V19.216   V19.216   V10.89  
   4  V18.21    V18.21    A180.76   V9.31     V10.89    V10.89    A179.13 
   5  A180.76   A180.76   V14.5     V12.79    V22.204   V16.21    V16.21  
   6  A180.72   A180.72   V15.164   V19.216   V16.21    V15.164   V20.167 
   7  V15.164   V20.230   V20.230   A180.72   V20.234   V20.234   V22.219 
   8  V16.21    V20.167   V14.90    V22.204   V20.230   A153.154  V19.308 
   9  V20.167   V16.21    A180.72   A180.76   V14.90    V20.230   V12.18  
  10  V20.230   V20.7     V20.167   V20.167   V15.164   A179.13   V19.216 
        70        80        90       100       110       120       130
  V10.89    V22.172   V19.216   V19.216   V9.31     V9.31     V9.31   
  V22.172   V19.216   V22.172   V22.204   V14.90    V19.216   V14.90  
  V16.21    V20.167   V22.204   V9.31     V20.230   V22.172   V19.216 
  V14.90    V16.21    V16.190   V22.172   V19.216   V14.90    V22.172 
  V19.216   V10.89    A153.154  V20.234   V22.204   V20.230   V20.230 
  A153.154  V15.164   V14.90    V14.90    V12.79    V20.167   V12.79  
  V20.167   A179.13   V9.31     V16.21    V22.172   A153.154  V22.204 
  V20.234   V20.230   V20.167   V10.89    A180.72   V22.204   A153.154
  V22.204   V20.234   V12.18    A153.154  A180.76   V12.79    V16.190 
  V9.31     V14.90    V10.89    V15.164   V20.234   V3.128    A180.72 
       140       150       160       170       180       190       200
  V9.31     V10.89    V20.167   V20.167   A179.13   V19.216   V20.230 
  V22.172   V22.172   V20.230   V10.89    V20.167   V20.230   V14.90  
  V20.230   V20.167   V10.89    V20.230   V14.90    V14.90    V22.172 
  V20.234   V19.216   V19.216   V16.21    V20.230   V9.31     V9.31   
  V14.90    V16.21    V9.31     V22.172   V10.89    V22.172   V20.167 
  V20.167   A153.154  V14.90    A153.154  V16.21    V20.167   V20.234 
  V12.122   V14.90    A153.154  V14.90    V22.172   V12.79    V12.122 
  V19.216   V20.234   V16.190   A179.13   V9.31     V12.122   V12.79  
  A180.72   V15.164   V16.33    V9.31     V15.164   V20.234   V16.21  
  V16.21    V20.230   V22.172   V22.219   V19.216   V3.128    A180.72 
       210       220       230       240       250       260       270
  V14.90    V12.122   V12.122   V3.128    V14.90    V14.90    V14.90  
  V22.172   V14.90    V18.21    V20.167   V22.204   V20.167   V22.172 
  V20.167   V20.230   V14.90    V12.122   V22.172   V22.172   A180.72 
  V3.128    V18.21    V14.5     V14.90    A180.72   V3.128    V12.122 
  V12.122   V20.167   A180.76   V18.21    V12.79    V12.122   V12.79  
  V20.230   V20.234   V20.234   V22.172   V12.122   A180.72   V22.204 
  V20.234   V14.5     V3.128    A180.76   A180.76   V22.204   V3.128  
  A180.72   V22.172   A180.72   V15.164   V20.167   V12.79    A180.78 
  V15.164   A180.72   V20.167   A180.72   V10.89    A180.76   V18.21  
  A180.76   A180.76   V15.164   V14.5     V15.164   V20.230   V20.167 
       280       290       300       310       320       330       340
  V22.172   V12.122   V22.172   V19.216   V19.216   V22.172   V19.216 
  V14.90    V14.90    V20.167   V16.33    V9.31     V19.216   V10.89  
  V12.122   A180.72   V19.216   V14.90    V22.172   V14.90    V22.172 
  V22.204   V14.5     V15.164   V22.172   V20.230   V10.89    A153.154
  V19.216   V20.167   V16.21    V9.31     V20.234   A153.154  V20.167 
  V15.164   V18.21    V10.89    V10.89    V20.167   V22.204   A179.13 
  V18.21    A180.76   V14.90    V20.167   V22.204   V9.31     V22.204 
  V12.79    V20.234   V20.234   V20.230   V14.90    A180.39   V19.308 
  V14.5     V3.128    V20.230   V16.190   V16.21    V16.190   V16.21  
  V20.234   V22.172   A179.13   V16.21    V10.89    V22.219   V22.219 
       350       360       370       380       390       400       410
  V20.230   V20.167   V19.216   V9.31     V19.216   V9.31     V3.128  
  V20.167   V22.172   V22.172   V12.122   V22.172   V14.90    V12.122 
  V9.31     V16.21    V20.167   V20.234   V3.128    V22.204   V20.167 
  V19.216   V10.89    V3.128    V14.90    V12.122   A180.76   V20.230 
  V14.90    V14.90    V22.204   V20.230   V14.90    V20.230   V14.90  
  V16.21    V20.234   V12.122   A180.76   V9.31     A180.72   V9.31   
  V22.172   V15.164   V20.234   V3.128    V20.234   V22.172   V22.172 
  V16.33    V12.122   V20.230   A180.72   V16.33    V12.79    V20.7   
  V10.89    A179.13   V15.164   V22.204   V20.167   V19.216   V20.234 
  V15.164   V20.230   V16.33    V20.167   V22.204   V20.234   V19.216 
       420       430       440       450       460       470       480
  V9.31     V12.122   V9.31     A180.76   V20.167   V20.167   V14.90  
  V20.234   V9.31     V14.90    V18.21    V3.128    V22.172   A180.76 
  V14.90    V14.90    V20.234   V20.234   V14.5     V20.234   V22.204 
  V20.230   V20.234   V20.230   A180.72   V18.21    V3.128    V22.172 
  V22.172   A180.76   V12.122   V12.122   A180.76   V14.90    A180.72 
  V12.122   V20.230   A180.72   V14.5     V20.234   V20.230   V12.79  
  V20.167   V3.128    V22.204   V20.230   V12.122   A180.76   V20.230 
  V15.164   A180.72   A180.76   V15.164   V20.230   A180.72   V20.234 
  V3.128    V20.167   V12.79    V3.128    A180.72   V22.204   V3.128  
  A180.76   V22.172   V19.216   V14.90    V15.164   V19.216   A180.78 
       490       500       510       520       530       540       550
  V20.234   V12.122   V9.31     V14.90    V20.167   V10.89    V22.204 
  V3.128    V20.234   V22.204   V22.204   V19.216   A153.154  V16.190 
  A180.76   A180.76   V14.90    V9.31     V22.172   V22.219   V19.216 
  A180.72   V20.230   V20.234   V3.128    V10.89    V19.216   V22.172 
  V12.122   V18.21    V20.230   V19.216   V16.21    V12.18    V14.90  
  V22.204   A180.72   V12.122   A180.76   V22.204   V16.190   V20.230 
  V18.21    V3.128    A180.72   A180.72   V12.122   V22.172   V12.79  
  V14.90    V14.5     V19.216   A180.78   V15.164   V16.21    V9.31   
  V14.5     V20.7     A180.76   V12.79    V20.234   V20.167   A180.72 
  V20.230   V20.167   V22.172   V22.172   V20.230   V22.204   V10.89  
       560       570       580       590       600       610       620
  V14.90    V20.230   V22.204   V20.167   V14.90    V20.167   V22.204 
  V20.230   V9.31     V12.79    V22.172   A180.72   V14.90    V20.167 
  A180.76   A180.78   V14.90    V15.164   A180.76   V22.204   V19.216 
  V9.31     V14.90    A180.72   V16.21    V22.204   V12.122   V12.122 
  A180.72   A180.72   V22.172   V10.89    V12.122   V22.172   V22.172 
  A180.78   V22.204   V20.230   V19.216   V9.31     V20.230   V3.128  
  V3.128    A180.76   A180.76   V20.230   V20.234   V19.216   V20.234 
  V12.79    V3.128    V9.31     V20.234   V22.172   V3.128    V14.90  
  V22.172   V12.79    V19.216   V3.128    V12.79    V12.79    V20.230 
  V22.204   V20.234   V20.234   V14.90    V20.230   A180.72   V16.33  
       630       640       650       660       670       680       690
  V14.90    V12.122   V22.204   V14.90    V9.31     V3.128    A179.13 
  V9.31     V14.90    V12.122   V19.216   V20.234   V14.90    V16.21  
  A180.76   V20.234   V20.234   V22.204   V22.204   V22.172   V10.89  
  A180.72   V20.167   V14.90    V20.167   V14.90    V20.167   V15.164 
  V12.122   V14.5     V22.172   V22.172   A180.72   V19.216   V20.167 
  V22.204   V22.204   A180.72   V9.31     V22.172   V9.31     V22.172 
  V20.230   A180.72   V20.167   V3.128    V20.230   V22.204   V22.204 
  V20.234   V3.128    V14.5     V16.33    V12.122   V16.190   V22.219 
  V22.172   V18.21    A180.76   A180.72   V20.167   V20.230   V12.18  
  V20.167   V20.230   V15.164   V10.89    V15.164   A180.72   V19.308 
       700       710       720       730       740       750       760
  V12.122   V20.167   V22.204   V14.90    V14.90    V22.204   V20.234 
  V22.204   V3.128    V22.172   V3.128    V22.204   V20.234   V22.204 
  V20.167   V16.21    V9.31     V9.31     A180.72   V14.90    V14.90  
  V20.234   V15.164   V20.230   V22.172   V12.122   A180.72   A180.76 
  V22.172   V10.89    V14.90    V22.204   V22.172   V12.79    A180.72 
  V19.216   V20.234   V3.128    V20.230   V20.234   V22.172   V3.128  
  V16.21    V12.122   V10.89    V20.167   V20.230   V20.230   V20.167 
  V10.89    V20.230   V19.216   V12.122   V12.79    V12.122   V12.122 
  V15.164   V22.172   V20.167   V19.216   V20.167   V9.31     V20.230 
  A180.72   V22.204   A180.72   V20.234   V3.128    A180.76   V9.31   
       770       780       790       800       810       820       830
  V3.128    V3.128    V18.21    V12.122   V12.122   V14.90    V19.216 
  V20.167   V18.21    V12.122   V18.21    V14.90    V22.204   V22.172 
  V15.164   A180.78   V14.5     V14.5     V22.172   V19.216   V20.167 
  V20.230   V14.90    V20.167   V20.234   V22.204   V12.79    V16.33  
  V14.90    V12.122   V14.90    V20.167   V15.164   V22.172   V22.204 
  V16.21    V22.172   A180.72   V15.164   V20.234   V20.230   V14.90  
  V22.204   V20.167   V3.128    A180.72   V12.79    A180.72   V12.122 
  A180.76   A180.72   A180.76   V14.90    V14.5     V20.167   V16.190 
  V9.31     V20.230   V20.234   V12.79    V18.21    V10.89    V12.79  
  V12.122   V14.5     V15.164   V16.21    A180.72   A180.76   V10.89  
       840       850       860       870       880       890       900
  V19.216   V22.204   V22.204   V19.216   V19.216   V19.216   V19.216 
  V16.33    V20.234   V14.90    V22.172   V9.31     V19.222   V9.31   
  V22.204   V19.216   V22.172   V20.167   V22.172   V16.190   V12.79  
  V20.167   V9.31     V20.167   V22.204   V20.230   V10.98    V22.204 
  V20.234   V14.90    V19.216   V15.164   V12.122   V22.204   V14.90  
  V10.89    V12.122   V10.89    V14.90    V14.90    A180.39   V22.172 
  V22.172   V20.167   A179.13   V3.128    V20.234   V14.90    V20.230 
  A180.72   V20.230   V15.164   V10.89    V12.79    V22.172   V16.190 
  V9.31     A180.76   V12.18    V20.230   V20.167   V12.79    A180.39 
  V14.90    A180.72   V9.31     V16.21    A180.72   V9.31     V19.222 
       910       920       930       940       950       960       970
  V19.216   V19.216   V9.31     V19.216   V20.167   V20.230   V9.31   
  V22.204   V9.31     V20.230   V20.230   V14.90    V12.122   V20.234 
  V16.190   V16.190   V19.216   V9.31     V16.21    V20.234   V20.230 
  V22.172   V14.90    V22.204   V20.167   V20.230   V12.79    V22.172 
  V19.222   V22.204   V22.172   V14.90    V12.122   V22.172   A180.76 
  V12.79    V22.172   V14.90    V22.172   V9.31     V16.21    V19.216 
  A180.39   V20.230   V20.234   V12.79    V20.234   V19.216   V16.21  
  V14.90    A180.39   V20.167   V16.21    V15.164   V9.31     V20.167 
  A153.154  V10.98    V12.79    A180.72   V22.172   V14.90    A180.72 
  V9.31     V12.79    A180.72   V20.234   A179.13   A180.72   V14.90  
       980       990      1000      1010      1020      1030      1040
  V9.31     V9.31     V19.216   V14.90    V19.216   V14.90    V9.31   
  V20.230   V20.234   V14.90    V9.31     V16.190   V19.216   V14.90  
  V14.90    V20.230   V22.172   V20.230   V22.204   V22.172   V22.204 
  V20.234   V14.90    V9.31     V22.172   V22.172   V22.204   V19.216 
  A180.76   V22.172   V20.230   V12.79    V19.222   V9.31     V20.234 
  V22.172   V22.204   V12.79    A180.72   V14.90    V12.79    V12.79  
  A180.72   V12.79    V20.167   V19.216   A180.39   V16.190   V22.172 
  V12.79    V12.122   A180.72   V22.204   V12.66    A180.72   A180.72 
  V19.216   V19.216   V22.204   A180.39   V10.98    V20.234   A180.78 
  V12.122   A180.72   V16.21    V12.122   V12.79    V20.230   A180.76 
      1050      1060      1070      1080      1090
  V19.216   V22.204   V16.190   V19.216   V22.172 
  V22.204   V19.216   V19.216   V12.122   V22.204 
  V14.90    V14.90    V22.172   V22.172   V14.90  
  V22.172   V12.122   V22.204   V14.90    V19.216 
  V12.79    V22.172   V14.90    V22.204   V10.89  
  V9.31     V12.79    V12.18    V20.167   V20.167 
  V12.122   A180.72   V10.89    V12.79    V12.79  
  A180.72   V9.31     V20.167   A180.72   V20.234 
  V16.33    V20.234   V22.219   V20.230   V9.31   
  V16.190   A180.78   V9.31     V20.234   A180.72 

Dissimilarities for k-closest analogues

   k      0     10     20     30     40     50     60     70     80     90
   1  0.900  0.902  0.903  0.904  0.904  0.907  0.907  0.908  0.908  0.908
   2  0.903  0.904  0.904  0.904  0.905  0.908  0.908  0.909  0.908  0.910
   3  0.903  0.904  0.906  0.904  0.906  0.908  0.909  0.910  0.909  0.913
   4  0.903  0.906  0.906  0.905  0.906  0.909  0.910  0.910  0.909  0.913
   5  0.905  0.906  0.906  0.905  0.908  0.909  0.910  0.910  0.909  0.914
   6  0.905  0.907  0.906  0.905  0.908  0.909  0.910  0.911  0.910  0.914
   7  0.907  0.907  0.907  0.906  0.908  0.911  0.910  0.911  0.910  0.914
   8  0.907  0.908  0.907  0.906  0.908  0.911  0.911  0.911  0.910  0.914
   9  0.907  0.909  0.907  0.906  0.908  0.911  0.911  0.911  0.911  0.915
  10  0.908  0.910  0.907  0.906  0.908  0.912  0.911  0.911  0.911  0.915
    100    110    120    130    140    150    160    170    180    190    200
  0.910  0.908  0.910  0.909  0.911  0.908  0.908  0.906  0.908  0.909  0.906
  0.911  0.910  0.910  0.909  0.911  0.909  0.910  0.907  0.910  0.910  0.908
  0.911  0.912  0.911  0.910  0.912  0.909  0.910  0.907  0.910  0.910  0.908
  0.912  0.913  0.911  0.911  0.912  0.910  0.910  0.907  0.911  0.910  0.908
  0.913  0.914  0.912  0.911  0.914  0.910  0.910  0.907  0.911  0.912  0.908
  0.913  0.914  0.914  0.913  0.914  0.910  0.910  0.908  0.911  0.912  0.909
  0.913  0.914  0.914  0.913  0.915  0.911  0.910  0.908  0.911  0.912  0.909
  0.913  0.915  0.914  0.914  0.915  0.911  0.910  0.908  0.912  0.913  0.910
  0.914  0.915  0.915  0.914  0.915  0.911  0.911  0.909  0.913  0.914  0.910
  0.914  0.915  0.915  0.914  0.915  0.912  0.911  0.910  0.914  0.914  0.910
    210    220    230    240    250    260    270    280    290    300    310
  0.907  0.906  0.906  0.906  0.906  0.906  0.909  0.910  0.907  0.907  0.912
  0.908  0.909  0.908  0.910  0.908  0.908  0.910  0.911  0.908  0.908  0.913
  0.908  0.909  0.908  0.911  0.909  0.908  0.911  0.911  0.909  0.908  0.913
  0.908  0.909  0.908  0.911  0.910  0.908  0.912  0.911  0.909  0.909  0.914
  0.909  0.909  0.909  0.911  0.910  0.908  0.912  0.912  0.910  0.909  0.915
  0.910  0.909  0.909  0.912  0.911  0.909  0.912  0.912  0.910  0.909  0.916
  0.910  0.909  0.910  0.912  0.911  0.909  0.913  0.912  0.910  0.909  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.912  0.911  0.910  0.916
  0.910  0.910  0.910  0.913  0.911  0.910  0.913  0.913  0.912  0.910  0.916
  0.910  0.910  0.911  0.913  0.911  0.910  0.914  0.914  0.912  0.910  0.917
    320    330    340    350    360    370    380    390    400    410    420
  0.910  0.911  0.907  0.908  0.908  0.910  0.908  0.910  0.907  0.911  0.906
  0.911  0.911  0.908  0.909  0.909  0.910  0.909  0.910  0.907  0.911  0.907
  0.911  0.911  0.908  0.909  0.909  0.911  0.909  0.912  0.909  0.912  0.907
  0.912  0.911  0.909  0.910  0.909  0.912  0.909  0.912  0.910  0.912  0.907
  0.912  0.912  0.909  0.910  0.909  0.912  0.910  0.912  0.910  0.912  0.908
  0.912  0.912  0.910  0.910  0.909  0.912  0.911  0.912  0.910  0.912  0.908
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.910  0.913  0.909
  0.913  0.913  0.911  0.911  0.909  0.913  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.913  0.909
  0.913  0.913  0.911  0.912  0.910  0.914  0.911  0.913  0.911  0.914  0.909
    430    440    450    460    470    480    490    500    510    520    530
  0.909  0.905  0.906  0.907  0.906  0.909  0.907  0.906  0.911  0.907  0.910
  0.911  0.908  0.907  0.907  0.906  0.909  0.907  0.907  0.912  0.910  0.911
  0.911  0.909  0.907  0.909  0.907  0.909  0.908  0.908  0.912  0.910  0.911
  0.911  0.909  0.908  0.910  0.907  0.910  0.908  0.908  0.913  0.911  0.911
  0.911  0.910  0.908  0.911  0.907  0.910  0.908  0.908  0.914  0.911  0.911
  0.912  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.911
  0.913  0.911  0.908  0.912  0.907  0.911  0.908  0.909  0.914  0.912  0.912
  0.913  0.911  0.909  0.912  0.907  0.911  0.909  0.910  0.915  0.912  0.912
  0.913  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
  0.914  0.911  0.909  0.912  0.908  0.912  0.909  0.911  0.915  0.913  0.913
    540    550    560    570    580    590    600    610    620    630    640
  0.910  0.910  0.907  0.907  0.906  0.904  0.906  0.910  0.913  0.906  0.907
  0.911  0.910  0.908  0.907  0.907  0.907  0.908  0.911  0.913  0.910  0.908
  0.911  0.911  0.910  0.909  0.907  0.907  0.908  0.911  0.914  0.910  0.909
  0.911  0.911  0.910  0.909  0.907  0.907  0.909  0.911  0.914  0.910  0.909
  0.912  0.911  0.910  0.909  0.908  0.907  0.910  0.911  0.915  0.910  0.909
  0.912  0.912  0.911  0.909  0.908  0.907  0.910  0.912  0.915  0.910  0.909
  0.913  0.913  0.911  0.910  0.910  0.907  0.910  0.913  0.915  0.911  0.910
  0.913  0.914  0.912  0.910  0.910  0.908  0.911  0.913  0.916  0.911  0.910
  0.913  0.914  0.912  0.910  0.911  0.908  0.911  0.913  0.916  0.912  0.910
  0.914  0.914  0.913  0.911  0.911  0.908  0.911  0.914  0.916  0.912  0.910
    650    660    670    680    690    700    710    720    730    740    750
  0.906  0.910  0.911  0.913  0.907  0.909  0.909  0.912  0.914  0.908  0.907
  0.907  0.910  0.911  0.913  0.909  0.909  0.911  0.913  0.914  0.909  0.909
  0.909  0.910  0.912  0.914  0.909  0.910  0.911  0.914  0.915  0.910  0.909
  0.909  0.910  0.912  0.916  0.909  0.911  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.910  0.912  0.912  0.914  0.915  0.910  0.910
  0.910  0.911  0.913  0.916  0.914  0.913  0.913  0.915  0.915  0.910  0.910
  0.910  0.911  0.913  0.917  0.914  0.913  0.913  0.915  0.916  0.911  0.910
  0.911  0.912  0.913  0.918  0.914  0.913  0.913  0.916  0.916  0.911  0.911
  0.911  0.912  0.914  0.918  0.914  0.913  0.913  0.916  0.917  0.911  0.911
  0.911  0.913  0.914  0.919  0.915  0.913  0.914  0.916  0.917  0.911  0.911
    760    770    780    790    800    810    820    830    840    850    860
  0.909  0.911  0.914  0.907  0.907  0.908  0.908  0.906  0.907  0.910  0.910
  0.910  0.911  0.914  0.908  0.908  0.908  0.910  0.910  0.909  0.911  0.911
  0.910  0.913  0.917  0.910  0.909  0.909  0.910  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.910  0.910  0.909  0.911  0.910  0.911  0.911  0.912
  0.910  0.913  0.917  0.911  0.910  0.909  0.912  0.911  0.912  0.912  0.912
  0.910  0.913  0.918  0.911  0.911  0.909  0.912  0.912  0.912  0.912  0.912
  0.911  0.914  0.918  0.911  0.911  0.909  0.913  0.912  0.913  0.913  0.913
  0.911  0.914  0.919  0.911  0.911  0.910  0.913  0.913  0.913  0.913  0.914
  0.912  0.914  0.919  0.911  0.912  0.910  0.914  0.913  0.914  0.913  0.914
  0.912  0.914  0.919  0.912  0.912  0.910  0.914  0.913  0.914  0.913  0.915
    870    880    890    900    910    920    930    940    950    960    970
  0.910  0.909  0.913  0.912  0.908  0.909  0.909  0.907  0.910  0.909  0.908
  0.910  0.912  0.914  0.915  0.912  0.913  0.910  0.908  0.910  0.910  0.908
  0.910  0.912  0.914  0.916  0.912  0.915  0.912  0.909  0.911  0.910  0.909
  0.911  0.913  0.915  0.916  0.913  0.916  0.913  0.909  0.911  0.911  0.909
  0.912  0.913  0.915  0.917  0.913  0.917  0.914  0.909  0.911  0.911  0.909
  0.913  0.913  0.915  0.918  0.913  0.917  0.915  0.910  0.911  0.911  0.909
  0.913  0.914  0.917  0.918  0.914  0.917  0.915  0.911  0.911  0.911  0.909
  0.913  0.914  0.918  0.918  0.914  0.917  0.915  0.911  0.912  0.911  0.910
  0.915  0.914  0.918  0.919  0.915  0.918  0.915  0.912  0.912  0.912  0.910
  0.915  0.915  0.918  0.920  0.915  0.918  0.916  0.912  0.913  0.912  0.910
    980    990   1000   1010   1020   1030   1040   1050   1060   1070   1080
  0.907  0.911  0.908  0.913  0.910  0.910  0.912  0.906  0.910  0.910  0.908
  0.909  0.912  0.908  0.913  0.914  0.911  0.914  0.909  0.911  0.910  0.908
  0.909  0.912  0.909  0.914  0.914  0.911  0.916  0.909  0.914  0.911  0.909
  0.911  0.912  0.909  0.915  0.915  0.912  0.917  0.909  0.915  0.911  0.909
  0.911  0.913  0.909  0.915  0.915  0.912  0.917  0.911  0.915  0.912  0.910
  0.912  0.914  0.910  0.916  0.916  0.914  0.917  0.912  0.915  0.913  0.911
  0.912  0.914  0.912  0.916  0.916  0.915  0.917  0.912  0.916  0.913  0.911
  0.912  0.915  0.912  0.917  0.917  0.916  0.918  0.912  0.916  0.914  0.911
  0.912  0.915  0.912  0.918  0.918  0.916  0.918  0.913  0.917  0.914  0.911
  0.913  0.915  0.913  0.918  0.918  0.916  0.918  0.913  0.917  0.915  0.911
   1090
  0.907
  0.908
  0.908
  0.908
  0.910
  0.910
  0.911
  0.911
  0.911
  0.911

> 
> ## compare training set dissimilarities with normals
> ## and derive cut-offs
> ik.dij <- dissim(ik.analog)
> plot(ik.dij)
> 
> 
> 
> cleanEx()
> nameEx("plot.mat")
> ### * plot.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.mat
> ### Title: Plot diagnostics for a mat object
> ### Aliases: plot.mat
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## MAT
> ik.mat <- mat(ImbrieKipp, SumSST, method = "chord")
> 
> ## summary plot of MAT model
> layout(matrix(1:4, ncol = 2, byrow = TRUE))
> plot(ik.mat)
> layout(1)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.mcarlo")
> ### * plot.mcarlo
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.mcarlo
> ### Title: Plot Monte Carlo simulated dissimilarity distributions
> ### Aliases: plot.mcarlo
> ### Keywords: hplot multivariate
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## perform the modified method of Sawada (2004) - paired sampling,
> ## with replacement
> ik.mcarlo <- mcarlo(ImbrieKipp, method = "chord", nsamp = 1000,
+                     type = "paired", replace = FALSE)
> ik.mcarlo

	Simulated Dissimilarities

Simulation type : paired 
No. simulations : 1000 
Coefficient     : chord 

Summary of simulated distribution:
    Min 1st Qu.  Median    Mean 3rd Qu.     Max 
 0.0917  1.2921  1.3694  1.2293  1.4052  1.4119 

Percentiles of simulated distribution:
    1%   2.5%     5%    10%    90%    95%  97.5%    99% 
0.0917 0.1035 0.1343 0.6572 1.4111 1.4115 1.4116 1.4119 

> 
> ## plot the simulated distribution
> layout(matrix(1:2, ncol = 1))
> plot(ik.mcarlo)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("plot.minDC")
> ### * plot.minDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.minDC
> ### Title: Plot of minimum dissimilarity per sample
> ### Aliases: plot.minDC
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## reconstruct for the RLGH core data
> v12.mat <- predict(ik.mat, V12.122)
> 
> ## extract the minimum DC values
> v12.mdc <- minDC(v12.mat)
> v12.mdc

	Minimum dissimilarity per sample

Dissimilarity: chord 

    0    10    20    30    40    50    60    70    80    90   100   110   120 
0.900 0.902 0.903 0.904 0.904 0.907 0.907 0.908 0.908 0.908 0.910 0.908 0.910 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
0.909 0.911 0.908 0.908 0.906 0.908 0.909 0.906 0.907 0.906 0.906 0.906 0.906 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
0.906 0.909 0.910 0.907 0.907 0.912 0.910 0.911 0.907 0.908 0.908 0.910 0.908 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
0.910 0.907 0.911 0.906 0.909 0.905 0.906 0.907 0.906 0.909 0.907 0.906 0.911 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
0.907 0.910 0.910 0.910 0.907 0.907 0.906 0.904 0.906 0.910 0.913 0.906 0.907 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
0.906 0.910 0.911 0.913 0.907 0.909 0.909 0.912 0.914 0.908 0.907 0.909 0.911 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
0.914 0.907 0.907 0.908 0.908 0.906 0.907 0.910 0.910 0.910 0.909 0.913 0.912 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
0.908 0.909 0.909 0.907 0.910 0.909 0.908 0.907 0.911 0.908 0.913 0.910 0.910 
 1040  1050  1060  1070  1080  1090 
0.912 0.906 0.910 0.910 0.908 0.907 
> 
> ## draw a plot of minimum DC by time
> plot(v12.mdc, use.labels = TRUE, xlab = "Depth (cm.)")
> 
> 
> 
> cleanEx()
> nameEx("plot.prcurve")
> ### * plot.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.prcurve
> ### Title: Plot a fitted principal curve in PCA space
> ### Aliases: plot.prcurve lines.prcurve
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.691
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.497
Iteration   6: d.sq: 4369.944

PC Converged in 6 iterations.

> 
> ## Plot the curve
> plot(aber.pc)
> 
> ## The lines() method can be used to add the principal curve to an
> ## existing plot
> ord <- rda(abernethy2)
> plot(ord, scaling = 1)
> lines(aber.pc, scaling = 1)
> 
> 
> 
> cleanEx()
> nameEx("plot.residLen")
> ### * plot.residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.residLen
> ### Title: Plot method for residual lengths
> ### Aliases: plot.residLen
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                50%  75%  90%  95%  99%
Training Set: 0.854 1.56 2.45 2.61 3.72
Passive:      1.004 1.50 1.87 2.17 2.55
> 
> ## plot a histogram of the residual distances
> plot(rlens)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot.wa")
> ### * plot.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.wa
> ### Title: Plot diagnostics for a weighted averaging model
> ### Aliases: plot.wa
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## see full example in ?wa
> 
> 
> 
> 
> cleanEx()
> nameEx("plot3d.prcurve")
> ### * plot3d.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: Plot3d
> ### Title: Interactive 3D plot of a principal curve in principal coordinate
> ###   space
> ### Aliases: Plot3d
> ### Keywords: dynamic graphics
> 
> ### ** Examples
> 
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using the median complexity over
> ## all species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = FALSE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4853.791
Iteration   2: d.sq: 5013.497
Iteration   3: d.sq: 5109.973
Iteration   4: d.sq: 5135.654
Iteration   5: d.sq: 5137.944

PC Converged in 5 iterations.

> 
> ## 3D plot of data with curve superimposed
> ## plot3d.prcurve(aber.pc) # now deprecated, instead use
> Plot3d(aber.pc)
Loading required package: rgl
> 
> 
> 
> 
> cleanEx()

detaching package:rgl

> nameEx("prcurve")
> ### * prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: prcurve
> ### Title: Fits a principal curve to m-dimensional data
> ### Aliases: prcurve initCurve print.prcurve
> ### Keywords: multivariate nonparametric smooth
> 
> ### ** Examples
> 
> ## Load Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using the median complexity over
> ## all species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = FALSE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4853.791
Iteration   2: d.sq: 5013.497
Iteration   3: d.sq: 5109.973
Iteration   4: d.sq: 5135.654
Iteration   5: d.sq: 5137.944

PC Converged in 5 iterations.

> 
> ## Extract fitted values
> fit <- fitted(aber.pc) ## locations on curve
> abun <- fitted(aber.pc, type = "smooths") ## fitted response
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc2 <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                     vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.691
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.497
Iteration   6: d.sq: 4369.944

PC Converged in 6 iterations.

> 
> ## Predict new locations
> take <- abernethy2[1:10, ]
> pred <- predict(aber.pc2, take)
> 
> ## Not run: 
> ##D ## Fit principal curve using a GAM - currently slow ~10secs
> ##D aber.pc3 <- prcurve(abernethy2, method = "ca", trace = TRUE,
> ##D                     vary = TRUE, smoother = smoothGAM, bs = "cr")
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("predict.mat")
> ### * predict.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.mat
> ### Title: Predict method for Modern Analogue Technique models
> ### Aliases: predict.mat print.predict.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## predict for V12.122 data
> predict(ik.mat, V12.122)

	Modern Analogue Technique predictions

Dissimilarity: chord 
k-closest analogues: 3,	Chosen automatically? TRUE
Weighted mean: FALSE 
Bootstrap estimates: FALSE 

Model error estimates:
    RMSEP r.squared  avg.bias  max.bias 
   1.7130    0.9409    0.1328    5.1667 

Predicted values:
    0    10    20    30    40    50    60    70    80    90   100   110   120 
27.33 27.33 27.33 26.33 25.90 25.90 25.50 25.83 25.90 26.00 27.00 27.33 26.33 
  130   140   150   160   170   180   190   200   210   220   230   240   250 
27.17 26.50 25.57 26.57 26.57 27.23 27.17 26.33 25.90 27.50 27.33 27.73 26.00 
  260   270   280   290   300   310   320   330   340   350   360   370   380 
25.90 26.33 26.50 27.50 25.90 26.33 26.33 26.17 25.83 27.07 25.90 25.90 27.50 
  390   400   410   420   430   440   450   460   470   480   490   500   510 
26.83 27.00 27.73 27.17 27.50 27.17 27.00 27.40 25.90 26.83 27.67 27.33 27.00 
  520   530   540   550   560   570   580   590   600   610   620   630   640 
27.00 25.90 26.07 26.17 27.17 27.33 26.50 25.90 27.17 26.57 26.57 27.17 27.33 
  650   660   670   680   690   700   710   720   730   740   750   760   770 
27.17 26.83 27.00 26.83 27.17 26.90 27.40 26.17 27.83 27.00 26.83 26.83 27.40 
  780   790   800   810   820   830   840   850   860   870   880   890   900 
27.67 27.33 27.33 26.50 26.83 25.90 26.17 26.83 26.00 25.90 26.33 25.00 26.83 
  910   920   930   940   950   960   970   980   990  1000  1010  1020  1030 
26.17 26.50 27.33 27.33 26.73 27.50 27.33 27.33 27.33 26.17 27.33 26.17 26.17 
 1040  1050  1060  1070  1080  1090 
27.00 26.83 26.83 25.50 26.50 26.00 
> 
> 
> 
> 
> cleanEx()
> nameEx("predict.pcr")
> ### * predict.pcr
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.pcr
> ### Title: Predicted values from a principal components regression
> ### Aliases: predict.pcr
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Imbrie & Kipp data and
> ## summer sea-surface temperatures
> data(ImbrieKipp)
> data(SumSST)
> 
> ## choose 10 samples to act as a test set, for illustration
> take <- c(5,58,31,51,42,28,30,57,8,50)
> 
> ## normal interface and apply Hellinger transformation
> mod <- pcr(ImbrieKipp[-take, ], SumSST[-take], tranFun = Hellinger)
> 
> ## predictions
> predict(mod, ImbrieKipp[take, ], ncomp = 4)
             PC1       PC2       PC3       PC4
V14.47  10.34383  8.964025  8.816845  8.700079
V20.7   28.37448 26.720456 26.781783 26.619102
V12.18  26.20249 26.438019 26.250313 26.405603
V15.164 28.73089 27.389314 27.464025 27.556603
V22.204 26.62995 26.287830 26.489270 26.472449
V19.222 22.51833 23.657659 23.610868 23.537830
V16.189 26.73964 26.671009 26.551076 26.529436
V20.230 28.03053 26.819795 27.094141 27.094730
V23.29  11.45795 11.373413 11.816852 12.136959
A180.76 28.15434 26.970442 27.221069 27.230316
> 
> ## predictions
> set.seed(123)
> predict(mod, ImbrieKipp[take, ], ncomp = 4, CV = "bootstrap",
+         nboot = 100)
             PC1       PC2       PC3       PC4
V14.47  10.86146  9.108554  8.796106  8.721006
V20.7   27.93000 26.680977 26.738630 26.619345
V12.18  26.09875 26.452455 26.273816 26.340640
V15.164 28.31861 27.344207 27.415372 27.455231
V22.204 26.44229 26.237016 26.479955 26.523139
V19.222 22.69438 23.664213 23.651692 23.626940
V16.189 26.56779 26.665168 26.550892 26.443218
V20.230 27.67475 26.752244 27.058222 27.096922
V23.29  12.11350 11.412378 11.789892 12.165228
A180.76 27.79627 26.907033 27.191718 27.251444
> 
> 
> 
> 
> cleanEx()
> nameEx("predict.wa")
> ### * predict.wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.wa
> ### Title: Predict from a weighted average model
> ### Aliases: predict.wa print.predict.wa
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp
> data(ImbrieKipp)
> data(SumSST)
> ik.wa <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+             min.tol = 2, small.tol = "min")
> ik.wa

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## load V12.122 core data
> data(V12.122)
> V12.122 <- V12.122 / 100
> 
> ## predict summer sea-surface temperature for V12.122 core
> set.seed(2)
> v12.pred <- predict(ik.wa, V12.122, CV = "bootstrap", n.boot = 100)
> 
> ## draw the fitted reconstruction
> reconPlot(v12.pred, use.labels = TRUE, display = "bars")
> 
> ## extract the model performance stats
> performance(v12.pred)
   RMSEP       R2 Avg.Bias Max.Bias 
   2.362    0.899   -0.148   -3.216 
> 
> 
> 
> 
> cleanEx()
> nameEx("rankDC")
> ### * rankDC
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rankDC
> ### Title: Rank correlation between environmental and species
> ###   dissimilarities.
> ### Aliases: rankDC print.rankDC plot.rankDC dotplot.rankDC dotplot
> ### Keywords: hplot methods utilities multivariate
> 
> ### ** Examples
> 
> data(swappH)
> data(swapdiat)
> 
> rc <- rankDC(swappH, swapdiat, dc = c("chord","euclidean","gower"))
> 
> ## base plot uses dotchart()
> plot(rc)
> 
> ## lattice version of the base plot
> dotplot(rc)
> 
> 
> 
> 
> cleanEx()
> nameEx("reconPlot")
> ### * reconPlot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: reconPlot
> ### Title: Stratigraphic plots of palaeoenvironmental reconstructions
> ### Aliases: reconPlot reconPlot.default reconPlot.predict.mat
> ###   reconPlot.predict.wa
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## Fit a MAT model
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> ## Reconstruct pH for the RLGH core
> v12.pH <- predict(ik.mat, V12.122)
> 
> ## draw the reconstruction
> reconPlot(v12.pH, use.labels = TRUE, display.error = "bars",
+           xlab = "Depth", ylab = "Summer Seas-surface Temperature")
> 
> 
> 
> cleanEx()
> nameEx("residLen")
> ### * residLen
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residLen
> ### Title: Squared residual length diagnostics
> ### Aliases: residLen print.residLen fittedY sqrlLinear sqrlUnimodal
> ### Keywords: methods multivariate
> 
> ### ** Examples
> 
> ## load the Imbrie and Kipp example data
> data(ImbrieKipp, SumSST, V12.122)
> 
> ## squared residual lengths for Core V12.122
> rlens <- residLen(ImbrieKipp, SumSST, V12.122)
> rlens

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122)

Ordination Method: cca

Quantiles of residual lengths:

                50%  75%  90%  95%  99%
Training Set: 0.854 1.56 2.45 2.61 3.72
Passive:      1.004 1.50 1.87 2.17 2.55
> 
> ## as before but using linear RDA
> residLen(ImbrieKipp, SumSST, V12.122, method = "rda")

	Squared residual lengths

Call: residLen(X = ImbrieKipp, env = SumSST, passive = V12.122, method
= "rda")

Ordination Method: rda

Quantiles of residual lengths:

                   50%      75%     90%    95%      99%
Training Set: 17.44163 40.33589 80.6058 85.394 103.8648
Passive:       0.00773  0.00909  0.0107  0.011   0.0123
> 
> 
> 
> cleanEx()
> nameEx("residuals.prcurve")
> ### * residuals.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: residuals.prcurve
> ### Title: Residuals of a principal curve fit.
> ### Aliases: residuals.prcurve resid.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
>   ## Load Abernethy Forest data set
>   data(abernethy)
> 
>   ## Remove the Depth and Age variables
>   abernethy2 <- abernethy[, -(37:38)]
>   
>   ## Fit the principal curve, preserving the data in the smooth.spline
>   ## smooth functions fitted via keep.data = TRUE
>   aber.pc <- prcurve(abernethy2, method = "ca", keep.data = TRUE)
> 
>   ## default "distance" residuals
>   resid(aber.pc)
        1         2         3         4         5         6         7         8 
14.264852  3.339616  4.534670  7.343308  1.395606  2.276634  1.497317  5.424320 
        9        10        11        12        13        14        15        16 
 2.571996  2.803516  3.041763  4.775465  1.715575  2.382978  4.218761  4.606372 
       17        18        19        20        21        22        23        24 
 5.301167  2.993025  9.986568  6.411143  3.234004  5.207111  6.458562  4.446028 
       25        26        27        28        29        30        31        32 
 4.648528 10.693325  8.145018  7.354527  6.058375  5.054151  4.866059 17.164061 
       33        34        35        36        37        38        39        40 
13.632436 22.271686  6.458558  3.465228  6.082847  3.619209  6.032345  3.241343 
       41        42        43        44        45        46        47        48 
 5.045163  6.146788 14.719240 13.464204 12.087784 24.672399 14.475148 12.994268 
       49 
19.998570 
> 
>   ## residuals from the underlying smooth models, also illustrates
>   ## how to select specific types of residual from the individual
>   ## method using argument 'type'
>   resid(aber.pc, which = "smooths", type = "deviance")
          Betula Pinus sylvestris        Ulmus      Quercus Alnus glutinosa
 [1,] -2.3568160      0.129150193 -0.013915687  0.079415037    -0.026196824
 [2,] -0.4075439     -2.492365530 -0.039673056  0.034621642     0.327227517
 [3,]  3.1795872      0.429126767 -0.043901759  0.025847590    -0.261576556
 [4,]  1.5921355     -0.106538689  0.298530963 -0.029896200     0.152575972
 [5,]  0.5507456      0.588796664 -0.064651531 -0.053670391    -0.191653028
 [6,] -0.9362944      1.569895168 -0.069748608 -0.120315991     0.137792588
 [7,]  0.2709890      1.124477590 -0.070619016 -0.132709233    -0.158319057
 [8,]  0.3086439     -2.164067744 -0.144929186 -0.172451969    -0.145053462
 [9,] -3.5886738     -1.147462100 -0.169750053  0.362204750    -0.164479867
[10,] -1.8848090     -1.178907937 -0.172769019  0.323807573    -0.166915724
[11,] -0.8102093     -1.232364776 -0.175766614  0.588174902    -0.169291394
[12,]  2.1066669      5.497765163  0.772276816 -0.666055364     0.779242704
[13,]  0.9237452     -1.615350086 -0.068444108 -0.061929875    -0.068257556
[14,]  0.6817618     -0.866359478 -0.035476065 -0.149470282    -0.042534916
[15,]  8.5831720     -0.745136344 -0.001516665 -0.062188471    -0.019614027
[16,] -8.9862051      0.256044224  0.028271072  0.004878063    -0.003394177
[17,] -0.4357694      2.349352134  0.038758115  0.026042260     0.001348441
[18,] -8.5906877     -0.084236500  0.078921796  0.108028774     0.015703405
[19,]  0.9052950     -0.870406275  0.063759677  0.094785437     0.014080195
[20,] -1.1249921      2.399343622  0.024717835  0.061093714     0.010775619
[21,]  0.7713952      1.953011315 -0.170758819 -0.111571654    -0.002441168
[22,]  3.1499196      0.878175705 -0.184020899 -0.123578479    -0.003309095
[23,]  5.1123765      1.524003520 -0.193318665 -0.132014596    -0.003917835
[24,]  8.5764542      0.556821118 -0.409467559 -0.333755267    -0.018610254
[25,] -3.0746710     -0.359270653 -0.097563130 -0.020641391    -0.021372559
[26,]  5.5825908     -0.755825225  0.093895515 -0.011995117    -0.037001699
[27,]  3.6772473     -0.562790930 -0.308763586 -0.585504794     0.141917703
[28,]  0.9059052     -1.440377607  0.097957430 -0.541084273    -0.048484473
[29,] -1.5624323     -2.675959610 -0.329773913 -0.280673732    -0.055748154
[30,] -2.1426332     -3.159841359  0.303299036 -0.165532438    -0.060231118
[31,] -0.4347984     -0.369514060  0.525156971  0.384433989     0.118716506
[32,] -4.5539640     -2.849690314  0.451685879  0.877722129    -0.063082891
[33,] -4.2164216     -0.625920690  0.683121452  1.103668879    -0.071917042
[34,] -1.1571606      3.352185982 -0.652286809 -0.038482951     0.207882834
[35,]  0.6724060      2.165113303 -0.289564681 -0.396366555    -0.171431899
[36,]  0.7312017      1.784694473 -0.432249949 -1.025125372    -0.386693920
[37,]  1.5035894      1.529226958  0.535987724 -0.908301982    -0.692949607
[38,]  0.6563814      0.800576527 -0.392538193  0.307405781    -0.700964216
[39,]  2.9045505      2.219908920  0.299949242 -0.123647870    -0.575954719
[40,] -0.6476012      0.001325783 -0.234389385  0.915284912    -0.419598849
[41,]  1.0908527      0.984316627  0.292108553  0.163113441    -0.789969718
[42,] -9.1869423     -7.111762276  1.208118960  1.804508926     4.714647321
[43,] -1.8565871     -1.352213705 -0.495224853  0.243956626     0.092112784
[44,]  5.2762582      2.706909680 -0.230686660 -0.835881759    -0.612190087
[45,]  0.2557774      0.068057883  0.539967422  0.429203981    -0.382163027
[46,] -0.9473611     -0.225621493 -0.953188021 -1.263395482    -0.360902502
[47,] -2.7812601     -1.374282945 -0.285025921 -0.102218582     0.281909036
[48,]  1.3749402      0.509481310  0.449421464  0.200496640    -0.156194609
[49,]  0.3392452     -0.011494304 -0.055923506  0.309765026     0.056483403
      Corylus-Myrica       Salix Juniperus communis Calluna vulgaris
 [1,]    0.001429671 -0.07923696       -0.481974983      -0.21282316
 [2,]   -0.027293562  0.24570363        0.567815283       0.51511594
 [3,]    0.079475893 -0.23091046        0.631698390      -0.41163018
 [4,]    0.012195976  3.32235686       -0.401254434      -0.17140611
 [5,]   -0.354381416 -1.42613443       -0.338021966      -0.21280309
 [6,]   -0.070050718 -2.94849327       -0.209415204      -0.31176499
 [7,]    0.467929141  0.19594078        0.229335326       1.05423907
 [8,]   -0.410137053 -8.08739427        0.698368415       0.23844063
 [9,]    0.582970525 -6.31324883        0.244409311      -0.12396841
[10,]   -0.464652098  4.46150982        0.240099248      -0.11277921
[11,]   -0.473517335 21.81153874        1.491917890      -0.10194443
[12,]    0.468903189 -5.75566457        0.221618200      -0.09455353
[13,]   -0.266498596 -2.58653149       -3.419587870      -0.50694227
[14,]    0.181173844 -2.52182352       -5.499046942      -0.37634203
[15,]    0.520960338 -1.58928866       -6.171314588      -1.00550600
[16,]    0.944027932  0.22663164        7.677262530       3.18957802
[17,]    1.308134693 -0.70459365       -1.683687751      -1.02669180
[18,]    0.882848770  1.15493709       13.592631380       0.28552416
[19,]   -0.283090157 -0.55032600        1.566940805      -1.81888545
[20,]   -0.675266908  1.36772982        1.924585478       0.43755098
[21,]   -5.427984101  0.49110784       -3.111405624       1.22346917
[22,]   -4.959699181  1.04061107       -0.521675481      -0.65996168
[23,]   -5.416731457  0.77474026       -0.070335891      -0.56186839
[24,]   -5.162637420 -3.29419330       -1.108016782       1.00084322
[25,]   -0.239027564  2.99216121       -0.628386096       1.35285148
[26,]    0.672764313 -1.03775511       -2.699772597      -0.06164797
[27,]    0.695659386  0.30336399       -1.877856059      -0.85884022
[28,]    1.792856114  0.62860387       -1.850459107      -0.22338451
[29,]    4.143999657 -0.69356826       -0.478481266       1.35307125
[30,]    5.306894600 -0.16596401       -0.967229313       0.51513632
[31,]    2.921799408 -0.74337724       -0.708738813      -1.11282598
[32,]    8.971767958 -0.74263939       -0.759626534      -0.23242762
[33,]    3.686444345 -0.35374574       -0.008252441      -0.44590285
[34,]   -4.929909013  0.40838820        2.042385226      -0.37270965
[35,]   -3.716857729  0.60839506        1.676594705      -0.66538829
[36,]   -0.576285516  0.18878317        0.308535673      -0.87622019
[37,]   -1.316730195  0.06877344        0.144552865      -0.92670984
[38,]   -0.783151411 -0.15797066        0.167300309       0.46944530
[39,]   -2.652226339 -0.06081836        0.251699994      -1.20712135
[40,]    2.047499685  0.29311400        0.089847605      -0.30399880
[41,]   -0.892698051  0.65498749        0.083767257      -1.60166098
[42,]    0.212555877 -1.04879460       -0.295920207       5.22562211
[43,]    1.427759785 -0.02696289       -0.305922317       1.47658765
[44,]   -4.036998840 -0.33605066       -0.245373086      -0.90937305
[45,]    0.684599981  0.30775127        0.150491189      -0.34530956
[46,]    4.934437726 -0.23973823        0.149463931      -0.89076568
[47,]    2.824410709 -0.32782626       -0.172624712       1.08155917
[48,]   -1.387378514  0.34276181       -0.121407392      -0.71924590
[49,]   -1.250296344  0.13315976       -0.015533554       0.04436869
          Empetrum    Gramineae  Cyperaceae Solidago-type    Compositae
 [1,] -0.936740745   0.38033033  0.69032995  0.1011160997  8.242185e-02
 [2,] -0.158371473   1.18491629  0.54628257  0.2952804722  5.532643e-03
 [3,]  1.130344817   1.33174155  0.31552188 -0.0243115652 -8.789593e-03
 [4,]  0.881193944  -1.05584618 -2.28181376 -0.1455062952  2.686291e-01
 [5,]  1.120145417  -1.98833765 -1.47230893 -0.1971357202 -1.227161e-01
 [6,]  0.276526544  -1.16501864  4.88656904 -0.0417253536 -2.078328e-01
 [7,]  0.880317687  -2.76391400 -4.83371969 -0.3684119074 -2.237378e-01
 [8,]  0.320974277  15.11545079  7.11900267 -1.0188686010 -9.975502e-01
 [9,] -3.785663676 -10.53581224  8.04940104  2.5830702513  3.056334e+00
[10,] -4.461771120   1.13893796 -5.66884742  0.4157020844 -1.119891e+00
[11,] -4.360473223   4.10864795 -6.24571472 -0.3150382118 -1.123207e+00
[12,] -3.161091313  -5.43684217 -0.99094836 -0.6123316330  7.769960e-01
[13,]  8.986082184  -2.95715150 -3.37500927 -0.4354396334  1.707080e-01
[14,]  8.769089683   3.71253275  2.81605165 -0.4368795319 -4.130236e-01
[15,]  8.342357448  -4.64118608 -0.77151734  0.0655652016 -2.769221e-01
[16,] -3.013733299   3.61979069  0.42576419 -0.1780638438  1.282175e-03
[17,] -4.427944275   0.95406039  2.42421975  0.1831368500  1.060202e-02
[18,] -4.951908340  -2.62832523 -1.31252048 -0.0075447483 -1.405854e-02
[19,] -1.508910506   3.51496492 -1.08332971  0.1628509241  1.571429e-01
[20,] -3.277868703  -1.13082101  0.05325698 -0.0062965705 -1.050220e-02
[21,] -0.366728283   2.81049455  0.59853709 -0.0054328417 -4.417859e-03
[22,]  0.013417415   0.10838538  0.65015813 -0.0055222490 -4.182936e-03
[23,]  1.416370900  -2.34867336 -0.27868909 -0.0055925768 -4.026456e-03
[24,]  0.472447744  -0.06363820 -0.44875058 -0.0085081026 -1.580394e-03
[25,]  0.482412731  -0.64256063 -0.27920667 -0.0092199660 -1.300698e-03
[26,]  0.019072421  -0.95150782 -0.79988392 -0.0137000336 -2.338620e-04
[27,]  0.007279354  -0.85221181 -0.10282943 -0.0140283736 -1.822963e-04
[28,] -0.025218099   0.13959746  0.99165976 -0.0171897171  2.177118e-04
[29,]  0.043650996   0.41183531  0.11953827 -0.0192594448  4.147643e-04
[30,]  0.415208493   0.45111668 -0.04612818 -0.0204340850  5.123305e-04
[31,]  0.284336767  -0.59953620  0.17697290 -0.0206964293  5.330956e-04
[32,]  0.349457977  -0.75775727 -0.10793391 -0.0211320973  5.669339e-04
[33,]  0.035839419   0.10735222 -0.03628661  0.1770182453  7.067903e-04
[34,]  0.035269153   1.02181233  0.32293018 -0.0258337877  1.017374e-03
[35,]  0.035990363   0.20008627 -0.05236042 -0.0079378244  3.969321e-04
[36,]  0.104290257   0.41885266 -0.18917328 -0.0031338909  1.650508e-04
[37,] -0.115505050   0.45717648 -0.57695790 -0.0010227806  5.906876e-05
[38,] -0.118585601   0.08890327 -0.53383398 -0.0009355469  5.461822e-05
[39,] -0.135867561  -0.20127188 -0.64359417 -0.0004843826  3.148939e-05
[40,] -0.149202239  -0.58186374 -0.62509308 -0.0001759742  1.555557e-05
[41,] -0.153509995   0.67870764 -0.82526092 -0.0000826024  1.070788e-05
[42,]  0.589580940   0.14101785  3.55669922  0.0002649263 -7.462870e-06
[43,]  0.557539176  -0.54745998  0.79603255  0.0005149194 -2.072486e-05
[44,] -0.199115680  -0.29761626 -0.47097525  0.0007869891 -3.802447e-05
[45,] -0.202524019  -0.56931916 -0.70300744  0.0007439443 -3.620783e-05
[46,] -0.204989268   0.57553624 -0.50805945  0.0007186060 -3.511160e-05
[47,]  0.136512721  -0.25084454  1.18730080  0.0005788945 -2.888623e-05
[48,] -0.251303666   0.05049510 -0.32838535  0.0004252889 -2.186761e-05
[49,]  0.261317307   0.24477251 -0.13408933  0.0001026248 -6.919770e-06
          Artemisia Caryophyllaceae        Sagina        Silene Chenopodiaceae
 [1,]  3.757862e-01   -2.511874e-01  7.235126e-02  4.340981e-02  -5.194826e-02
 [2,]  2.186127e-01   -1.151244e-01 -2.530108e-01 -4.370880e-02   2.137172e-01
 [3,] -1.067275e+00   -2.147048e-01 -2.565897e-01 -5.925150e-02  -9.150889e-02
 [4,] -9.932399e-01    7.240537e-01  8.205640e-01 -1.406678e-01  -1.173287e-01
 [5,]  5.342839e-01    3.151279e-01  8.352264e-02  1.831023e-01   2.237299e-01
 [6,]  2.339655e+00   -4.544043e-01 -2.505431e-01 -2.221588e-01  -1.489049e-01
 [7,]  1.129567e+00    2.158524e-01 -2.478709e-01  1.895953e-01  -1.531741e-01
 [8,]  3.100242e+00   -3.872675e-01 -2.068684e-01  1.325319e-01   1.720243e-01
 [9,] -1.227241e+00    7.828953e-01  8.468060e-01  7.527390e-01   7.704749e-01
[10,] -2.811338e+00   -2.397866e-01 -1.893488e-01 -2.773679e-01  -2.622952e-01
[11,] -2.919603e+00   -2.205042e-01 -1.843566e-01 -2.655348e-01  -2.533224e-01
[12,] -2.727466e+00   -2.047441e-01 -1.797675e-01 -2.552613e-01  -2.453135e-01
[13,]  1.374057e+00   -3.481658e-02 -5.935471e-02 -4.723468e-02  -5.316389e-02
[14,]  1.389217e+00   -3.657919e-02 -4.561453e-02 -2.346063e-02  -2.810768e-02
[15,]  1.395971e+00   -4.527726e-02 -3.658342e-02 -4.881868e-03  -7.980043e-03
[16,] -1.036168e-01   -5.522312e-02 -3.202625e-02  6.502821e-03   4.673488e-03
[17,]  1.963948e-01    2.719882e-01  1.293272e-01  9.460065e-03   8.004406e-03
[18,] -1.373243e-01   -2.582612e-02 -7.519212e-03  9.588708e-03   5.051606e-03
[19,]  5.282770e-02   -2.018631e-02 -5.501973e-03  7.823584e-03   1.790896e-03
[20,] -8.504693e-02   -1.248533e-02 -2.930888e-03  5.252658e-03  -3.713551e-03
[21,] -2.663158e-02   -1.819055e-03  1.076164e-04  1.233811e-03  -1.503448e-02
[22,] -2.475571e-02   -1.549734e-03  1.692870e-04  1.119146e-03  -1.541251e-02
[23,] -2.351874e-02   -1.375045e-03  2.085288e-04  1.044106e-03  -1.566067e-02
[24,] -5.694716e-03    7.879758e-04  6.002804e-04  3.244491e-05   1.620539e-01
[25,] -3.876665e-03    9.526956e-04  6.128173e-04 -5.975315e-05  -1.769654e-02
[26,]  2.428336e-03    1.344639e-03  5.683496e-04 -3.442451e-04  -1.447082e-02
[27,]  2.700592e-03    1.351383e-03  5.614362e-04 -3.545283e-04  -1.419752e-02
[28,]  4.671654e-03    1.350803e-03  4.871526e-04 -4.192631e-04  -1.156855e-02
[29,]  5.532899e-03    1.309317e-03  4.344711e-04 -4.394424e-04  -9.877060e-03
[30,]  5.927738e-03    1.276917e-03  4.037562e-04 -4.460629e-04  -8.925456e-03
[31,]  6.008922e-03    1.268951e-03  3.968014e-04 -4.471680e-04  -8.712634e-03
[32,]  6.139007e-03    1.255141e-03  3.851439e-04 -4.487327e-04  -8.357836e-03
[33,]  6.643370e-03    1.185564e-03  3.320827e-04 -4.516478e-04  -6.771191e-03
[34,]  7.328260e-03    8.676768e-04  1.504534e-04 -4.116854e-04  -1.675809e-03
[35,]  2.198917e-03    9.065805e-05 -3.808762e-05 -9.016837e-05   1.730982e-03
[36,]  8.629206e-04    1.839084e-05 -2.337612e-05 -3.200603e-05   9.055199e-04
[37,]  2.783663e-04   -4.852982e-06 -1.283092e-05 -8.204284e-06   4.340858e-04
[38,]  2.542563e-04   -5.664825e-06 -1.232396e-05 -7.251452e-06   4.127085e-04
[39,]  1.296317e-04   -9.631846e-06 -9.590946e-06 -2.371347e-06   2.991889e-04
[40,]  4.451768e-05   -1.208631e-05 -7.599388e-06  9.114806e-07   2.183041e-04
[41,]  1.876389e-05   -1.278003e-05 -6.972777e-06  1.895176e-06   1.931857e-04
[42,] -7.701141e-05   -1.509557e-05 -4.512828e-06  5.501450e-06   9.629371e-05
[43,] -1.457874e-04   -1.636285e-05 -2.552362e-06  8.013352e-06   2.150965e-05
[44,] -2.188420e-04   -1.176121e-05  2.447316e-06  9.512210e-06  -1.362209e-04
[45,] -2.067075e-04   -1.056892e-05  2.576546e-06  8.878582e-06  -1.357779e-04
[46,] -1.995814e-04   -9.923129e-06  2.625761e-06  8.517170e-06  -1.348018e-04
[47,] -1.604024e-04   -6.739836e-06  2.716208e-06  6.602338e-06  -1.246008e-04
[48,] -1.174362e-04   -3.603306e-06  2.641536e-06  4.572098e-06  -1.087474e-04
[49,] -2.730931e-05    2.558535e-06  2.280173e-06  3.954876e-07  -6.999858e-05
      Epilobium-type Papilionaceae Anthyllis vulneraria Astragalus alpinus
 [1,]  -5.330066e-02 -1.123777e-01         2.831316e-02       2.293431e-01
 [2,]   2.482379e-01  1.044191e-01         1.354724e-02      -3.062019e-01
 [3,]  -5.081461e-02 -2.083636e-01         1.062567e-02      -3.479955e-01
 [4,]  -4.712676e-02 -2.592395e-01        -8.268953e-03      -5.699743e-01
 [5,]  -4.824452e-02  7.923814e-01        -1.649058e-02      -2.889661e-01
 [6,]  -5.801477e-02  3.363865e-02        -3.994052e-02       4.283724e-01
 [7,]  -6.059746e-02 -2.642006e-01        -4.435915e-02       1.315752e+00
 [8,]  -2.524522e-01 -6.178048e-02        -2.565565e-01      -2.692691e-01
 [9,]  -2.853638e-01 -2.211951e-02        -2.881449e-01      -1.110511e-01
[10,]   7.127386e-01 -1.748764e-02         7.101587e-01      -9.205324e-02
[11,]   3.419868e-01 -1.255612e-02         3.396309e-01      -7.171625e-02
[12,]  -2.874382e-01 -8.683612e-03        -2.896108e-01      -5.566342e-02
[13,]  -1.013754e-01  1.383506e-02        -1.013571e-01       5.024231e-02
[14,]  -6.220326e-02  1.066969e-02        -6.209078e-02       3.984539e-02
[15,]  -2.837120e-02  7.164130e-03        -2.821322e-02       2.767469e-02
[16,]  -5.436151e-03  4.309875e-03        -5.269509e-03       1.744828e-02
[17,]   9.916369e-04  3.417762e-03         1.156426e-03       1.420106e-02
[18,]   1.425474e-02 -7.817446e-04         1.430619e-02      -2.252895e-03
[19,]   1.198654e-02 -7.518792e-04         1.202542e-02      -2.285290e-03
[20,]   8.476553e-03 -6.422601e-04         8.498914e-03      -2.073240e-03
[21,]   2.438563e-03 -2.942629e-04         2.439912e-03      -1.049215e-03
[22,]   2.252222e-03 -2.798263e-04         2.253095e-03      -1.002325e-03
[23,]   2.129647e-03 -2.701773e-04         2.130213e-03      -9.708490e-04
[24,]   3.999655e-04 -1.153616e-04         3.970714e-04      -4.495461e-04
[25,]   2.293085e-04 -9.707942e-05         2.262128e-04      -3.856760e-04
[26,]  -3.440227e-04 -2.568797e-05        -3.473332e-04      -1.298677e-04
[27,]  -3.677289e-04 -2.215164e-05        -3.710211e-04      -1.168739e-04
[28,]  -5.342563e-04  5.651723e-06        -5.372827e-04      -1.334862e-05
[29,]  -6.027637e-04  1.963735e-05        -6.055624e-04       3.977531e-05
[30,]  -6.327898e-04  2.664525e-05        -6.354480e-04       6.669022e-05
[31,]  -6.388290e-04  2.814425e-05        -6.414549e-04       7.247372e-05
[32,]  -6.483979e-04  3.059281e-05        -6.509689e-04       8.194117e-05
[33,]  -6.838434e-04  4.080060e-05        -6.861587e-04       1.217156e-04
[34,]  -7.089168e-04  6.461582e-05        -7.102808e-04       2.184714e-04
[35,]  -1.952020e-04  2.694937e-05        -1.951524e-04       9.802308e-05
[36,]  -7.482923e-05  1.134146e-05        -7.476329e-05       4.175545e-05
[37,]  -2.302563e-05  4.139145e-06        -2.297519e-05       1.553337e-05
[38,]  -2.090414e-05  3.835543e-06        -2.085475e-05       1.442375e-05
[39,]  -9.961855e-06  2.255999e-06        -9.918434e-06       8.644181e-06
[40,]  -2.514976e-06  1.165872e-06        -2.476327e-06       4.648183e-06
[41,]  -2.667523e-07  8.338412e-07        -2.296795e-07       3.429711e-06
[42,]   8.066838e-06 -4.127205e-07         8.097334e-06      -1.152223e-06
[43,]   1.401034e-05 -1.325494e-06         1.403505e-05      -4.518168e-06
[44,]   1.970970e-05 -2.560052e-06         1.971216e-05      -9.231515e-06
[45,]   1.856107e-05 -2.442167e-06         1.856194e-05      -8.822990e-06
[46,]   1.789214e-05 -2.370514e-06         1.789222e-05      -8.572672e-06
[47,]   1.425231e-05 -1.960208e-06         1.424903e-05      -7.126164e-06
[48,]   1.029721e-05 -1.494445e-06         1.029121e-05      -5.472007e-06
[49,]   2.044005e-06 -4.988552e-07         2.033426e-06      -1.922349e-06
        Ononis-type      Rosaceae     Rubiaceae Ranunculaceae    Thalictrum
 [1,] -1.372937e-01  1.654573e-01  0.0357345324  3.191122e-02 -1.116407e-02
 [2,] -6.568944e-01 -7.469269e-02  0.0174694199  1.458846e-02 -5.813685e-02
 [3,] -7.441653e-01 -6.492705e-02  0.0138457401  1.117886e-02  4.556740e-01
 [4,]  1.416579e+00 -3.110089e-02 -0.0096995564 -1.067033e-02 -4.018084e-01
 [5,]  5.397728e-01 -2.616427e-02 -0.0199977765 -2.008053e-02 -4.207849e-01
 [6,]  4.601093e-01 -2.562087e-02 -0.0494985870 -4.668608e-02 -4.762187e-01
 [7,] -4.974600e-01 -2.679256e-02 -0.0550754718 -5.166613e-02  7.742746e-01
 [8,]  3.821056e-01 -1.655893e-01 -0.3322865847 -2.736133e-01  8.495744e-01
 [9,] -2.966524e-01  8.600692e-01  0.6610923199  7.431614e-01 -4.640867e-01
[10,] -2.616604e-01 -1.792077e-01  0.6177204870 -2.966642e-01  5.531244e-01
[11,] -2.237029e-01 -1.774839e-01 -0.3848606650  3.348587e-01 -4.272493e-01
[12,] -1.933668e-01 -1.754101e-01 -0.3862285408 -2.927746e-01 -4.109013e-01
[13,]  6.307449e-02 -5.440929e-02 -0.1490604682 -9.545097e-02 -3.233129e-03
[14,]  5.564241e-02 -3.238577e-02 -0.1414171588 -5.756064e-02  1.291821e-02
[15,]  4.322832e-02 -1.361588e-02  0.2022840594 -2.519219e-02 -1.560951e-01
[16,]  3.110080e-02 -9.622666e-04  0.2264053151 -3.470082e-03  2.988848e-02
[17,]  2.698584e-02  2.596172e-03 -0.3117732456  2.575182e-03  1.822526e-01
[18,]  1.708941e-04  1.152475e-02  0.2425133268  1.395928e-02 -8.263714e-02
[19,] -5.906311e-04  1.061548e-02 -0.0824658902  1.169442e-02  9.545076e-02
[20,] -1.276518e-03  9.217347e-03 -0.0636876358  8.218901e-03 -6.167136e-02
[21,] -1.217867e-03  5.544214e-03  0.1626063856  2.313855e-03  1.253402e-01
[22,] -1.187336e-03  5.318600e-03 -0.1438466923  2.133325e-03 -3.348027e-02
[23,] -1.166068e-03  5.159844e-03  0.0385696421  2.014643e-03 -3.267652e-02
[24,] -7.210092e-04  8.742759e-04 -0.0964282821  3.485128e-04 -1.792993e-02
[25,] -6.537340e-04 -6.204336e-05 -0.0901082877  1.855155e-04 -1.592611e-02
[26,] -3.502539e-04 -6.305447e-03  0.1289825992 -3.574758e-04 -7.374427e-03
[27,] -3.331653e-04 -6.803170e-03  0.1207425577 -3.796575e-04 -6.914174e-03
[28,] -1.901142e-04 -1.200802e-02 -0.0435671338 -5.341075e-04 -3.140521e-03
[29,] -1.114728e-04 -1.596728e-02 -0.0342488373 -5.964693e-04 -1.123145e-03
[30,] -7.018310e-05 -1.850314e-02 -0.0291777217 -6.233963e-04 -7.869118e-05
[31,] -6.118323e-05 -1.910727e-02 -0.0280571785 -6.287708e-04  1.477133e-04
[32,] -4.635262e-05 -2.014747e-02 -0.0261991534 -6.372525e-04  5.198474e-04
[33,]  1.742216e-05 -2.534341e-02 -0.0180378214 -6.681455e-04  2.105955e-03
[34,]  1.914518e-04  1.111891e-01  0.0063870017 -6.823321e-04  6.256378e-03
[35,]  1.238564e-04 -9.404908e-02  0.0120511621 -1.836513e-04  3.393885e-03
[36,]  5.533056e-05  6.018595e-02  0.0057556276 -6.993445e-05  1.485455e-03
[37,]  2.206972e-05  7.302930e-02  0.0025008266 -2.121950e-05  5.755793e-04
[38,]  2.064042e-05  9.339711e-02  0.0023578124 -1.922850e-05  5.367391e-04
[39,]  1.316252e-05 -9.410215e-02  0.0016048688 -8.965516e-06  3.339233e-04
[40,]  7.955641e-06 -9.169039e-02  0.0010754143 -1.987944e-06  1.931297e-04
[41,]  6.360992e-06  8.919038e-02  0.0009122891  1.172453e-07  1.500910e-04
[42,]  3.272319e-07 -8.659650e-02  0.0002898581  7.913342e-06 -1.232746e-05
[43,] -4.160369e-06  1.079823e-01 -0.0001807278  1.346255e-05 -1.324943e-04
[44,] -1.125475e-05 -5.236211e-02 -0.0010358031  1.861781e-05 -3.132925e-04
[45,] -1.084208e-05 -4.971258e-02 -0.0010106282  1.751836e-05 -3.007482e-04
[46,] -1.057844e-05 -4.843980e-02 -0.0009925956  1.687945e-05 -2.928954e-04
[47,] -8.985263e-06 -4.338448e-02 -0.0008715195  1.341239e-05 -2.464385e-04
[48,] -7.099361e-06  1.507636e-01 -0.0007175697  9.654247e-06 -1.923229e-04
[49,] -2.980106e-06 -2.916819e-02 -0.0003697126  1.822958e-06 -7.507847e-05
      Rumex acetosa-type   Oxyria-type Parnassia palustris Saxifraga spp1
 [1,]       2.426777e+00  1.851769e-02        2.504843e-02   5.199540e-02
 [2,]       7.358972e-01  8.599773e-03        1.375980e-02  -3.266410e-01
 [3,]      -2.969326e+00  6.644267e-03        1.147960e-02   7.091831e-02
 [4,]      -3.313191e+00 -5.925327e-03       -3.792834e-03   3.312681e-01
 [5,]       7.352067e-01 -1.135758e-02       -1.069145e-02   2.858254e-01
 [6,]      -8.442616e-01 -2.676180e-02       -3.097954e-02  -4.443279e-01
 [7,]       1.269407e+00 -2.965169e-02       -3.488892e-02  -2.941500e-02
 [8,]      -1.175137e+01 -1.618425e-01       -2.675244e-01  -6.913929e-01
 [9,]       1.130471e+01 -1.777625e-01       -3.277544e-01   1.357932e+00
[10,]       1.084105e+01  8.219498e-01       -3.348532e-01  -7.208642e-01
[11,]      -6.230437e+00 -1.774463e-01       -3.419163e-01  -7.171662e-01
[12,]       3.571385e+00 -1.762385e-01        1.553382e+00   1.188033e+00
[13,]       4.413778e+00 -5.840849e-02       -1.463670e-01  -2.350281e-01
[14,]      -6.488385e+00 -3.535533e-02       -9.292240e-02  -1.421375e-01
[15,]      -2.671378e+00 -1.561605e-02       -4.566199e-02  -6.264411e-02
[16,]      -3.636150e+00 -2.340613e-03       -1.294173e-02  -9.209336e-03
[17,]       4.121800e-01  1.359519e-03       -3.639963e-03   5.678642e-03
[18,]       7.530403e-01  8.471144e-03        1.892016e-02   3.415494e-02
[19,]      -2.267771e-01  7.102257e-03        1.604453e-02   2.863033e-02
[20,]       5.572395e-01  4.997998e-03        1.150406e-02   2.014143e-02
[21,]       7.835641e-01  1.413551e-03        3.465819e-03   5.690203e-03
[22,]       3.851939e-01  1.303751e-03        3.212471e-03   5.247736e-03
[23,]       6.166727e-01  1.231557e-03        3.045601e-03   4.956825e-03
[24,]       1.746760e-01  2.169622e-04        6.642281e-04   8.694676e-04
[25,]      -1.871573e-01  1.175255e-04        4.249800e-04   4.690540e-04
[26,]       1.145552e-01 -2.143254e-04       -3.930204e-04  -8.666720e-04
[27,]      -6.871241e-02 -2.279172e-04       -4.276775e-04  -9.213459e-04
[28,]      -1.879218e-01 -3.227374e-04       -6.753583e-04  -1.302593e-03
[29,]      -1.513310e-01 -3.611802e-04       -7.808877e-04  -1.457010e-03
[30,]      -1.313168e-01 -3.778345e-04       -8.283937e-04  -1.523854e-03
[31,]      -1.268872e-01 -3.811644e-04       -8.380765e-04  -1.537214e-03
[32,]      -1.195376e-01 -3.864241e-04       -8.535231e-04  -1.558311e-03
[33,]      -8.719368e-02 -4.056551e-04       -9.123656e-04  -1.635380e-03
[34,]       9.948485e-03 -4.155776e-04       -9.776765e-04  -1.674112e-03
[35,]       2.683149e-02 -1.123990e-04       -2.822768e-04  -4.522608e-04
[36,]      -2.619057e-04 -4.286313e-05       -1.096512e-04  -1.724095e-04
[37,]      -1.235300e-02 -1.304534e-05       -3.466745e-05  -5.243437e-05
[38,]       1.772313e-01 -1.182615e-05       -3.158434e-05  -4.752933e-05
[39,]      -1.464234e-02 -5.540762e-06       -1.566267e-05  -2.224279e-05
[40,]      -1.561463e-02 -1.266543e-06       -4.805398e-06  -5.048219e-06
[41,]      -1.584980e-02  2.320205e-08       -1.523404e-06   1.400701e-07
[42,]      -1.640559e-02  4.800451e-06        1.066467e-05   1.935670e-05
[43,]      -1.632776e-02  8.202316e-06        1.939106e-05   3.303940e-05
[44,]      -9.072600e-03  1.138474e-05        2.827182e-05   4.581829e-05
[45,]      -7.918169e-03  1.071432e-05        2.666891e-05   4.311836e-05
[46,]      -7.305807e-03  1.032456e-05        2.573113e-05   4.154884e-05
[47,]      -4.381939e-03  8.208252e-06        2.059927e-05   3.302805e-05
[48,]      -1.602903e-03  5.913067e-06        1.499449e-05   2.378819e-05
[49,]       3.723101e-03  1.128893e-06        3.265048e-06   4.529640e-06
      Saxifraga spp2         Sedum        Urtica      Veronica
 [1,]  -4.475967e-02 -1.536234e-03  1.563617e-01  1.560104e-01
 [2,]  -5.859376e-02 -3.392649e-01 -9.684482e-02  8.098336e-02
 [3,]   3.496461e-01 -3.971910e-01 -8.919475e-02  6.597204e-02
 [4,]  -6.914392e-02  5.847736e-02 -6.377708e-02 -3.298724e-02
 [5,]  -7.506157e-02  6.668903e-01 -5.996042e-02 -7.695110e-02
 [6,]  -9.947818e-02 -5.563766e-01  2.435235e-01 -2.045296e-01
 [7,]  -1.049991e-01  8.017602e-01 -5.623522e-02 -2.288780e-01
 [8,]  -4.817282e-01  4.895166e-01  3.430241e-01 -1.558441e+00
 [9,]  -5.595670e-01 -2.586787e-01 -1.885371e-01 -1.847755e+00
[10,]   4.336650e-01 -2.317867e-01 -2.017115e-01  1.122912e+00
[11,]   6.883410e-01 -2.024520e-01 -2.186508e-01 -1.903603e+00
[12,]   3.761852e-01 -1.788861e-01 -2.346457e-01  5.701164e+00
[13,]  -2.170931e-01  3.877211e-02  8.201077e-01 -7.622344e-01
[14,]  -1.351060e-01  3.722462e-02  2.698059e-01 -4.787337e-01
[15,]  -6.362354e-02  3.146732e-02 -2.108221e-02 -2.299768e-01
[16,]  -1.474885e-02  2.498679e-02 -4.517688e-01 -5.892500e-02
[17,]  -9.709263e-04  2.271451e-02 -8.732805e-02 -1.051961e-02
[18,]   2.951273e-02  5.462627e-03 -8.385884e-02  1.012932e-01
[19,]   2.489902e-02  4.285782e-03 -6.769569e-02  8.565379e-02
[20,]   1.770419e-02  2.250300e-03 -5.255625e-02  6.113132e-02
[21,]   5.188563e-03 -5.651022e-03 -5.466446e-02  1.814041e-02
[22,]   4.799094e-03 -6.189107e-03 -5.536375e-02  1.679495e-02
[23,]   4.542768e-03 -6.567785e-03 -5.584583e-02  1.590913e-02
[24,]   9.094491e-04 -1.578650e-02  2.988217e-01  3.314791e-03
[25,]   5.483528e-04 -1.750613e-02  2.895610e-01  2.056970e-03
[26,]  -6.734541e-04 -2.697973e-02 -4.983517e-02 -2.219195e-03
[27,]  -7.244826e-04 -2.761364e-02 -4.891744e-02 -2.398963e-03
[28,]  -1.085519e-03 -3.341175e-02 -4.004162e-02 -3.676754e-03
[29,]  -1.236263e-03 -3.691340e-02 -3.430089e-02 -4.215311e-03
[30,]  -1.303098e-03 -3.878150e-02 -3.106463e-02 -4.455798e-03
[31,]  -1.316619e-03  1.408154e-01 -3.034033e-02 -4.504621e-03
[32,]  -1.338105e-03 -3.984151e-02 -2.913245e-02 -4.582349e-03
[33,]  -1.418688e-03  1.575206e-01 -2.372515e-02 -4.876032e-03
[34,]  -1.490144e-03 -4.543301e-02 -6.291086e-03 -5.167730e-03
[35,]  -4.182901e-04 -1.308288e-02  5.777574e-03 -1.469275e-03
[36,]  -1.612285e-04 -5.078440e-03  3.043595e-03 -5.683485e-04
[37,]  -5.017694e-05 -1.603294e-03  1.469012e-03 -1.781707e-04
[38,]  -4.562158e-05 -1.460438e-03  1.397435e-03 -1.621483e-04
[39,]  -2.211384e-05 -7.227530e-04  1.017091e-03 -7.943783e-05
[40,]  -6.102226e-06 -2.197669e-04  7.458173e-04 -2.307180e-05
[41,]  -1.265754e-06 -6.773203e-05  6.615246e-04 -6.040046e-06
[42,]   1.667558e-05  4.968112e-04  3.361091e-04  5.717230e-05
[43,]   2.949198e-05  9.009269e-04  8.456444e-05  1.023753e-04
[44,]   4.209481e-05  1.310915e-03 -4.512920e-04  1.475391e-04
[45,]   3.966891e-05  1.236477e-03 -4.506672e-04  1.390993e-04
[46,]   3.825352e-05  1.192939e-03 -4.478434e-04  1.341691e-04
[47,]   3.053417e-05  9.547559e-04 -4.157292e-04  1.072387e-04
[48,]   2.212888e-05  6.946976e-04 -3.644988e-04  7.787498e-05
[49,]   4.568708e-06  1.505462e-04 -2.381826e-04  1.648124e-05
> 
> 
> 
> 
> cleanEx()
> nameEx("rlgh")
> ### * rlgh
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rlgh
> ### Title: Round Loch of Glenhead Diatoms
> ### Aliases: rlgh
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(rlgh)
> 
> 
> 
> cleanEx()
> nameEx("roc")
> ### * roc
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: roc
> ### Title: ROC curve analysis
> ### Aliases: roc roc.default roc.mat roc.analog print.roc summary.roc
> ###   print.summary.roc
> ### Keywords: models multivariate methods
> 
> ### ** Examples
> 
> ## load the example data
> data(swapdiat, swappH, rlgh)
> 
> ## merge training and test set on columns
> dat <- join(swapdiat, rlgh, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:  167  277
Data set 2:  101  139
Merged:      268  277

> 
> ## extract the merged data sets and convert to proportions
> swapdiat <- dat[[1]] / 100
> rlgh <- dat[[2]] / 100
> 
> ## fit an analogue matching (AM) model using the squared chord distance
> ## measure - need to keep the training set dissimilarities
> swap.ana <- analog(swapdiat, rlgh, method = "SQchord",
+                    keep.train = TRUE)
> 
> ## fit the ROC curve to the SWAP diatom data using the AM results
> ## Generate a grouping for the SWAP lakes
> METHOD <- if (getRversion() < "3.1.0") {"ward"} else {"ward.D"}
> clust <- hclust(as.dist(swap.ana$train), method = METHOD)
> grps <- cutree(clust, 12)
> 
> ## fit the ROC curve
> swap.roc <- roc(swap.ana, groups = grps)
> swap.roc

	ROC curve of dissimilarities

Discrimination for all groups:

Optimal Dissimilarity = 0.575 

AUC = 0.974, p-value: < 2.22e-16
No. within: 167   No. outside: 1837 

> 
> ## draw the ROC curve
> plot(swap.roc, 1)
> 
> ## draw the four default diagnostic plots
> layout(matrix(1:4, ncol = 2))
> plot(swap.roc)
> layout(1)
> 
> 
> 
> cleanEx()
> nameEx("scores.prcurve")
> ### * scores.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: scores.prcurve
> ### Title: 'scores' method for principal curve objects of class
> ###   '"prcurve"'.
> ### Aliases: scores.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.691
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.497
Iteration   6: d.sq: 4369.944

PC Converged in 6 iterations.

> 
> ## Extract position on the curve
> pos <- scores(aber.pc, display = "curve")
> head(pos)
       PrC
1 251.3134
2 253.7651
3 273.9467
4 267.3053
5 286.3480
6 277.9563
> 
> ## Extract the coordinates of the curve
> coord <- scores(aber.pc, display = "dimensions")
> dim(coord)
[1] 49 36
> all.equal(dim(coord), dim(abernethy2))
[1] TRUE
> 
> 
> 
> cleanEx()
> nameEx("screeplot")
> ### * screeplot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: screeplot
> ### Title: Screeplots of model results
> ### Aliases: screeplot.mat screeplot.bootstrap.mat
> ### Keywords: hplot methods
> 
> ### ** Examples
> 
> ## Imbrie and Kipp example
> ## load the example data
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training and test set on columns
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> V12.122 <- dat[[2]] / 100
> 
> ## fit the MAT model using the chord distance measure
> (ik.mat <- mat(ImbrieKipp, SumSST, method = "chord"))

	Modern Analogue Technique

Call:
mat(x = ImbrieKipp, y = SumSST, method = "chord") 

Percentiles of the dissimilarities for the training set:

   1%    2%    5%   10%   20% 
0.220 0.280 0.341 0.414 0.501 

Inferences based on the mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.875 0.931    0.284    6.000
  3 1.713 0.941    0.133    5.167
  4 1.796 0.935    0.177    5.125
  5 1.748 0.939    0.209    5.100
  6 1.716 0.943    0.284    5.667
  7 1.763 0.943    0.381    6.429
  8 1.831 0.941    0.390    6.625
  9 1.913 0.940    0.449    7.222
 10 2.040 0.935    0.577    7.500

Inferences based on the weighted mean of k-closest analogues:

  k RMSEP    R2 Avg Bias Max Bias
  1 2.501 0.880    0.321    9.000
  2 1.894 0.929    0.263    6.183
  3 1.733 0.940    0.138    5.470
  4 1.773 0.937    0.173    5.384
  5 1.750 0.939    0.187    5.366
  6 1.709 0.942    0.218    5.493
  7 1.712 0.942    0.254    5.635
  8 1.758 0.940    0.253    5.693
  9 1.777 0.939    0.274    5.838
 10 1.857 0.935    0.362    5.927

> 
> screeplot(ik.mat)
> 
> 
> 
> cleanEx()
> nameEx("splitSample")
> ### * splitSample
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: splitSample
> ### Title: Select samples from along an environmental gradient
> ### Aliases: splitSample
> ### Keywords: manip utilities
> 
> ### ** Examples
> 
> data(swappH)
> 
> ## take a test set of 20 samples along the pH gradient
> test1 <- splitSample(swappH, chunk = 10, take = 20)
> test1
 [1]  27  29  85 115  43 146 121  93 102   5  64 155  75  44 122  54 162 165 123
[20] 129
attr(,"lengths")
 [1] 2 2 2 2 2 2 2 2 2 2
> swappH[test1]
   6.21      61 HOLMEV1   RLGH2    ACH1 SCOATT1    S131   LCSU1    LOD1  115.11 
  4.616   4.600   4.700   4.800   5.101   5.000   5.220   5.350   5.547   5.682 
   DOI1   TINK1   GLAS1    ARR1    S141   BYCH1   WHIN1   WOOD1    S151     S21 
  5.899   5.966   6.240   6.179   6.380   6.440   6.899   6.782   7.250   7.160 
> 
> ## take a larger sample where some chunks don't have many samples
> ## do random filling
> set.seed(3)
> test2 <- splitSample(swappH, chunk = 10, take = 70, fill = "random")
> test2
 [1]  99  72  17  68  36  21   1  52   7  34 150 151   9 101 149 109 135 105  43
[20]  76 103 113 108  10  87  60 128  55 157  63  41  71 153  32  77 132  31 154
[39] 125 110 100  64  75  96 158  30  58  73 145  23 120  20 122  47  86 143  14
[58]  57 111  46 162 165  74 118 133 129 164  18  45 123
attr(,"lengths")
 [1] 7 7 7 7 7 7 7 8 7 6
> swappH[test2]
  LJOSV1     FLE1     3.11     ENO1    82.11     4.11     1.21    BUGE1 
   4.410    4.538    4.600    4.543    4.619    4.381    4.491    4.840 
     121    80.11 SKOMAKV1    STRO1    17.21    LLGH1     SKE2    NAGA1 
   4.800    4.730    4.670    4.837    4.912    4.642    5.100    5.038 
    S271    MACA1     ACH1    GLYN1    LOWT1    RIEC1    MUCK1    18.11 
   5.130    5.022    5.101    4.920    5.000    5.266    5.417    5.441 
    IRD1     COR1     S201    CFYN1     UAI1    DIWA1    89.11    FINL1 
   5.260    5.328    5.490    5.470    5.767    5.720    5.766    5.756 
   TEAN1       71     GOD1     S241    66.11    TECW1     S171    OCHI1 
   5.700    5.700    5.660    5.990    5.990    6.060    5.810    5.953 
   LLDU1     DOI1    GLAS1    LENY1     UIS1    65.21    CLYD1    GARN1 
   5.800    5.899    6.240    6.240    6.209    6.175    6.140    6.250 
     S91    44.21     S121    37.11     S141    BARL1    INVA1      S71 
   6.200    6.600    6.510    6.494    6.380    6.430    6.586    6.460 
   20.11    CLON1    PARC1    BARE1    WHIN1    WOOD1    GEIR1      S11 
   6.577    6.942    6.800    6.748    6.899    6.782    6.760    6.840 
    S251      S21    WHIT1    3.511    ARTH1     S151 
   6.970    7.160    7.031    7.000    7.093    7.250 
> 
> 
> 
> cleanEx()
> nameEx("sppResponse.prcurve")
> ### * sppResponse.prcurve
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: sppResponse
> ### Title: Species responses along gradients.
> ### Aliases: sppResponse sppResponse.prcurve
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Load the Abernethy Forest data set
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit the principal curve using varying complexity of smoothers
> ## for each species
> aber.pc <- prcurve(abernethy2, method = "ca", trace = TRUE,
+                    vary = TRUE, penalty = 1.4)

   Determining initial DFs for each variable...
  |                                                                              |                                                                      |   0%  |                                                                              |==                                                                    |   3%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |========                                                              |  11%  |                                                                              |==========                                                            |  14%  |                                                                              |============                                                          |  17%  |                                                                              |==============                                                        |  19%  |                                                                              |================                                                      |  22%  |                                                                              |==================                                                    |  25%  |                                                                              |===================                                                   |  28%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |=========================                                             |  36%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  42%  |                                                                              |===============================                                       |  44%  |                                                                              |=================================                                     |  47%  |                                                                              |===================================                                   |  50%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  56%  |                                                                              |=========================================                             |  58%  |                                                                              |===========================================                           |  61%  |                                                                              |=============================================                         |  64%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |===================================================                   |  72%  |                                                                              |====================================================                  |  75%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  81%  |                                                                              |==========================================================            |  83%  |                                                                              |============================================================          |  86%  |                                                                              |==============================================================        |  89%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |====================================================================  |  97%  |                                                                              |======================================================================| 100%


Fitting Principal Curve:

Initial curve: d.sq: 103233.450
Iteration   1: d.sq: 4283.431
Iteration   2: d.sq: 4312.298
Iteration   3: d.sq: 4340.691
Iteration   4: d.sq: 4355.388
Iteration   5: d.sq: 4366.497
Iteration   6: d.sq: 4369.944

PC Converged in 6 iterations.

> 
> ## Extract the fitted species response curves
> resp <- sppResponse(aber.pc)
> 
> 
> 
> cleanEx()
> nameEx("stdError")
> ### * stdError
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: stdError
> ### Title: Standard error of MAT fitted and predicted values
> ### Aliases: stdError stdError.mat stdError.predict.mat
> ### Keywords: methods univar
> 
> ### ** Examples
> 
> ## Imbrie and Kipp Sea Surface Temperature
> data(ImbrieKipp)
> data(SumSST)
> data(V12.122)
> 
> ## merge training set and core samples
> dat <- join(ImbrieKipp, V12.122, verbose = TRUE)

Summary:

            Rows Cols
Data set 1:   61   27
Data set 2:  110   30
Merged:      171   30

> 
> ## extract the merged data sets and convert to proportions
> ImbrieKipp <- dat[[1]] / 100
> ImbrieKippCore <- dat[[2]] / 100
> 
> ## fit the MAT model using the squared chord distance measure
> ik.mat <- mat(ImbrieKipp, SumSST, method = "SQchord")
> 
> ## standard errors - unweighted
> stdError(ik.mat)

	Standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : FALSE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  3.3292   2.5658   2.5166   3.3292   2.5658   3.0000   2.5658   1.2583 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  2.7839   3.2146   1.5000   2.0817   2.0207   2.6458   0.5000   3.0551 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  3.4641   2.3629   2.1794   2.5166   0.0000   1.0408   2.2546   2.2546 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  3.0551   1.5275   2.5981   2.2546   1.0000   0.6429   0.1155   1.1547 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  1.1547   1.1547   2.0000   0.6429   0.6429   0.5292   1.5275   0.5774 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  1.5535   1.5000   1.4434   1.1676   0.5000   1.0408   0.7638   0.5774 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  0.5292   0.2887   0.4619   0.7638   0.5774   1.5044   0.5774   0.2887 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  0.2887   0.5774   0.5774   0.5774   0.0000 
> ## standard errors - weighted version for above
> stdError(ik.mat, k = getK(ik.mat), weighted = TRUE)

	Weighted standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : TRUE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  3.6236   2.6922   2.4905   3.4762   2.7156   2.9827   2.8185   1.0950 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  2.3923   3.5829   1.6044   1.7100   1.7521   2.5962   0.4759   2.9924 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  3.3505   2.2243   2.0883   2.7274   0.0000   1.0314   2.3222   2.1879 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  2.9545   1.6056   2.5588   2.2645   0.9839   0.6838   0.1276   1.0083 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  1.1467   1.0698   2.0196   0.5636   0.5709   0.5259   1.4834   0.5630 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  1.5190   1.4169   1.3391   1.1180   0.5088   1.0723   0.8010   0.6063 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  0.5797   0.3105   0.4611   0.7731   0.5710   1.4630   0.5954   0.3002 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  0.2970   0.5809   0.5851   0.5700   0.0000 
> 
> ## standard errors - weighted; note this uses more (7) analogues
> ## than the above as this model had lowest LOO error
> stdError(ik.mat, weighted = TRUE)

	Weighted standard deviation of MAT predictions

 k-analogues: 7
 Weighted   : TRUE

  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  3.2045   3.8607   3.7093   3.8413   3.6463   3.3567   2.5745   1.8870 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
  2.1729   2.6576   2.6189   2.5574   2.0575   2.5081   1.9093   3.3261 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
  3.3846   2.1971   2.8468   2.3900   1.8478   1.9721   3.1867   2.3264 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
  3.0681   1.9150   1.9977   2.7098   1.9177   0.6841   0.7857   1.2002 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
  1.0991   1.3316   1.4314   0.5048   0.9144   0.5466   1.3659   0.6610 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
  1.2663   1.0450   1.2885   1.0775   1.0370   1.0816   1.0877   0.6390 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
  0.7313   0.4802   0.8549   0.8869   0.4255   1.0753   0.4841   0.7742 
 V20.230    V20.7  V20.234   V18.21  V12.122 
  0.4281   0.5189   0.4316   0.5208   0.1722 
> 
> ## reconstruct for the V12-122 core data
> coreV12.mat <- predict(ik.mat, V12.122, k = 3)
> ## standard errors
> stdError(coreV12.mat)

	Standard deviation of MAT predictions

 k-analogues: 3
 Weighted   : FALSE

     0     10     20     30     40     50     60     70     80     90    100 
0.5774 0.5774 0.5774 1.6073 1.2767 1.2767 0.8660 1.2583 1.4434 1.3229 0.5000 
   110    120    130    140    150    160    170    180    190    200    210 
0.2887 1.6073 0.2887 1.7321 0.9292 0.8145 0.8145 1.1676 0.2887 1.7321 2.2546 
   220    230    240    250    260    270    280    290    300    310    320 
0.5000 0.5774 1.4189 1.3229 1.2767 1.6073 1.8028 0.5774 1.2767 1.1547 1.6073 
   330    340    350    360    370    380    390    400    410    420    430 
1.4434 1.2583 0.7506 1.2767 1.2767 0.5000 2.2546 0.5000 1.4189 0.2887 0.5000 
   440    450    460    470    480    490    500    510    520    530    540 
0.2887 0.0000 1.4422 1.2767 0.2887 1.1547 0.5774 0.5000 0.5000 1.2767 0.1155 
   550    560    570    580    590    600    610    620    630    640    650 
1.0408 0.2887 0.2887 0.5000 1.2767 0.2887 0.9019 0.4041 0.2887 0.5774 0.7638 
   660    670    680    690    700    710    720    730    740    750    760 
0.2887 0.5000 2.2546 1.2583 0.9644 1.4422 1.5275 1.0408 0.5000 0.2887 0.2887 
   770    780    790    800    810    820    830    840    850    860    870 
1.4422 1.1547 0.5774 0.5774 1.8028 0.2887 1.3229 1.0408 0.5000 1.3229 1.2767 
   880    890    900    910    920    930    940    950    960    970    980 
1.6073 2.0000 0.7638 1.0408 1.3229 0.2887 0.2887 0.4619 0.5000 0.2887 0.2887 
   990   1000   1010   1020   1030   1040   1050   1060   1070   1080   1090 
0.2887 1.4434 0.2887 1.0408 1.4434 0.5000 1.3229 0.2887 1.3229 1.8028 1.3229 
> 
> 
> 
> cleanEx()
> nameEx("summary.analog")
> ### * summary.analog
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.analog
> ### Title: Summarise analogue matching results
> ### Aliases: summary.analog print.summary.analog
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## analog matching between SWAP and RLGH core
> ##D swap.analog <- analog(swapdiat, rlgh, method = "chord")
> ##D swap.analog
> ##D summary(swap.analog)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.bootstrap.mat")
> ### * summary.bootstrap.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.bootstrap.mat
> ### Title: Summarise bootstrap resampling for MAT models
> ### Aliases: summary.bootstrap.mat print.summary.bootstrap.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D 
> ##D ## bootstrap training set
> ##D swap.boot <- bootstrap(swap.mat, k = 10, n.boot = 100)
> ##D swap.boot
> ##D summary(swap.boot)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.cma")
> ### * summary.cma
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.cma
> ### Title: Summarise the extraction of close modern analogues
> ### Aliases: summary.cma print.summary.cma
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## analog matching between SWAP and RLGH core
> ##D swap.analog <- analog(swapdiat, rlgh, method = "chord")
> ##D swap.analog
> ##D summary(swap.analog)
> ##D 
> ##D ## close modern analogues
> ##D swap.cma <- cma(swap.analog, cutoff = 0.6)
> ##D swap.cma
> ##D summary(swap.cma)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.mat")
> ### * summary.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.mat
> ### Title: Summarise Modern Analogue Technique models
> ### Aliases: summary.mat print.summary.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D swap.mat
> ##D 
> ##D ## model summary
> ##D summary(swap.mat)
> ##D 
> ##D ## model summary - evaluating models using k = 1, ..., 20
> ##D ## analogues instead of the default, 10.
> ##D summary(swap.mat, k = 20)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("summary.predict.mat")
> ### * summary.predict.mat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.predict.mat
> ### Title: Summarise MAT model predictions
> ### Aliases: summary.predict.mat print.summary.predict.mat
> ### Keywords: methods
> 
> ### ** Examples
> 
> ## Not run: 
> ##D ## continue the RLGH example from ?join
> ##D example(join)
> ##D 
> ##D ## fit the MAT model using the squared chord distance measure
> ##D swap.mat <- mat(swapdiat, swappH, method = "SQchord")
> ##D 
> ##D ## predict for RLGH data
> ##D swap.pred <- predict(swap.mat, rlgh, bootstrap = FALSE)
> ##D summary(swap.pred)
> ## End(Not run)
> 
> 
> 
> cleanEx()
> nameEx("swapdiat")
> ### * swapdiat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: swapdiat
> ### Title: SWAP sub-fossil diatom and pH training set
> ### Aliases: swapdiat
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(swapdiat)
> 
> 
> 
> cleanEx()
> nameEx("swappH")
> ### * swappH
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: swappH
> ### Title: SWAP sub-fossil diatom and pH training set
> ### Aliases: swappH
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(swappH)
> str(swappH)
 Named num [1:167] 4.49 5.26 4.9 6.43 5.68 ...
 - attr(*, "names")= chr [1:167] "1.21" "10.21" "11" "113.21" ...
> 
> 
> 
> cleanEx()
> nameEx("timetrack")
> ### * timetrack
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: timetrack
> ### Title: Timetracks of change in species composition
> ### Aliases: timetrack print.timetrack plot.timetrack points.timetrack
> ###   fitted.timetrack scores.timetrack predict.timetrack
> ### Keywords: methods hplot
> 
> ### ** Examples
> 
> ## load the RLGH and SWAP data sets
> data(rlgh, swapdiat)
> 
> ## Fit the timetrack ordination
> mod <- timetrack(swapdiat, rlgh, transform = "hellinger",
+                  method = "rda")
> mod

	Timetrack Ordination

Call: timetrack(X = swapdiat, passive = rlgh, method = "rda", transform
= "hellinger")

Ordination Output:
Call: rda(X = X)

              Inertia Rank
Total          0.6163     
Unconstrained  0.6163  166
Inertia is variance 

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 
0.11915 0.05669 0.03734 0.03336 0.02803 0.02362 0.01917 0.01520 
(Showed only 8 of all 166 unconstrained eigenvalues)

> 
> ## Plot the timetrack
> plot(mod, ptype = "b", col = c("forestgreen", "orange"), lwd = 2)
> 
> ## Other options (reorder the time track)
> ord <- rev(seq_len(nrow(rlgh)))
> plot(mod, choices = 2:3, order = ord, ptype = "b",
+      col = c("forestgreen", "orange"), lwd = 2)
> 
> ## illustrating use of the formula
> data(swappH)
> mod2 <- timetrack(swapdiat, rlgh, env = data.frame(pH = swappH),
+                   transform = "hellinger", method = "rda",
+                   formula = ~ pH)
> mod2

	Timetrack Ordination

Call: timetrack(X = swapdiat, passive = rlgh, env = data.frame(pH =
swappH), method = "rda", transform = "hellinger", formula = ~pH)

Ordination Output:
Call: rda(X = X, Y = mf)

              Inertia Proportion Rank
Total          0.6163     1.0000     
Constrained    0.0974     0.1581    1
Unconstrained  0.5189     0.8419  165
Inertia is variance 

Eigenvalues for constrained axes:
   RDA1 
0.09743 

Eigenvalues for unconstrained axes:
    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 
0.06026 0.03786 0.03356 0.02876 0.02448 0.02205 0.01854 0.01377 
(Showed only 8 of all 165 unconstrained eigenvalues)

> plot(mod2)
> 
> ## scores and fitted methods
> head(fitted(mod, type = "passive"))
            PC1        PC2
000.3 0.1375142 0.08856751
000.8 0.1863037 0.08457038
001.3 0.1908819 0.08600249
001.8 0.1763641 0.08944730
002.3 0.1957923 0.08841358
002.8 0.1765786 0.07861150
> head(scores(mod, type = "passive"))
                 PC1          PC2
1.21    0.2160382637 -0.029893425
10.21  -0.0348364914  0.021721523
11      0.2096872141  0.004435281
113.21 -0.0008560853  0.071167503
115.11  0.0907404572 -0.015968707
12.11   0.1220684180 -0.237747308
> 
> ## predict locations in timetrack for new observations
> take <- rlgh[1:50, ]
> take <- take[ , colSums(take) > 0]
> mod3 <- predict(mod, newdata = take)
> class(mod3) ## returns a timetrack object
[1] "timetrack"
> take <- rlgh[-(1:50), ]
> take <- take[ , colSums(take) > 0]
> mod4 <- predict(mod, newdata = take)
> 
> ## build a plot up from base parts
> plot(mod, type = "n", ptype = "n")
> points(mod, which = "ordination", col = "grey", pch = 19, cex = 0.7)
> points(mod3, which = "passive", col = "red")
> points(mod4, which = "passive", col = "blue")
> 
> 
> 
> cleanEx()
> nameEx("tran")
> ### * tran
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: tran
> ### Title: Common data transformations and standardizations
> ### Aliases: tran tran.default tran.formula
> ### Keywords: multivariate manip methods
> 
> ### ** Examples
> 
> data(swapdiat)
> ## convert percentages to proportions
> sptrans <- tran(swapdiat, "pcent2prop")
> 
> ## apply Hellinger transformation
> spHell <- tran(swapdiat, "hellinger")
> 
> ## Dummy data to illustrate formula method
> d <- data.frame(A = runif(10), B = runif(10), C = runif(10))
> ## simulate some missings
> d[sample(10,3), 1] <- NA
> ## apply tran using formula
> tran(~ . - B, data = d, na.action = na.pass,
+      method = "missing", na.value = 0)
            A          C
1  0.26550866 0.93470523
2  0.37212390 0.21214252
3  0.57285336 0.65167377
4  0.00000000 0.12555510
5  0.00000000 0.26722067
6  0.00000000 0.38611409
7  0.94467527 0.01339033
8  0.66079779 0.38238796
9  0.62911404 0.86969085
10 0.06178627 0.34034900
> 
> 
> 
> cleanEx()
> nameEx("varExpl")
> ### * varExpl
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: varExpl
> ### Title: Variance explained by ordination axes
> ### Aliases: varExpl varExpl.default varExpl.cca varExpl.prcurve
> ### Keywords: multivariate utility
> 
> ### ** Examples
> 
> 
> data(abernethy)
> 
> ## Remove the Depth and Age variables
> abernethy2 <- abernethy[, -(37:38)]
> 
> ## Fit PCA
> aber.pca <- rda(abernethy2)
> 
> ## Distance along the first PCA axis
> varExpl(aber.pca)
      PC1 
0.4649883 
> 
> 
> 
> cleanEx()
> nameEx("wa")
> ### * wa
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: wa
> ### Title: Weighted averaging transfer functions
> ### Aliases: wa wa.default wa.formula print.wa fitted.wa residuals.wa
> ###   coef.wa waFit
> ### Keywords: methods models regression multivariate
> 
> ### ** Examples
> 
> ## Don't show: 
> od <- options(digits = 5)
> ## End Don't show
> data(ImbrieKipp)
> data(SumSST)
> 
> ## fit the WA model
> mod <- wa(SumSST ~., data = ImbrieKipp)
> mod

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp) 

Deshrinking  : Inverse 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0188     0.9173     0.0000    -3.8155  

> 
> ## extract the fitted values
> fitted(mod)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  3.7310   3.8599   4.1077   4.2939   8.2876   9.2444   4.0761  13.8155 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
 14.3345  16.5213  15.8044  18.7365  18.2896  18.4587  17.3886  20.4020 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
 19.9694  19.7086  18.7815  22.7892  22.4079  20.7855  22.4544  22.1814 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 21.5623  23.3379  23.3608  22.8445  24.2193  25.6257  25.4988  23.3779 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 23.7472  23.1125  24.5166  25.3837  25.7968  26.2585  24.1625  25.4644 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
 26.2402  25.8240  26.6780  26.3945  26.0913  25.7191  25.8627  26.3385 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 26.7898  26.6969  26.8217  25.9874  26.8824  26.9062  26.5153  26.0680 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 26.6088  27.2316  26.7654  26.9459  26.8330 
> 
> ## residuals for the training set
> residuals(mod)
   V14.61   V17.196   V18.110   V16.227    V14.47    V23.22     V2.12    V23.29 
-1.730960  1.140079  1.392336  2.706094 -1.287580  1.255591  6.923869 -3.815481 
   V12.43      R9.7    A157.3    V23.81    V23.82    V12.53    V23.83    V12.56 
-1.334514 -4.521301 -1.804396 -4.236542 -3.289596 -3.958708 -1.388560 -2.401983 
  A152.84    V16.50   V22.122    V16.41     V4.32    V12.66   V19.245      V4.8 
 0.030579 -1.708591  0.218460 -4.289225 -0.907882  0.214508 -1.454368  1.818595 
  A180.15    V18.34   V20.213   V19.222   A180.39   V16.189    V12.18     V7.67 
 2.437667 -0.337938  0.639214  0.155458 -1.219277 -1.625657 -0.498810  2.622087 
  V17.165   V19.310   V16.190  A153.154   V19.308   V22.172    V10.98   V22.219 
 2.252766  2.887535  0.483422  0.616261  0.203160 -1.758495  2.837538  0.735556 
   V16.33   V22.204   V20.167    V10.89    V12.79   V19.216    V14.90   A180.72 
-1.240175  0.675969 -0.477965 -0.394526 -0.091336  1.280861  1.137318  1.161456 
   V16.21   A180.76   V15.164   A180.78     V14.5    V3.128   A179.13     V9.31 
 0.210242  0.303094  0.178331  1.012626  0.117565  2.093765  1.984665  1.432030 
  V20.230     V20.7   V20.234    V18.21   V12.122 
 0.891171  0.268358  0.234590  0.054063  1.166988 
> 
> ## deshrinking coefficients
> coef(mod)
[1] -5.6876  1.2659
> 
> ## diagnostics plots
> par(mfrow = c(1,2))
> plot(mod)
> par(mfrow = c(1,1))
> 
> ## caterpillar plot of optima and tolerances
> caterpillarPlot(mod)                 ## observed tolerances
> caterpillarPlot(mod, type = "model") ## with tolerances used in WA model
> 
> ## plot diagnostics for the WA model
> par(mfrow = c(1,2))
> plot(mod)
> par(mfrow = c(1,1))
> 
> ## tolerance DW
> mod2 <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+            min.tol = 2, small.tol = "min")
> mod2

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "min",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   2.0268     0.9166     0.0000    -2.4507  

> 
> ## compare actual tolerances to working values
> with(mod2, rbind(tolerances, model.tol))
           O.univ G.cglob G.ruber G.tenel G.saccu G.rubes G.pacL G.pacR G.bullo
tolerances 3.7464  1.8956  1.9096  2.1248  1.9797  1.9683 3.9414 5.1812   5.828
model.tol  3.7464  2.1248  2.1248  2.1248  2.1248  2.1248 3.9414 5.1812   5.828
           G.falco G.calid G.aequi G.gluti G.duter G.infla G.trnL G.trnR
tolerances  3.1092  2.9731  2.5617  5.8983  1.9983  4.7239 4.1617 3.4349
model.tol   3.1092  2.9731  2.5617  5.8983  2.1248  4.7239 4.1617 3.4349
           G.crasf G.scitu G.mentu P.obliq C.nitid S.dehis G.digit  Other
tolerances   3.354  3.9907  2.3866  1.5548  1.4617  3.8447  3.1089 5.1125
model.tol    3.354  3.9907  2.3866  2.1248  2.1248  3.8447  3.1089 5.1125
           G.quin G.hirsu
tolerances 4.2688  3.9421
model.tol  4.2688  3.9421
> 
> ## tolerance DW
> mod3 <- wa(SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE,
+            min.tol = 2, small.tol = "mean")
> mod3

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, tol.dw = TRUE, small.tol = "mean",  

     min.tol = 2) 

Deshrinking  : Inverse 
Tolerance DW : Yes 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   1.9924     0.9194     0.0000    -2.5992  

> 
> ## fit a WA model with monotonic deshrinking
> mod4 <- wa(SumSST ~., data = ImbrieKipp, deshrink = "monotonic")
> mod4

	Weighted Averaging Transfer Function

Call:
wa(formula = SumSST ~ ., data = ImbrieKipp, deshrink = "monotonic") 

Deshrinking  : Monotonic 
Tolerance DW : No 
No. samples  : 61 
No. species  : 27 

Performance:
     RMSE  R-squared  Avg. Bias  Max. Bias  
   1.6107     0.9474     0.0000    -3.8985  

> 
> ## extract the fitted values
> fitted(mod4)
  V14.61  V17.196  V18.110  V16.227   V14.47   V23.22    V2.12   V23.29 
  5.8985   5.9591   6.0758   6.1635   8.1265   8.6414   6.0609  11.5633 
  V12.43     R9.7   A157.3   V23.81   V23.82   V12.53   V23.83   V12.56 
 11.9710  14.0109  13.2762  16.8040  16.1689  16.4046  15.0028  19.3976 
 A152.84   V16.50  V22.122   V16.41    V4.32   V12.66  V19.245     V4.8 
 18.7065  18.2923  16.8700  22.9403  22.4278  20.0083  22.4915  22.1128 
 A180.15   V18.34  V20.213  V19.222  A180.39  V16.189   V12.18    V7.67 
 21.2115  23.6373  23.6652  23.0128  24.6599  26.0993  25.9754  23.6862 
 V17.165  V19.310  V16.190 A153.154  V19.308  V22.172   V10.98  V22.219 
 24.1262  23.3567  24.9810  25.8625  26.2661  26.7165  24.5973  25.9417 
  V16.33  V22.204  V20.167   V10.89   V12.79  V19.216   V14.90  A180.72 
 26.6986  26.2926  27.1273  26.8495  26.5532  26.1904  26.3303  26.7948 
  V16.21  A180.76  V15.164  A180.78    V14.5   V3.128  A179.13    V9.31 
 27.2370  27.1459  27.2683  26.4518  27.3279  27.3512  26.9679  26.5304 
 V20.230    V20.7  V20.234   V18.21  V12.122 
 27.0595  27.6704  27.2131  27.3901  27.2794 
> 
> ## residuals for the training set
> residuals(mod4)
   V14.61   V17.196   V18.110   V16.227    V14.47    V23.22     V2.12    V23.29 
-3.898451 -0.959142 -0.575776  0.836468 -1.126549  1.858557  4.939074 -1.563327 
   V12.43      R9.7    A157.3    V23.81    V23.82    V12.53    V23.83    V12.56 
 1.029013 -2.010916  0.723792 -2.303976 -1.168939 -1.904646  0.997217 -1.397640 
  A152.84    V16.50   V22.122    V16.41     V4.32    V12.66   V19.245      V4.8 
 1.293463 -0.292346  2.130001 -4.440318 -0.927838  0.991727 -1.491527  1.887240 
  A180.15    V18.34   V20.213   V19.222   A180.39   V16.189    V12.18     V7.67 
 2.788500 -0.637275  0.334750 -0.012758 -1.659931 -2.099307 -0.975387  2.313835 
  V17.165   V19.310   V16.190  A153.154   V19.308   V22.172    V10.98   V22.219 
 1.873805  2.643276  0.019001  0.137472 -0.266124 -2.216472  2.402708  0.258265 
   V16.33   V22.204   V20.167    V10.89    V12.79   V19.216    V14.90   A180.72 
-1.698566  0.207389 -0.927317 -0.849545 -0.553215  0.809566  0.669733  0.705244 
   V16.21   A180.76   V15.164   A180.78     V14.5    V3.128   A179.13     V9.31 
-0.236962 -0.145893 -0.268262  0.548197 -0.327863  1.648793  1.532122  0.969585 
  V20.230     V20.7   V20.234    V18.21   V12.122 
 0.440478 -0.170385 -0.213081 -0.390149  0.720613 
> 
> ## Don't show: 
> options(od)
> ## End Don't show
> 
> 
> 
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("weightedCor")
> ### * weightedCor
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: weightedCor
> ### Title: Weighted correlation test of WA reconstruction
> ### Aliases: weightedCor weightedCor.default print.weightedCor
> ###   plot.weightedCor
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> data(ImbrieKipp, SumSST, V12.122)
> 
> Cor <- weightedCor(ImbrieKipp, env = SumSST,
+                    fossil = V12.122, type = "simulate", sim = 49)
Simulating 49 Weighted Correlations:
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   2%  |                                                                              |===                                                                   |   4%  |                                                                              |====                                                                  |   6%  |                                                                              |======                                                                |   8%  |                                                                              |=======                                                               |  10%  |                                                                              |=========                                                             |  12%  |                                                                              |==========                                                            |  14%  |                                                                              |===========                                                           |  16%  |                                                                              |=============                                                         |  18%  |                                                                              |==============                                                        |  20%  |                                                                              |================                                                      |  22%  |                                                                              |=================                                                     |  24%  |                                                                              |===================                                                   |  27%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  31%  |                                                                              |=======================                                               |  33%  |                                                                              |========================                                              |  35%  |                                                                              |==========================                                            |  37%  |                                                                              |===========================                                           |  39%  |                                                                              |=============================                                         |  41%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  45%  |                                                                              |=================================                                     |  47%  |                                                                              |==================================                                    |  49%  |                                                                              |====================================                                  |  51%  |                                                                              |=====================================                                 |  53%  |                                                                              |=======================================                               |  55%  |                                                                              |========================================                              |  57%  |                                                                              |=========================================                             |  59%  |                                                                              |===========================================                           |  61%  |                                                                              |============================================                          |  63%  |                                                                              |==============================================                        |  65%  |                                                                              |===============================================                       |  67%  |                                                                              |=================================================                     |  69%  |                                                                              |==================================================                    |  71%  |                                                                              |===================================================                   |  73%  |                                                                              |=====================================================                 |  76%  |                                                                              |======================================================                |  78%  |                                                                              |========================================================              |  80%  |                                                                              |=========================================================             |  82%  |                                                                              |===========================================================           |  84%  |                                                                              |============================================================          |  86%  |                                                                              |=============================================================         |  88%  |                                                                              |===============================================================       |  90%  |                                                                              |================================================================      |  92%  |                                                                              |==================================================================    |  94%  |                                                                              |===================================================================   |  96%  |                                                                              |===================================================================== |  98%  |                                                                              |======================================================================| 100%

> Cor

	Weighted correlation of WA Transfer Function

Call:
weightedCor(x = ImbrieKipp, env = SumSST, fossil = V12.122, type = "simulate", 
    sim = 49)

Test Type           : Simulation
Weighted Correlation: 0.491 (p = 0.56)
Correlation         : 0.437 (p = < 2.22e-16)

> 
> plot(Cor)
> plot(Cor, type = "null")
> 
> 
> 
> ### * <FOOTER>
> ###
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  26.133 0.195 26.597 0 0.005 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
